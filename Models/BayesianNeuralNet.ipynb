{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b164751-70a5-475c-a610-a4628c21d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Data Loading Function\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.calibration import calibration_curve\n",
    "import pyro\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal,AutoLowRankMultivariateNormal\n",
    "from pyro.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "513335db-1392-4910-8be5-ad1ca4bdb753",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomCelebADataset(Dataset):\n",
    "    def __init__(self, root, split='train', transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        # Paths to metadata files\n",
    "        attr_path = os.path.join(root, 'list_attr_celeba_small.txt')\n",
    "        split_path = os.path.join(root, 'list_eval_partition_small.txt')\n",
    "        img_folder = os.path.join(root, 'img_align_celeba')\n",
    " \n",
    "        # Load labels\n",
    "        with open(attr_path) as f:\n",
    "            lines = f.readlines()\n",
    "            header = lines[1].strip().split()\n",
    "            data = [line.strip().split() for line in lines[2:]]\n",
    "        self.attr_names = header\n",
    "        df_attr = pd.DataFrame(data)\n",
    "        df_attr.columns = ['filename'] + header\n",
    "        df_attr[header] = df_attr[header].astype(int)\n",
    "        df_attr[header] = (df_attr[header] == 1).astype(int)  # convert -1 to 0\n",
    " \n",
    "        # Load split info\n",
    "        df_split = pd.read_csv(split_path, delim_whitespace=True, header=None, names=['filename', 'split'])\n",
    " \n",
    "        # Merge and filter by split\n",
    "        df = pd.merge(df_attr, df_split, on='filename')\n",
    "        split_map = {'train': 0, 'valid': 1, 'test': 2}\n",
    "        self.df = df[df['split'] == split_map[split]].reset_index(drop=True)\n",
    " \n",
    "        self.img_folder = img_folder\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_folder, row['filename'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        labels = torch.tensor(row[self.attr_names].values.astype('float32'))\n",
    "        return image, labels\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd7c13a-e11a-48a6-a2a8-a033531538e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/7d14srh9427f80ydt2svl4cc0000gn/T/ipykernel_6787/2221640474.py:22: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_split = pd.read_csv(split_path, delim_whitespace=True, header=None, names=['filename', 'split'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Transform for classical models (flattened)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # flatten to 12288-dim\n",
    "])\n",
    " \n",
    "dataset = CustomCelebADataset(\n",
    "    root='/Users/anshikapradhan/Documents/STAT 542/Project/Data',\n",
    "    split='train',\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5983604-7ffe-4640-b87f-492cd347ed15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes - X: (5000, 116412) Y: (5000, 40)\n",
      "Standardization complete. Mean: -1.1833517e-10 Std: 1.0000011\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract all (image, label) pairs into full arrays\n",
    "X_list = []\n",
    "Y_list = []\n",
    " \n",
    "for img, label in dataset:\n",
    "    X_list.append(img.numpy())        # already flattened by transform\n",
    "    Y_list.append(label.numpy())      # 40-dim binary vector\n",
    " \n",
    "X = np.stack(X_list)  # shape: (n_samples, 12288)\n",
    "Y = np.stack(Y_list)  # shape: (n_samples, 40)\n",
    " \n",
    "print(\"Shapes - X:\", X.shape, \"Y:\", Y.shape)\n",
    " \n",
    "# Step 2: Standardize features (mean 0, std 1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    " \n",
    "print(\"Standardization complete. Mean:\", np.mean(X_scaled), \"Std:\", np.std(X_scaled))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ab4a2b-87e0-4c08-a5c2-df7363a9d984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to celeba_scaled_small_data.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save to disk using pickle\n",
    "with open('celeba_scaled_small_data.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_scaled': X_scaled,\n",
    "        'Y': Y,\n",
    "        'scaler': scaler\n",
    "    }, f)\n",
    "\n",
    "print(\"Saved to celeba_scaled_small_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "263b7054-444f-4952-b232-7b911ef7bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. X shape: (5000, 116412) Y shape: (5000, 40)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "with open('celeba_scaled_small_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_scaled = data['X_scaled']\n",
    "Y = data['Y']\n",
    "scaler = data['scaler']\n",
    "\n",
    "print(\"Data loaded. X shape:\", X_scaled.shape, \"Y shape:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cb61189-6e54-4517-af8b-04cea88b9f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define attribute names manually (if not already in memory)\n",
    "attr_names = [\n",
    "    '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald',\n",
    "    'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair',\n",
    "    'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin',\n",
    "    'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones',\n",
    "    'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',\n",
    "    'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks',\n",
    "    'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
    "    'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77757d9b-b9d7-4226-b95a-7e0395761362",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiling_idx = attr_names.index('Smiling')\n",
    "Y_smile = Y[:, smiling_idx]  # shape: (n_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da7b043a-5ceb-449e-88ff-99b45d51f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-SNE or PCA Projection of Flattened Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfc26bc0-f9a5-472d-832f-5da47418b1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 256])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Step 1: Initialize PCA with 256 components\n",
    "pca = PCA(n_components=256, random_state=42)\n",
    "# Step 2: Fit PCA on training data only\n",
    "X_train_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(X_train_pca, dtype=torch.float32)\n",
    "Y_smile_tensor = torch.tensor(Y_smile, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "smile_dataset = TensorDataset(X_tensor, Y_smile_tensor)\n",
    "smile_dataloader = DataLoader(smile_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Sanity check: get one batch\n",
    "images_batch, labels_batch = next(iter(smile_dataloader))\n",
    "print(images_batch.shape)  # should be [32, 12288]\n",
    "print(labels_batch.shape)  # should be [32, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b091842-85a0-456b-b1f3-0a6eed812094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.utils as vutils\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming you already have this DataLoader:\n",
    "# # dataloader = DataLoader(tensor_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# # Get one batch\n",
    "# images, labels = next(iter(dataloader))\n",
    "\n",
    "# # Convert flat images back to (C, H, W) format for display\n",
    "# images_grid = images.view(-1, 3, 64, 64)\n",
    "\n",
    "# # Display the image grid\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Sample CelebA images with Smiling label\")\n",
    "# plt.imshow(np.transpose(vutils.make_grid(images_grid[:16], nrow=4, normalize=True), (1, 2, 0)))\n",
    "# plt.show()\n",
    "\n",
    "# # Print Smiling labels\n",
    "# smiling_idx = attr_names.index('Smiling')\n",
    "# print(\"Smiling:\", labels[:16, smiling_idx].int().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "960ce0fe-3979-4846-834c-9c9252eff394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Attribute Frequencies - This gives insights into class imbalance before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79321dd9-b762-47ec-a5e3-4ac875f93ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "import numpy as np\n",
    "\n",
    "class CelebABNN(PyroModule):\n",
    "    def __init__(self, in_dim=256, out_dim=1, hid_dim=400, n_hid_layers=2, prior_scale=0.1):\n",
    "        super().__init__()\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        # Define layer sizes\n",
    "        self.layer_sizes = [in_dim] + n_hid_layers * [hid_dim] + [out_dim]\n",
    "        layer_list = [PyroModule[nn.Linear](self.layer_sizes[i], self.layer_sizes[i+1]) for i in range(len(self.layer_sizes) - 1)]\n",
    "        self.layers = PyroModule[nn.ModuleList](layer_list)\n",
    "\n",
    "        # Set priors on weights and biases\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            in_size = self.layer_sizes[i]\n",
    "            out_size = self.layer_sizes[i+1]\n",
    "            layer.weight = PyroSample(dist.Normal(0., prior_scale * np.sqrt(2 / in_size)).expand([out_size, in_size]).to_event(2))\n",
    "            layer.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_size]).to_event(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        # Forward pass through hidden layers\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.activation(layer(x))\n",
    "        logits = self.layers[-1](x)  # No activation; raw logits for Bernoulli\n",
    "\n",
    "        # Use Bernoulli likelihood for multi-label classification\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Bernoulli(logits=logits).to_event(1), obs=y)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39a0e648-ce34-4aed-a487-1027c78d9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Instantiate the model\n",
    "model = CelebABNN(in_dim=256, out_dim=1, hid_dim=200, n_hid_layers=1, prior_scale=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a34c8c5-35b5-4083-a4d5-0bb7c6840f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Define the guide (variational distribution)\n",
    "#guide = AutoDiagonalNormal(model)\n",
    "from pyro.infer.autoguide import AutoLowRankMultivariateNormal\n",
    "guide = AutoLowRankMultivariateNormal(model, rank=30)  # or rank=30 depending on latent dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8aa1c92-e710-4f9a-ab12-6aa0d16a6b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define optimizer and loss function\n",
    "optimizer = Adam({\"lr\": 1e-3})\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9e97d-c737-451b-8e4e-05d93e67fcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] ELBO loss: 87888.1048\n",
      "[Epoch 2] ELBO loss: 65604.4283\n",
      "[Epoch 3] ELBO loss: 52712.3794\n",
      "[Epoch 4] ELBO loss: 43415.7360\n",
      "[Epoch 5] ELBO loss: 36493.8215\n",
      "[Epoch 6] ELBO loss: 30955.3758\n",
      "[Epoch 7] ELBO loss: 26093.7789\n",
      "[Epoch 8] ELBO loss: 22442.5948\n",
      "[Epoch 9] ELBO loss: 19510.5172\n",
      "[Epoch 10] ELBO loss: 17098.4524\n",
      "[Epoch 11] ELBO loss: 15183.0139\n",
      "[Epoch 12] ELBO loss: 13519.3218\n",
      "[Epoch 13] ELBO loss: 11999.7690\n",
      "[Epoch 14] ELBO loss: 10758.7963\n",
      "[Epoch 15] ELBO loss: 9592.2629\n",
      "[Epoch 16] ELBO loss: 8662.4864\n",
      "[Epoch 17] ELBO loss: 7834.7527\n",
      "[Epoch 18] ELBO loss: 7090.8976\n",
      "[Epoch 19] ELBO loss: 6403.3794\n",
      "[Epoch 20] ELBO loss: 5791.6109\n",
      "[Epoch 21] ELBO loss: 5253.9986\n",
      "[Epoch 22] ELBO loss: 4762.3139\n",
      "[Epoch 23] ELBO loss: 4322.4688\n",
      "[Epoch 24] ELBO loss: 3921.4350\n",
      "[Epoch 25] ELBO loss: 3559.0303\n",
      "[Epoch 26] ELBO loss: 3224.6078\n",
      "[Epoch 27] ELBO loss: 2924.9437\n",
      "[Epoch 28] ELBO loss: 2648.2290\n",
      "[Epoch 29] ELBO loss: 2401.4938\n",
      "[Epoch 30] ELBO loss: 2167.2302\n",
      "[Epoch 31] ELBO loss: 1959.9845\n",
      "[Epoch 32] ELBO loss: 1769.2693\n",
      "[Epoch 33] ELBO loss: 1598.8675\n",
      "[Epoch 34] ELBO loss: 1438.9914\n",
      "[Epoch 35] ELBO loss: 1294.6635\n",
      "[Epoch 36] ELBO loss: 1163.2930\n",
      "[Epoch 37] ELBO loss: 1040.9416\n",
      "[Epoch 38] ELBO loss: 935.2318\n",
      "[Epoch 39] ELBO loss: 835.6457\n",
      "[Epoch 40] ELBO loss: 745.0168\n",
      "[Epoch 41] ELBO loss: 665.5263\n",
      "[Epoch 42] ELBO loss: 590.7041\n",
      "[Epoch 43] ELBO loss: 526.2282\n",
      "[Epoch 44] ELBO loss: 467.7790\n",
      "[Epoch 45] ELBO loss: 413.2867\n",
      "[Epoch 46] ELBO loss: 367.5910\n",
      "[Epoch 47] ELBO loss: 323.6089\n",
      "[Epoch 48] ELBO loss: 284.0696\n",
      "[Epoch 49] ELBO loss: 252.1433\n",
      "[Epoch 50] ELBO loss: 222.9460\n",
      "[Epoch 51] ELBO loss: 196.7972\n",
      "[Epoch 52] ELBO loss: 174.8188\n",
      "[Epoch 53] ELBO loss: 154.1636\n",
      "[Epoch 54] ELBO loss: 136.8964\n",
      "[Epoch 55] ELBO loss: 122.8295\n",
      "[Epoch 56] ELBO loss: 109.6347\n",
      "[Epoch 57] ELBO loss: 99.3148\n",
      "[Epoch 58] ELBO loss: 89.9177\n",
      "[Epoch 59] ELBO loss: 82.4069\n",
      "[Epoch 60] ELBO loss: 76.0800\n",
      "[Epoch 61] ELBO loss: 70.6225\n",
      "[Epoch 62] ELBO loss: 66.5757\n",
      "[Epoch 63] ELBO loss: 63.4301\n",
      "[Epoch 64] ELBO loss: 60.3760\n",
      "[Epoch 65] ELBO loss: 57.8869\n",
      "[Epoch 66] ELBO loss: 56.3985\n",
      "[Epoch 67] ELBO loss: 55.4663\n",
      "[Epoch 68] ELBO loss: 54.7896\n",
      "[Epoch 69] ELBO loss: 54.0330\n",
      "[Epoch 70] ELBO loss: 53.0162\n",
      "[Epoch 71] ELBO loss: 53.3515\n",
      "[Epoch 72] ELBO loss: 52.8934\n",
      "[Epoch 73] ELBO loss: 53.2915\n",
      "[Epoch 74] ELBO loss: 53.5675\n",
      "[Epoch 75] ELBO loss: 53.9479\n",
      "[Epoch 76] ELBO loss: 53.7242\n",
      "[Epoch 77] ELBO loss: 53.9117\n",
      "[Epoch 78] ELBO loss: 54.2075\n",
      "[Epoch 79] ELBO loss: 54.6120\n",
      "[Epoch 80] ELBO loss: 54.2036\n",
      "[Epoch 81] ELBO loss: 54.9451\n",
      "[Epoch 82] ELBO loss: 55.3073\n",
      "[Epoch 83] ELBO loss: 55.4055\n",
      "[Epoch 84] ELBO loss: 55.5591\n",
      "[Epoch 85] ELBO loss: 55.8758\n",
      "[Epoch 86] ELBO loss: 55.6539\n",
      "[Epoch 87] ELBO loss: 56.1794\n",
      "[Epoch 88] ELBO loss: 56.1707\n",
      "[Epoch 89] ELBO loss: 56.2359\n",
      "[Epoch 90] ELBO loss: 56.1339\n",
      "[Epoch 91] ELBO loss: 56.2294\n",
      "[Epoch 92] ELBO loss: 56.2183\n",
      "[Epoch 93] ELBO loss: 56.4517\n",
      "[Epoch 94] ELBO loss: 56.5914\n",
      "[Epoch 95] ELBO loss: 56.9390\n",
      "[Epoch 96] ELBO loss: 56.6980\n",
      "[Epoch 97] ELBO loss: 57.1156\n",
      "[Epoch 98] ELBO loss: 56.7305\n",
      "[Epoch 99] ELBO loss: 56.7014\n",
      "[Epoch 100] ELBO loss: 56.6142\n",
      "[Epoch 101] ELBO loss: 56.7160\n",
      "[Epoch 102] ELBO loss: 57.0784\n",
      "[Epoch 103] ELBO loss: 56.6840\n",
      "[Epoch 104] ELBO loss: 56.8856\n",
      "[Epoch 105] ELBO loss: 56.7217\n",
      "[Epoch 106] ELBO loss: 57.1359\n",
      "[Epoch 107] ELBO loss: 56.8811\n",
      "[Epoch 108] ELBO loss: 56.9702\n",
      "[Epoch 109] ELBO loss: 56.5037\n",
      "[Epoch 110] ELBO loss: 56.8907\n",
      "[Epoch 111] ELBO loss: 56.8560\n",
      "[Epoch 112] ELBO loss: 56.4080\n",
      "[Epoch 113] ELBO loss: 56.9843\n",
      "[Epoch 114] ELBO loss: 57.4429\n",
      "[Epoch 115] ELBO loss: 57.1721\n",
      "[Epoch 116] ELBO loss: 57.1727\n",
      "[Epoch 117] ELBO loss: 56.7577\n",
      "[Epoch 118] ELBO loss: 57.2425\n",
      "[Epoch 119] ELBO loss: 56.8879\n",
      "[Epoch 120] ELBO loss: 56.6828\n",
      "[Epoch 121] ELBO loss: 56.8438\n",
      "[Epoch 122] ELBO loss: 57.1456\n",
      "[Epoch 123] ELBO loss: 57.0659\n",
      "[Epoch 124] ELBO loss: 56.5822\n",
      "[Epoch 125] ELBO loss: 56.5694\n",
      "[Epoch 126] ELBO loss: 57.4583\n",
      "[Epoch 127] ELBO loss: 56.8188\n",
      "[Epoch 128] ELBO loss: 57.0573\n",
      "[Epoch 129] ELBO loss: 56.6884\n",
      "[Epoch 130] ELBO loss: 56.9457\n",
      "[Epoch 131] ELBO loss: 57.3688\n",
      "[Epoch 132] ELBO loss: 56.9036\n",
      "[Epoch 133] ELBO loss: 56.8847\n",
      "[Epoch 134] ELBO loss: 57.1977\n",
      "[Epoch 135] ELBO loss: 56.6023\n",
      "[Epoch 136] ELBO loss: 57.1009\n",
      "[Epoch 137] ELBO loss: 57.1277\n",
      "[Epoch 138] ELBO loss: 56.9372\n",
      "[Epoch 139] ELBO loss: 56.7447\n",
      "[Epoch 140] ELBO loss: 57.1223\n",
      "[Epoch 141] ELBO loss: 57.0702\n",
      "[Epoch 142] ELBO loss: 57.2964\n",
      "[Epoch 143] ELBO loss: 56.9573\n",
      "[Epoch 144] ELBO loss: 57.1033\n",
      "[Epoch 145] ELBO loss: 56.9973\n",
      "[Epoch 146] ELBO loss: 56.9222\n",
      "[Epoch 147] ELBO loss: 57.0988\n",
      "[Epoch 148] ELBO loss: 56.4282\n",
      "[Epoch 149] ELBO loss: 57.5993\n",
      "[Epoch 150] ELBO loss: 57.3308\n",
      "[Epoch 151] ELBO loss: 56.8571\n",
      "[Epoch 152] ELBO loss: 56.9175\n",
      "[Epoch 153] ELBO loss: 56.8390\n",
      "[Epoch 154] ELBO loss: 56.9880\n",
      "[Epoch 155] ELBO loss: 56.6396\n",
      "[Epoch 156] ELBO loss: 57.1893\n",
      "[Epoch 157] ELBO loss: 57.3244\n",
      "[Epoch 158] ELBO loss: 57.1386\n",
      "[Epoch 159] ELBO loss: 57.2609\n",
      "[Epoch 160] ELBO loss: 56.9567\n",
      "[Epoch 161] ELBO loss: 57.0559\n",
      "[Epoch 162] ELBO loss: 56.5275\n",
      "[Epoch 163] ELBO loss: 57.1704\n",
      "[Epoch 164] ELBO loss: 57.2353\n",
      "[Epoch 165] ELBO loss: 56.8549\n",
      "[Epoch 166] ELBO loss: 56.9759\n",
      "[Epoch 167] ELBO loss: 57.1203\n",
      "[Epoch 168] ELBO loss: 57.1845\n",
      "[Epoch 169] ELBO loss: 57.4908\n",
      "[Epoch 170] ELBO loss: 56.8416\n",
      "[Epoch 171] ELBO loss: 56.8404\n",
      "[Epoch 172] ELBO loss: 56.6515\n",
      "[Epoch 173] ELBO loss: 57.0495\n",
      "[Epoch 174] ELBO loss: 56.8112\n",
      "[Epoch 175] ELBO loss: 56.8906\n",
      "[Epoch 176] ELBO loss: 57.0323\n",
      "[Epoch 177] ELBO loss: 56.7432\n",
      "[Epoch 178] ELBO loss: 57.0532\n",
      "[Epoch 179] ELBO loss: 56.4228\n",
      "[Epoch 180] ELBO loss: 57.6135\n",
      "[Epoch 181] ELBO loss: 57.2141\n",
      "[Epoch 182] ELBO loss: 57.0888\n",
      "[Epoch 183] ELBO loss: 57.4761\n",
      "[Epoch 184] ELBO loss: 57.1152\n",
      "[Epoch 185] ELBO loss: 57.4798\n",
      "[Epoch 186] ELBO loss: 57.0683\n",
      "[Epoch 187] ELBO loss: 56.8935\n",
      "[Epoch 188] ELBO loss: 57.2393\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Training loop\n",
    "num_epochs = 200\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.\n",
    "    for batch_x, batch_y in smile_dataloader:\n",
    "        loss = svi.step(batch_x, batch_y)\n",
    "        epoch_loss += loss\n",
    "    avg_loss = epoch_loss / len(smile_dataloader.dataset)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"[Epoch {epoch+1}] ELBO loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247ca289-eddb-43fc-b6ec-3b6897cea98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bnn_smile_with_temp_scaling(model, guide, X_tensor, Y_tensor, num_samples=1000, calibrate_temp=True, plot=True):\n",
    "    \"\"\"\n",
    "    Evaluate Bayesian Neural Network on 'Smiling' with optional temperature scaling.\n",
    "\n",
    "    Parameters:\n",
    "        model: Trained PyroModule\n",
    "        guide: Trained AutoGuide (can be AutoLowRankMultivariateNormal)\n",
    "        X_tensor: torch.Tensor of shape (n_samples, in_dim)\n",
    "        Y_tensor: torch.Tensor of shape (n_samples, 1)\n",
    "        num_samples: Number of posterior samples\n",
    "        calibrate_temp: If True, apply temperature scaling to logits\n",
    "        plot: Whether to show uncertainty and calibration plots\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.special import expit\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "    from sklearn.calibration import calibration_curve\n",
    "    import torch.nn.functional as F\n",
    "    from torch import nn\n",
    "    from torch.optim import LBFGS\n",
    "    import pyro\n",
    "\n",
    "    model.eval()\n",
    "    samples = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        sampled_params = guide(None)\n",
    "        replayed_model = pyro.poutine.replay(model, params=sampled_params)\n",
    "        with pyro.poutine.trace():\n",
    "            logits = replayed_model(X_tensor, y=None).detach().numpy()\n",
    "        samples.append(logits)\n",
    "\n",
    "    samples = np.stack(samples, axis=0).squeeze()  # (num_samples, n_samples)\n",
    "    mean_logits = samples.mean(axis=0)\n",
    "    std_logits = samples.std(axis=0)\n",
    "\n",
    "    # Temperature scaling\n",
    "    if calibrate_temp:\n",
    "        class TemperatureScaler(nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.temperature = nn.Parameter(torch.ones(1) * 1.0)\n",
    "\n",
    "            def forward(self, logits):\n",
    "                return logits / self.temperature\n",
    "\n",
    "        def calibrate_temperature(logits_val, y_val):\n",
    "            scaler = TemperatureScaler()\n",
    "            optimizer = LBFGS([scaler.temperature], lr=0.01, max_iter=100)\n",
    "\n",
    "            def eval():\n",
    "                optimizer.zero_grad()\n",
    "                loss = F.binary_cross_entropy_with_logits(\n",
    "                    scaler(logits_val).squeeze(), y_val.float())\n",
    "                loss.backward()\n",
    "                return loss\n",
    "\n",
    "            optimizer.step(eval)\n",
    "            return scaler\n",
    "\n",
    "        logits_val_tensor = torch.tensor(mean_logits, dtype=torch.float32)\n",
    "        y_val_tensor = torch.tensor(Y_tensor.numpy().squeeze(), dtype=torch.float32)\n",
    "        scaler = calibrate_temperature(logits_val_tensor, y_val_tensor)\n",
    "        scaled_logits = scaler(logits_val_tensor).detach().numpy()\n",
    "        probs = torch.sigmoid(torch.tensor(scaled_logits)).numpy()\n",
    "    else:\n",
    "        probs = torch.sigmoid(torch.tensor(mean_logits)).numpy()\n",
    "\n",
    "    y_pred = (probs >= 0.5).astype(int)\n",
    "    y_true = Y_tensor.numpy().squeeze()\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"f1_score\": f1_score(y_true, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_true, probs),\n",
    "        \"mean_uncertainty\": float(np.mean(std_logits))\n",
    "    }\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.hist(std_logits, bins=30, alpha=0.7)\n",
    "        plt.xlabel(\"Predictive Std Dev (Uncertainty)\")\n",
    "        plt.ylabel(\"Number of Samples\")\n",
    "        plt.title(\"Predictive Uncertainty for 'Smiling'\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        prob_true, prob_pred = calibration_curve(y_true, probs, n_bins=10)\n",
    "        plt.figure()\n",
    "        plt.plot(prob_pred, prob_true, marker='o')\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "        plt.xlabel(\"Predicted probability\")\n",
    "        plt.ylabel(\"True probability\")\n",
    "        plt.title(\"Calibration Curve\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.scatter(mean_logits, std_logits, alpha=0.5)\n",
    "        plt.xlabel(\"Mean Logits (Confidence)\")\n",
    "        plt.ylabel(\"Predictive Std Dev (Uncertainty)\")\n",
    "        plt.title(\"Confidence vs. Uncertainty\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, probs)\n",
    "    plt.plot(fpr, tpr); plt.title(\"ROC Curve\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.grid(True); plt.show()\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_true, probs)\n",
    "    plt.plot(recall, precision); plt.title(\"Precision-Recall Curve\"); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.grid(True); plt.show()\n",
    "\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f54f5-b602-4d8e-9208-4636c9c3d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = CustomCelebADataset(\n",
    "    root='/Users/anshikapradhan/Documents/STAT 542/Project/Data',\n",
    "    split='valid',\n",
    "    transform=transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab58ead-bd75-454e-8567-bd11f4f3e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4eb93-32f1-4d3f-997e-834a1b9e6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract all (image, label) pairs into full arrays\n",
    "X_val_list = []\n",
    "Y_val_list = []\n",
    " \n",
    "for img, label in valid_dataset:\n",
    "    X_val_list.append(img.numpy())        # already flattened by transform\n",
    "    Y_val_list.append(label.numpy())      # 40-dim binary vector\n",
    " \n",
    "X_val = np.stack(X_val_list)  # shape: (n_samples, 12288)\n",
    "Y_val = np.stack(Y_val_list)  # shape: (n_samples, 40)\n",
    " \n",
    "print(\"Shapes - X:\", X_val.shape, \"Y:\",Y_val.shape)\n",
    " \n",
    "# Step 2: Standardize features (mean 0, std 1)\n",
    "scaler = StandardScaler()\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n",
    " \n",
    "print(\"Standardization complete. Mean:\", np.mean(X_val_scaled), \"Std:\", np.std(X_val_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b25044-5f0d-485f-8ff6-e26ba226ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_smile = Y_val[:, smiling_idx] \n",
    "# Step 2: Fit PCA on training data only\n",
    "X_val_pca = pca.fit_transform(X_val_scaled)\n",
    "\n",
    "# Convert to tensors\n",
    "X_val_tensor = torch.tensor(X_val_pca, dtype=torch.float32)\n",
    "Y_smile_val_tensor = torch.tensor(Y_val_smile, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "smile_val_dataset = TensorDataset(X_val_tensor, Y_smile_val_tensor)\n",
    "smile_val_dataloader = DataLoader(smile_val_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe298b-ac18-4520-b619-93c7a4701315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate on validation set (logits used internally)\n",
    "metrics_val = evaluate_bnn_smile_with_temp_scaling(model, guide, X_val_tensor, Y_smile_val_tensor, calibrate_temp=True)\n",
    "print(\"Validation Metrics:\", metrics_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a2604-b851-425b-b800-41fa07f9fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibration Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20e083-b981-46ff-b1cb-cf764047fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Smiling: {Y_smile_tensor.mean().item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efdb17e-0d33-4db9-9b05-b0a9465aba40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
