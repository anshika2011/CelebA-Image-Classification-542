{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u8lc3rAqzFRc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jTUY_m1-V2xI"
   },
   "outputs": [],
   "source": [
    "# ───────────────\n",
    "# 1. Dataset\n",
    "# ───────────────\n",
    "class CustomCelebADataset(Dataset):\n",
    "    def __init__(self, root, split=\"train\", transform=None, attr_idx=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.attr_idx = attr_idx    # integer index of the one attribute you want\n",
    "\n",
    "        # metadata paths\n",
    "        attr_path = os.path.join(root, \"celeba\", \"list_attr_celeba.txt\")\n",
    "        split_path = os.path.join(root, \"celeba\", \"list_eval_partition.txt\")\n",
    "        img_folder = os.path.join(root, \"celeba\", \"img_align_celeba\")\n",
    "\n",
    "        # load attributes\n",
    "        with open(attr_path) as f:\n",
    "            lines = f.readlines()\n",
    "        header = lines[1].strip().split()\n",
    "        data = [l.strip().split() for l in lines[2:]]\n",
    "        df_attr = pd.DataFrame(data, columns=[\"filename\"] + header)\n",
    "        df_attr[header] = df_attr[header].astype(int)\n",
    "        df_attr[header] = (df_attr[header] == 1).astype(int)\n",
    "\n",
    "        # load train/val/test split\n",
    "        df_split = pd.read_csv(split_path, delim_whitespace=True,\n",
    "                               header=None, names=[\"filename\", \"split\"])\n",
    "        df = pd.merge(df_attr, df_split, on=\"filename\")\n",
    "        split_map = {\"train\": 0, \"valid\": 1, \"test\": 2}\n",
    "        self.df = df[df[\"split\"] == split_map[split]].reset_index(drop=True)\n",
    "\n",
    "        self.img_folder = img_folder\n",
    "        self.attr_names = header\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(os.path.join(self.img_folder, row[\"filename\"])).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        #labels = torch.tensor(row[self.attr_names].values.astype(\"float32\"))\n",
    "\n",
    "        all_labels = row[self.attr_names].values.astype(\"float32\")\n",
    "        single = float(all_labels[self.attr_idx])\n",
    "        labels = torch.tensor([single])\n",
    "\n",
    "        return img, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "A_sI6rUWWHQP"
   },
   "outputs": [],
   "source": [
    "# ───────────────\n",
    "# 2. Transforms\n",
    "# ───────────────\n",
    "# ImageNet mean/std (ViT pretrained)\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    # ensure divisible by patch size\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJzYQ2PBWKDt",
    "outputId": "add16078-47ef-4789-c6de-e1fc5881aa28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ny/z_qfvhw51dv2dxv6m_31p6_w0000gn/T/ipykernel_62161/2144400632.py:25: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_split = pd.read_csv(split_path, delim_whitespace=True,\n",
      "/var/folders/ny/z_qfvhw51dv2dxv6m_31p6_w0000gn/T/ipykernel_62161/2144400632.py:25: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_split = pd.read_csv(split_path, delim_whitespace=True,\n",
      "/var/folders/ny/z_qfvhw51dv2dxv6m_31p6_w0000gn/T/ipykernel_62161/2144400632.py:25: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_split = pd.read_csv(split_path, delim_whitespace=True,\n"
     ]
    }
   ],
   "source": [
    "# ───────────────\n",
    "# 3. DataLoaders\n",
    "# ───────────────\n",
    "root = \"/Users/sarthakmorj/Downloads/data\"\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "train_ds = CustomCelebADataset(root, split=\"train\", transform=train_transform, attr_idx=31)\n",
    "val_ds   = CustomCelebADataset(root, split=\"valid\", transform=val_transform, attr_idx=31)\n",
    "test_ds  = CustomCelebADataset(root, split=\"test\",  transform=val_transform, attr_idx=31)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=num_workers, pin_memory=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=num_workers, pin_memory=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=num_workers, pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcFTxL99WOq8"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 873,
     "referenced_widgets": [
      "1f4919bde4e14e99a82aa78d6e4a63e2",
      "b0440a258acd469d8c5a8cd1f94bed7f",
      "95ddb99c650645fcadf6c530f8d98a77",
      "1d38c7f817c140719ca0344c67c447e4",
      "8b5ebc0002d049a6ab90ae6cf8a85b0e",
      "4bd1451f5e6c48f1b0cd2eddf7ac450c",
      "8423e26de1ca41ae9c36ecf535abab0f",
      "8de7e2127b664cdd8fd86c950e9bb501",
      "d2b84222d8384ee1ae23c71e6c5bde2c",
      "c60248dd79d04344b37e9eeeceb59831",
      "7f491eb21bdf4ced8ae70fd622b972fd"
     ]
    },
    "id": "OMKKDjsNgyaj",
    "outputId": "1f421497-7ef8-4b78-b3db-56da7ffaeb7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([1, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification, BitsAndBytesConfig\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    TaskType,\n",
    ")\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    num_labels=1,              # num_labels=1 \n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6l4OxPvYwNZH"
   },
   "outputs": [],
   "source": [
    "labels = train_ds.df[train_ds.attr_names[31]].values.astype(int)\n",
    "pos = labels.sum()\n",
    "neg = len(labels) - pos\n",
    "pos_weight = torch.tensor(neg/pos).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVrNsPBArlk6",
    "outputId": "aa0ae68e-7b04-48d6-897e-ff6af1aa821a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 885,505 || all params: 86,684,930 || trainable%: 1.0215\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "lora_config = LoraConfig(\n",
    "    inference_mode=False,       \n",
    "    r=16,                       # LoRA rank\n",
    "    lora_alpha=32,              # LoRA scaling\n",
    "    target_modules=[\"query\",    # inject into self-attention Q, K, V\n",
    "                    \"key\",\n",
    "                    \"value\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"classifier\"],  # ensures ourclassification head stays trainable\n",
    ")\n",
    "\n",
    "# wrapping the HF model with PEFT → only LoRA params will be trainable\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()  # verify only LoRA adapters are unfrozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XUsaw4QEWRwE"
   },
   "outputs": [],
   "source": [
    "# ───────────────\n",
    "# 5. Loss / Optimizer / Scheduler\n",
    "# ───────────────\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "lora_r = 16\n",
    "lora_alpha = 32\n",
    "lr=3e-4,\n",
    "weight_decay=0.01,\n",
    "epochs = 10\n",
    "total_steps = len(train_loader) * epochs\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> No checkpoint found, starting from scratch\n"
     ]
    }
   ],
   "source": [
    "# ─── Checkpoint setup ───────────────────────────────────────────────────────\n",
    "import os, torch\n",
    "\n",
    "checkpoint_path = f\"/Users/sarthakmorj/Desktop/checkpoint_bs{batch_size}_lr{lr}_wd{weight_decay}_lora_r{lora_r}_lora_alpha{lora_alpha}.pth\"\n",
    "start_epoch   = 1\n",
    "start_batch   = 0\n",
    "\n",
    "if os.path.isfile(checkpoint_path):\n",
    "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict( ckpt[\"model_state\"] )\n",
    "    optimizer.load_state_dict( ckpt[\"opt_state\"]   )\n",
    "    scheduler.load_state_dict( ckpt[\"sched_state\"] )\n",
    "    start_epoch = ckpt[\"epoch\"]\n",
    "    start_batch = ckpt[\"batch_idx\"] + 1\n",
    "    # if we had finished that batch already, move on to the next epoch\n",
    "    if start_batch >= len(train_loader):\n",
    "        start_epoch += 1\n",
    "        start_batch = 0\n",
    "    print(f\"=> Resuming at epoch {start_epoch}, batch {start_batch}\")\n",
    "else:\n",
    "    print(\"=> No checkpoint found, starting from scratch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bYZevT9BWX_l"
   },
   "outputs": [],
   "source": [
    "# ───────────────\n",
    "# 6. Training Loop\n",
    "# ───────────────\n",
    "def train_one_epoch(epoch, resume_batch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    t0 = time.time()\n",
    "\n",
    "    pbar = tqdm(\n",
    "        train_loader,\n",
    "        desc=f\"Epoch {epoch}/{epochs}\",\n",
    "        total=len(train_loader),\n",
    "        initial=resume_batch,\n",
    "        leave=False\n",
    "    )\n",
    "\n",
    "    for batch_idx, (imgs, labels) in enumerate(pbar):\n",
    "        # skip already-done batches\n",
    "        if epoch == start_epoch and batch_idx < resume_batch:\n",
    "            continue\n",
    "\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        logits  = outputs.logits\n",
    "        loss    = criterion(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # update running loss & progress bar\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        seen = (pbar.n + 1) * imgs.size(0)\n",
    "        pbar.set_postfix(train_loss=f\"{running_loss/seen:.4f}\")\n",
    "\n",
    "        # checkpoint right after this batch\n",
    "        torch.save({\n",
    "            \"epoch\":       epoch,\n",
    "            \"batch_idx\":   batch_idx,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"opt_state\":   optimizer.state_dict(),\n",
    "            \"sched_state\": scheduler.state_dict(),\n",
    "            \"hparams\": {\n",
    "                \"lr\": lr,\n",
    "                \"weight_decay\": weight_decay,\n",
    "                \"warmup_steps\": warmup_steps,\n",
    "                \"lora_r\": lora_r,\n",
    "                \"lora_alpha\": lora_alpha\n",
    "                \n",
    "            }\n",
    "        }, checkpoint_path)\n",
    "\n",
    "    pbar.close()\n",
    "    avg_loss = running_loss / len(train_ds)\n",
    "    return avg_loss, time.time() - t0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Q4hwrDuAWdLz"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "@torch.no_grad()\n",
    "def evaluate_binary(loader):\n",
    "    model.eval()\n",
    "    all_y, all_p = [], []\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        logits  = outputs.logits.squeeze(-1)\n",
    "\n",
    "        probs  = torch.sigmoid(logits).cpu().numpy()\n",
    "        all_p.append(probs)\n",
    "        all_y.append(labels.view(-1).numpy())\n",
    "\n",
    "    y_true = np.concatenate(all_y)\n",
    "    y_prob = np.concatenate(all_p)\n",
    "    fpr, tpr, thresh = roc_curve(y_true, y_prob)\n",
    "    best = thresh[(tpr - fpr).argmax()]\n",
    "    y_pred = (y_prob > best).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "    return {\"acc\": acc, \"prec\": p, \"rec\": r, \"f1\": f1, \"roc_auc\": roc_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "eLvWeXDwWgq5",
    "outputId": "cd28b338-6181-47a5-9377-48b6e8721266"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall:   0%|                                           | 0/10 [00:00<?, ?it/s]\n",
      "Epoch 1/10:   0%|                                        | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1/10:   0%|                     | 0/79 [00:09<?, ?it/s, train_loss=0.7374]\u001b[A\n",
      "Epoch 1/10:   1%|▏            | 1/79 [00:09<12:41,  9.76s/it, train_loss=0.7374]\u001b[A\n",
      "Epoch 1/10:   1%|▏            | 1/79 [00:18<12:41,  9.76s/it, train_loss=0.7422]\u001b[A\n",
      "Epoch 1/10:   3%|▎            | 2/79 [00:19<12:11,  9.50s/it, train_loss=0.7422]\u001b[A\n",
      "Epoch 1/10:   3%|▎            | 2/79 [00:28<12:11,  9.50s/it, train_loss=0.7320]\u001b[A\n",
      "Epoch 1/10:   4%|▍            | 3/79 [00:28<11:56,  9.42s/it, train_loss=0.7320]\u001b[A\n",
      "Epoch 1/10:   4%|▍            | 3/79 [00:37<11:56,  9.42s/it, train_loss=0.7303]\u001b[A\n",
      "Epoch 1/10:   5%|▋            | 4/79 [00:37<11:43,  9.38s/it, train_loss=0.7303]\u001b[A\n",
      "Epoch 1/10:   5%|▋            | 4/79 [00:46<11:43,  9.38s/it, train_loss=0.7219]\u001b[A\n",
      "Epoch 1/10:   6%|▊            | 5/79 [00:47<11:33,  9.37s/it, train_loss=0.7219]\u001b[A\n",
      "Epoch 1/10:   6%|▊            | 5/79 [00:56<11:33,  9.37s/it, train_loss=0.7237]\u001b[A\n",
      "Epoch 1/10:   8%|▉            | 6/79 [00:56<11:22,  9.34s/it, train_loss=0.7237]\u001b[A\n",
      "Epoch 1/10:   8%|▉            | 6/79 [01:05<11:22,  9.34s/it, train_loss=0.7259]\u001b[A\n",
      "Epoch 1/10:   9%|█▏           | 7/79 [01:05<11:11,  9.33s/it, train_loss=0.7259]\u001b[A\n",
      "Epoch 1/10:   9%|█▏           | 7/79 [01:15<11:11,  9.33s/it, train_loss=0.7244]\u001b[A\n",
      "Epoch 1/10:  10%|█▎           | 8/79 [01:15<11:07,  9.41s/it, train_loss=0.7244]\u001b[A\n",
      "Epoch 1/10:  10%|█▎           | 8/79 [01:24<11:07,  9.41s/it, train_loss=0.7254]\u001b[A\n",
      "Epoch 1/10:  11%|█▍           | 9/79 [01:24<10:58,  9.40s/it, train_loss=0.7254]\u001b[A\n",
      "Epoch 1/10:  11%|█▍           | 9/79 [01:33<10:58,  9.40s/it, train_loss=0.7332]\u001b[A\n",
      "Epoch 1/10:  13%|█▌          | 10/79 [01:33<10:46,  9.37s/it, train_loss=0.7332]\u001b[A\n",
      "Epoch 1/10:  13%|█▌          | 10/79 [01:43<10:46,  9.37s/it, train_loss=0.7297]\u001b[A\n",
      "Epoch 1/10:  14%|█▋          | 11/79 [01:43<10:47,  9.53s/it, train_loss=0.7297]\u001b[A\n",
      "Epoch 1/10:  14%|█▋          | 11/79 [01:52<10:47,  9.53s/it, train_loss=0.7315]\u001b[A\n",
      "Epoch 1/10:  15%|█▊          | 12/79 [01:53<10:33,  9.45s/it, train_loss=0.7315]\u001b[A\n",
      "Epoch 1/10:  15%|█▊          | 12/79 [02:02<10:33,  9.45s/it, train_loss=0.7350]\u001b[A\n",
      "Epoch 1/10:  16%|█▉          | 13/79 [02:02<10:25,  9.48s/it, train_loss=0.7350]\u001b[A\n",
      "Epoch 1/10:  16%|█▉          | 13/79 [02:11<10:25,  9.48s/it, train_loss=0.7356]\u001b[A\n",
      "Epoch 1/10:  18%|██▏         | 14/79 [02:12<10:16,  9.48s/it, train_loss=0.7356]\u001b[A\n",
      "Epoch 1/10:  18%|██▏         | 14/79 [02:21<10:16,  9.48s/it, train_loss=0.7335]\u001b[A\n",
      "Epoch 1/10:  19%|██▎         | 15/79 [02:21<10:02,  9.42s/it, train_loss=0.7335]\u001b[A\n",
      "Epoch 1/10:  19%|██▎         | 15/79 [02:30<10:02,  9.42s/it, train_loss=0.7325]\u001b[A\n",
      "Epoch 1/10:  20%|██▍         | 16/79 [02:30<09:53,  9.42s/it, train_loss=0.7325]\u001b[A\n",
      "Epoch 1/10:  20%|██▍         | 16/79 [02:40<09:53,  9.42s/it, train_loss=0.7335]\u001b[A\n",
      "Epoch 1/10:  22%|██▌         | 17/79 [02:40<09:49,  9.51s/it, train_loss=0.7335]\u001b[A\n",
      "Epoch 1/10:  22%|██▌         | 17/79 [02:49<09:49,  9.51s/it, train_loss=0.7348]\u001b[A\n",
      "Epoch 1/10:  23%|██▋         | 18/79 [02:50<09:40,  9.52s/it, train_loss=0.7348]\u001b[A\n",
      "Epoch 1/10:  23%|██▋         | 18/79 [02:59<09:40,  9.52s/it, train_loss=0.7348]\u001b[A\n",
      "Epoch 1/10:  24%|██▉         | 19/79 [02:59<09:32,  9.54s/it, train_loss=0.7348]\u001b[A\n",
      "Epoch 1/10:  24%|██▉         | 19/79 [03:08<09:32,  9.54s/it, train_loss=0.7330]\u001b[A\n",
      "Epoch 1/10:  25%|███         | 20/79 [03:09<09:22,  9.53s/it, train_loss=0.7330]\u001b[A\n",
      "Epoch 1/10:  25%|███         | 20/79 [03:18<09:22,  9.53s/it, train_loss=0.7334]\u001b[A\n",
      "Epoch 1/10:  27%|███▏        | 21/79 [03:18<09:16,  9.60s/it, train_loss=0.7334]\u001b[A\n",
      "Epoch 1/10:  27%|███▏        | 21/79 [03:28<09:16,  9.60s/it, train_loss=0.7320]\u001b[A\n",
      "Epoch 1/10:  28%|███▎        | 22/79 [03:28<09:13,  9.71s/it, train_loss=0.7320]\u001b[A\n",
      "Epoch 1/10:  28%|███▎        | 22/79 [03:38<09:13,  9.71s/it, train_loss=0.7308]\u001b[A\n",
      "Epoch 1/10:  29%|███▍        | 23/79 [03:38<09:00,  9.65s/it, train_loss=0.7308]\u001b[A\n",
      "Epoch 1/10:  29%|███▍        | 23/79 [03:47<09:00,  9.65s/it, train_loss=0.7297]\u001b[A\n",
      "Epoch 1/10:  30%|███▋        | 24/79 [03:48<08:51,  9.66s/it, train_loss=0.7297]\u001b[A\n",
      "Epoch 1/10:  30%|███▋        | 24/79 [03:57<08:51,  9.66s/it, train_loss=0.7275]\u001b[A\n",
      "Epoch 1/10:  32%|███▊        | 25/79 [03:57<08:39,  9.62s/it, train_loss=0.7275]\u001b[A\n",
      "Epoch 1/10:  32%|███▊        | 25/79 [04:06<08:39,  9.62s/it, train_loss=0.7268]\u001b[A\n",
      "Epoch 1/10:  33%|███▉        | 26/79 [04:07<08:26,  9.55s/it, train_loss=0.7268]\u001b[A\n",
      "Epoch 1/10:  33%|███▉        | 26/79 [04:16<08:26,  9.55s/it, train_loss=0.7257]\u001b[A\n",
      "Epoch 1/10:  34%|████        | 27/79 [04:16<08:17,  9.57s/it, train_loss=0.7257]\u001b[A\n",
      "Epoch 1/10:  34%|████        | 27/79 [04:25<08:17,  9.57s/it, train_loss=0.7248]\u001b[A\n",
      "Epoch 1/10:  35%|████▎       | 28/79 [04:26<08:08,  9.58s/it, train_loss=0.7248]\u001b[A\n",
      "Epoch 1/10:  35%|████▎       | 28/79 [04:35<08:08,  9.58s/it, train_loss=0.7250]\u001b[A\n",
      "Epoch 1/10:  37%|████▍       | 29/79 [04:35<07:59,  9.59s/it, train_loss=0.7250]\u001b[A\n",
      "Epoch 1/10:  37%|████▍       | 29/79 [04:45<07:59,  9.59s/it, train_loss=0.7241]\u001b[A\n",
      "Epoch 1/10:  38%|████▌       | 30/79 [04:45<07:48,  9.56s/it, train_loss=0.7241]\u001b[A\n",
      "Epoch 1/10:  38%|████▌       | 30/79 [04:54<07:48,  9.56s/it, train_loss=0.7244]\u001b[A\n",
      "Epoch 1/10:  39%|████▋       | 31/79 [04:54<07:38,  9.56s/it, train_loss=0.7244]\u001b[A\n",
      "Epoch 1/10:  39%|████▋       | 31/79 [05:04<07:38,  9.56s/it, train_loss=0.7234]\u001b[A\n",
      "Epoch 1/10:  41%|████▊       | 32/79 [05:04<07:27,  9.52s/it, train_loss=0.7234]\u001b[A\n",
      "Epoch 1/10:  41%|████▊       | 32/79 [05:13<07:27,  9.52s/it, train_loss=0.7210]\u001b[A\n",
      "Epoch 1/10:  42%|█████       | 33/79 [05:13<07:18,  9.53s/it, train_loss=0.7210]\u001b[A\n",
      "Epoch 1/10:  42%|█████       | 33/79 [05:23<07:18,  9.53s/it, train_loss=0.7199]\u001b[A\n",
      "Epoch 1/10:  43%|█████▏      | 34/79 [05:23<07:08,  9.52s/it, train_loss=0.7199]\u001b[A\n",
      "Epoch 1/10:  43%|█████▏      | 34/79 [05:32<07:08,  9.52s/it, train_loss=0.7183]\u001b[A\n",
      "Epoch 1/10:  44%|█████▎      | 35/79 [05:32<06:59,  9.53s/it, train_loss=0.7183]\u001b[A\n",
      "Epoch 1/10:  44%|█████▎      | 35/79 [05:42<06:59,  9.53s/it, train_loss=0.7178]\u001b[A\n",
      "Epoch 1/10:  46%|█████▍      | 36/79 [05:42<06:50,  9.54s/it, train_loss=0.7178]\u001b[A\n",
      "Epoch 1/10:  46%|█████▍      | 36/79 [05:51<06:50,  9.54s/it, train_loss=0.7152]\u001b[A\n",
      "Epoch 1/10:  47%|█████▌      | 37/79 [05:52<06:40,  9.54s/it, train_loss=0.7152]\u001b[A\n",
      "Epoch 1/10:  47%|█████▌      | 37/79 [06:01<06:40,  9.54s/it, train_loss=0.7128]\u001b[A\n",
      "Epoch 1/10:  48%|█████▊      | 38/79 [06:01<06:28,  9.48s/it, train_loss=0.7128]\u001b[A\n",
      "Epoch 1/10:  48%|█████▊      | 38/79 [06:10<06:28,  9.48s/it, train_loss=0.7112]\u001b[A\n",
      "Epoch 1/10:  49%|█████▉      | 39/79 [06:10<06:19,  9.49s/it, train_loss=0.7112]\u001b[A\n",
      "Epoch 1/10:  49%|█████▉      | 39/79 [06:20<06:19,  9.49s/it, train_loss=0.7104]\u001b[A\n",
      "Epoch 1/10:  51%|██████      | 40/79 [06:20<06:11,  9.51s/it, train_loss=0.7104]\u001b[A\n",
      "Epoch 1/10:  51%|██████      | 40/79 [06:29<06:11,  9.51s/it, train_loss=0.7092]\u001b[A\n",
      "Epoch 1/10:  52%|██████▏     | 41/79 [06:29<06:01,  9.52s/it, train_loss=0.7092]\u001b[A\n",
      "Epoch 1/10:  52%|██████▏     | 41/79 [06:39<06:01,  9.52s/it, train_loss=0.7083]\u001b[A\n",
      "Epoch 1/10:  53%|██████▍     | 42/79 [06:39<05:52,  9.54s/it, train_loss=0.7083]\u001b[A\n",
      "Epoch 1/10:  53%|██████▍     | 42/79 [06:48<05:52,  9.54s/it, train_loss=0.7063]\u001b[A\n",
      "Epoch 1/10:  54%|██████▌     | 43/79 [06:49<05:43,  9.55s/it, train_loss=0.7063]\u001b[A\n",
      "Epoch 1/10:  54%|██████▌     | 43/79 [06:58<05:43,  9.55s/it, train_loss=0.7052]\u001b[A\n",
      "Epoch 1/10:  56%|██████▋     | 44/79 [06:58<05:33,  9.52s/it, train_loss=0.7052]\u001b[A\n",
      "Epoch 1/10:  56%|██████▋     | 44/79 [07:07<05:33,  9.52s/it, train_loss=0.7033]\u001b[A\n",
      "Epoch 1/10:  57%|██████▊     | 45/79 [07:08<05:23,  9.53s/it, train_loss=0.7033]\u001b[A\n",
      "Epoch 1/10:  57%|██████▊     | 45/79 [07:17<05:23,  9.53s/it, train_loss=0.7010]\u001b[A\n",
      "Epoch 1/10:  58%|██████▉     | 46/79 [07:17<05:15,  9.55s/it, train_loss=0.7010]\u001b[A\n",
      "Epoch 1/10:  58%|██████▉     | 46/79 [07:27<05:15,  9.55s/it, train_loss=0.6988]\u001b[A\n",
      "Epoch 1/10:  59%|███████▏    | 47/79 [07:27<05:05,  9.56s/it, train_loss=0.6988]\u001b[A\n",
      "Epoch 1/10:  59%|███████▏    | 47/79 [07:36<05:05,  9.56s/it, train_loss=0.6964]\u001b[A\n",
      "Epoch 1/10:  61%|███████▎    | 48/79 [07:36<04:56,  9.56s/it, train_loss=0.6964]\u001b[A\n",
      "Epoch 1/10:  61%|███████▎    | 48/79 [07:46<04:56,  9.56s/it, train_loss=0.6938]\u001b[A\n",
      "Epoch 1/10:  62%|███████▍    | 49/79 [07:46<04:46,  9.56s/it, train_loss=0.6938]\u001b[A\n",
      "Epoch 1/10:  62%|███████▍    | 49/79 [07:55<04:46,  9.56s/it, train_loss=0.6914]\u001b[A\n",
      "Epoch 1/10:  63%|███████▌    | 50/79 [07:56<04:37,  9.57s/it, train_loss=0.6914]\u001b[A\n",
      "Epoch 1/10:  63%|███████▌    | 50/79 [08:05<04:37,  9.57s/it, train_loss=0.6896]\u001b[A\n",
      "Epoch 1/10:  65%|███████▋    | 51/79 [08:05<04:27,  9.57s/it, train_loss=0.6896]\u001b[A\n",
      "Epoch 1/10:  65%|███████▋    | 51/79 [08:14<04:27,  9.57s/it, train_loss=0.6865]\u001b[A\n",
      "Epoch 1/10:  66%|███████▉    | 52/79 [08:15<04:18,  9.59s/it, train_loss=0.6865]\u001b[A\n",
      "Epoch 1/10:  66%|███████▉    | 52/79 [08:24<04:18,  9.59s/it, train_loss=0.6841]\u001b[A\n",
      "Epoch 1/10:  67%|████████    | 53/79 [08:25<04:10,  9.64s/it, train_loss=0.6841]\u001b[A\n",
      "Epoch 1/10:  67%|████████    | 53/79 [08:34<04:10,  9.64s/it, train_loss=0.6798]\u001b[A\n",
      "Epoch 1/10:  68%|████████▏   | 54/79 [08:34<04:00,  9.61s/it, train_loss=0.6798]\u001b[A\n",
      "Epoch 1/10:  68%|████████▏   | 54/79 [08:44<04:00,  9.61s/it, train_loss=0.6764]\u001b[A\n",
      "Epoch 1/10:  70%|████████▎   | 55/79 [08:44<03:54,  9.75s/it, train_loss=0.6764]\u001b[A\n",
      "Epoch 1/10:  70%|████████▎   | 55/79 [08:54<03:54,  9.75s/it, train_loss=0.6724]\u001b[A\n",
      "Epoch 1/10:  71%|████████▌   | 56/79 [08:54<03:48,  9.93s/it, train_loss=0.6724]\u001b[A\n",
      "Epoch 1/10:  71%|████████▌   | 56/79 [09:05<03:48,  9.93s/it, train_loss=0.6686]\u001b[A\n",
      "Epoch 1/10:  72%|████████▋   | 57/79 [09:05<03:45, 10.25s/it, train_loss=0.6686]\u001b[A\n",
      "Epoch 1/10:  72%|████████▋   | 57/79 [09:16<03:45, 10.25s/it, train_loss=0.6656]\u001b[A\n",
      "Epoch 1/10:  73%|████████▊   | 58/79 [09:17<03:41, 10.53s/it, train_loss=0.6656]\u001b[A\n",
      "Epoch 1/10:  73%|████████▊   | 58/79 [09:28<03:41, 10.53s/it, train_loss=0.6614]\u001b[A\n",
      "Epoch 1/10:  75%|████████▉   | 59/79 [09:28<03:37, 10.87s/it, train_loss=0.6614]\u001b[A\n",
      "Epoch 1/10:  75%|████████▉   | 59/79 [09:39<03:37, 10.87s/it, train_loss=0.6569]\u001b[A\n",
      "Epoch 1/10:  76%|█████████   | 60/79 [09:40<03:28, 10.99s/it, train_loss=0.6569]\u001b[A\n",
      "Epoch 1/10:  76%|█████████   | 60/79 [09:50<03:28, 10.99s/it, train_loss=0.6545]\u001b[A\n",
      "Epoch 1/10:  77%|█████████▎  | 61/79 [09:51<03:18, 11.03s/it, train_loss=0.6545]\u001b[A\n",
      "Epoch 1/10:  77%|█████████▎  | 61/79 [10:02<03:18, 11.03s/it, train_loss=0.6492]\u001b[A\n",
      "Epoch 1/10:  78%|█████████▍  | 62/79 [10:02<03:08, 11.06s/it, train_loss=0.6492]\u001b[A\n",
      "Epoch 1/10:  78%|█████████▍  | 62/79 [10:12<03:08, 11.06s/it, train_loss=0.6465]\u001b[A\n",
      "Epoch 1/10:  80%|█████████▌  | 63/79 [10:12<02:54, 10.93s/it, train_loss=0.6465]\u001b[A\n",
      "Epoch 1/10:  80%|█████████▌  | 63/79 [10:22<02:54, 10.93s/it, train_loss=0.6425]\u001b[A\n",
      "Epoch 1/10:  81%|█████████▋  | 64/79 [10:23<02:41, 10.74s/it, train_loss=0.6425]\u001b[A\n",
      "Epoch 1/10:  81%|█████████▋  | 64/79 [10:33<02:41, 10.74s/it, train_loss=0.6377]\u001b[A\n",
      "Epoch 1/10:  82%|█████████▊  | 65/79 [10:33<02:28, 10.61s/it, train_loss=0.6377]\u001b[A\n",
      "Epoch 1/10:  82%|█████████▊  | 65/79 [10:43<02:28, 10.61s/it, train_loss=0.6340]\u001b[A\n",
      "Epoch 1/10:  84%|██████████  | 66/79 [10:43<02:16, 10.51s/it, train_loss=0.6340]\u001b[A\n",
      "Epoch 1/10:  84%|██████████  | 66/79 [10:53<02:16, 10.51s/it, train_loss=0.6295]\u001b[A\n",
      "Epoch 1/10:  85%|██████████▏ | 67/79 [10:54<02:04, 10.41s/it, train_loss=0.6295]\u001b[A\n",
      "Epoch 1/10:  85%|██████████▏ | 67/79 [11:04<02:04, 10.41s/it, train_loss=0.6233]\u001b[A\n",
      "Epoch 1/10:  86%|██████████▎ | 68/79 [11:04<01:53, 10.36s/it, train_loss=0.6233]\u001b[A\n",
      "Epoch 1/10:  86%|██████████▎ | 68/79 [11:14<01:53, 10.36s/it, train_loss=0.6188]\u001b[A\n",
      "Epoch 1/10:  87%|██████████▍ | 69/79 [11:14<01:43, 10.32s/it, train_loss=0.6188]\u001b[A\n",
      "Epoch 1/10:  87%|██████████▍ | 69/79 [11:24<01:43, 10.32s/it, train_loss=0.6138]\u001b[A\n",
      "Epoch 1/10:  89%|██████████▋ | 70/79 [11:24<01:32, 10.27s/it, train_loss=0.6138]\u001b[A\n",
      "Epoch 1/10:  89%|██████████▋ | 70/79 [11:34<01:32, 10.27s/it, train_loss=0.6095]\u001b[A\n",
      "Epoch 1/10:  90%|██████████▊ | 71/79 [11:34<01:21, 10.24s/it, train_loss=0.6095]\u001b[A\n",
      "Epoch 1/10:  90%|██████████▊ | 71/79 [11:44<01:21, 10.24s/it, train_loss=0.6070]\u001b[A\n",
      "Epoch 1/10:  91%|██████████▉ | 72/79 [11:44<01:11, 10.21s/it, train_loss=0.6070]\u001b[A\n",
      "Epoch 1/10:  91%|██████████▉ | 72/79 [11:54<01:11, 10.21s/it, train_loss=0.6029]\u001b[A\n",
      "Epoch 1/10:  92%|███████████ | 73/79 [11:55<01:01, 10.18s/it, train_loss=0.6029]\u001b[A\n",
      "Epoch 1/10:  92%|███████████ | 73/79 [12:04<01:01, 10.18s/it, train_loss=0.5986]\u001b[A\n",
      "Epoch 1/10:  94%|███████████▏| 74/79 [12:05<00:50, 10.16s/it, train_loss=0.5986]\u001b[A\n",
      "Epoch 1/10:  94%|███████████▏| 74/79 [12:14<00:50, 10.16s/it, train_loss=0.5945]\u001b[A\n",
      "Epoch 1/10:  95%|███████████▍| 75/79 [12:15<00:40, 10.12s/it, train_loss=0.5945]\u001b[A\n",
      "Epoch 1/10:  95%|███████████▍| 75/79 [12:25<00:40, 10.12s/it, train_loss=0.5906]\u001b[A\n",
      "Epoch 1/10:  96%|███████████▌| 76/79 [12:25<00:30, 10.11s/it, train_loss=0.5906]\u001b[A\n",
      "Epoch 1/10:  96%|███████████▌| 76/79 [12:35<00:30, 10.11s/it, train_loss=0.5867]\u001b[A\n",
      "Epoch 1/10:  97%|███████████▋| 77/79 [12:35<00:20, 10.10s/it, train_loss=0.5867]\u001b[A\n",
      "Epoch 1/10:  97%|███████████▋| 77/79 [12:45<00:20, 10.10s/it, train_loss=0.5830]\u001b[A\n",
      "Epoch 1/10:  99%|███████████▊| 78/79 [12:45<00:10, 10.09s/it, train_loss=0.5830]\u001b[A\n",
      "Epoch 1/10:  99%|███████████▊| 78/79 [12:46<00:10, 10.09s/it, train_loss=4.6118]\u001b[A\n",
      "Epoch 1/10: 100%|████████████| 79/79 [12:47<00:00,  7.60s/it, train_loss=4.6118]\u001b[A\n",
      "Overall:  10%|███▏                            | 1/10 [13:50<2:04:33, 830.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 • Train loss=0.5829 (767.2s) • Val Acc=0.8980 • Prec=0.9021 • Recall=0.8833 • F1=0.8926 • AUC=0.9647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10:   0%|                                        | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2/10:   0%|                     | 0/79 [00:10<?, ?it/s, train_loss=0.2945]\u001b[A\n",
      "Epoch 2/10:   1%|▏            | 1/79 [00:10<14:11, 10.91s/it, train_loss=0.2945]\u001b[A\n",
      "Epoch 2/10:   1%|▏            | 1/79 [00:21<14:11, 10.91s/it, train_loss=0.2958]\u001b[A\n",
      "Epoch 2/10:   3%|▎            | 2/79 [00:21<13:37, 10.62s/it, train_loss=0.2958]\u001b[A\n",
      "Epoch 2/10:   3%|▎            | 2/79 [00:31<13:37, 10.62s/it, train_loss=0.2787]\u001b[A\n",
      "Epoch 2/10:   4%|▍            | 3/79 [00:32<13:30, 10.66s/it, train_loss=0.2787]\u001b[A\n",
      "Epoch 2/10:   4%|▍            | 3/79 [00:42<13:30, 10.66s/it, train_loss=0.2910]\u001b[A\n",
      "Epoch 2/10:   5%|▋            | 4/79 [00:42<13:16, 10.62s/it, train_loss=0.2910]\u001b[A\n",
      "Epoch 2/10:   5%|▋            | 4/79 [00:52<13:16, 10.62s/it, train_loss=0.2945]\u001b[A\n",
      "Epoch 2/10:   6%|▊            | 5/79 [00:52<12:54, 10.46s/it, train_loss=0.2945]\u001b[A\n",
      "Epoch 2/10:   6%|▊            | 5/79 [01:02<12:54, 10.46s/it, train_loss=0.2904]\u001b[A\n",
      "Epoch 2/10:   8%|▉            | 6/79 [01:03<12:39, 10.40s/it, train_loss=0.2904]\u001b[A\n",
      "Epoch 2/10:   8%|▉            | 6/79 [01:13<12:39, 10.40s/it, train_loss=0.2902]\u001b[A\n",
      "Epoch 2/10:   9%|█▏           | 7/79 [01:13<12:25, 10.35s/it, train_loss=0.2902]\u001b[A\n",
      "Epoch 2/10:   9%|█▏           | 7/79 [01:23<12:25, 10.35s/it, train_loss=0.2865]\u001b[A\n",
      "Epoch 2/10:  10%|█▎           | 8/79 [01:23<12:14, 10.35s/it, train_loss=0.2865]\u001b[A\n",
      "Epoch 2/10:  10%|█▎           | 8/79 [01:33<12:14, 10.35s/it, train_loss=0.2874]\u001b[A\n",
      "Epoch 2/10:  11%|█▍           | 9/79 [01:33<11:57, 10.25s/it, train_loss=0.2874]\u001b[A\n",
      "Epoch 2/10:  11%|█▍           | 9/79 [01:43<11:57, 10.25s/it, train_loss=0.2822]\u001b[A\n",
      "Epoch 2/10:  13%|█▌          | 10/79 [01:43<11:46, 10.23s/it, train_loss=0.2822]\u001b[A\n",
      "Epoch 2/10:  13%|█▌          | 10/79 [01:53<11:46, 10.23s/it, train_loss=0.2792]\u001b[A\n",
      "Epoch 2/10:  14%|█▋          | 11/79 [01:54<11:36, 10.24s/it, train_loss=0.2792]\u001b[A\n",
      "Epoch 2/10:  14%|█▋          | 11/79 [02:04<11:36, 10.24s/it, train_loss=0.2764]\u001b[A\n",
      "Epoch 2/10:  15%|█▊          | 12/79 [02:04<11:25, 10.24s/it, train_loss=0.2764]\u001b[A\n",
      "Epoch 2/10:  15%|█▊          | 12/79 [02:14<11:25, 10.24s/it, train_loss=0.2664]\u001b[A\n",
      "Epoch 2/10:  16%|█▉          | 13/79 [02:14<11:14, 10.22s/it, train_loss=0.2664]\u001b[A\n",
      "Epoch 2/10:  16%|█▉          | 13/79 [02:24<11:14, 10.22s/it, train_loss=0.2612]\u001b[A\n",
      "Epoch 2/10:  18%|██▏         | 14/79 [02:25<11:09, 10.31s/it, train_loss=0.2612]\u001b[A\n",
      "Epoch 2/10:  18%|██▏         | 14/79 [02:34<11:09, 10.31s/it, train_loss=0.2621]\u001b[A\n",
      "Epoch 2/10:  19%|██▎         | 15/79 [02:35<10:57, 10.27s/it, train_loss=0.2621]\u001b[A\n",
      "Epoch 2/10:  19%|██▎         | 15/79 [02:45<10:57, 10.27s/it, train_loss=0.2631]\u001b[A\n",
      "Epoch 2/10:  20%|██▍         | 16/79 [02:45<10:45, 10.24s/it, train_loss=0.2631]\u001b[A\n",
      "Epoch 2/10:  20%|██▍         | 16/79 [02:55<10:45, 10.24s/it, train_loss=0.2629]\u001b[A\n",
      "Epoch 2/10:  22%|██▌         | 17/79 [02:55<10:33, 10.22s/it, train_loss=0.2629]\u001b[A\n",
      "Epoch 2/10:  22%|██▌         | 17/79 [03:05<10:33, 10.22s/it, train_loss=0.2628]\u001b[A\n",
      "Epoch 2/10:  23%|██▋         | 18/79 [03:05<10:26, 10.27s/it, train_loss=0.2628]\u001b[A\n",
      "Epoch 2/10:  23%|██▋         | 18/79 [03:16<10:26, 10.27s/it, train_loss=0.2583]\u001b[A\n",
      "Epoch 2/10:  24%|██▉         | 19/79 [03:16<10:18, 10.31s/it, train_loss=0.2583]\u001b[A\n",
      "Epoch 2/10:  24%|██▉         | 19/79 [03:26<10:18, 10.31s/it, train_loss=0.2539]\u001b[A\n",
      "Epoch 2/10:  25%|███         | 20/79 [03:26<10:10, 10.35s/it, train_loss=0.2539]\u001b[A\n",
      "Epoch 2/10:  25%|███         | 20/79 [03:36<10:10, 10.35s/it, train_loss=0.2592]\u001b[A\n",
      "Epoch 2/10:  27%|███▏        | 21/79 [03:37<09:57, 10.31s/it, train_loss=0.2592]\u001b[A\n",
      "Epoch 2/10:  27%|███▏        | 21/79 [03:46<09:57, 10.31s/it, train_loss=0.2560]\u001b[A\n",
      "Epoch 2/10:  28%|███▎        | 22/79 [03:47<09:43, 10.24s/it, train_loss=0.2560]\u001b[A\n",
      "Epoch 2/10:  28%|███▎        | 22/79 [03:57<09:43, 10.24s/it, train_loss=0.2525]\u001b[A\n",
      "Epoch 2/10:  29%|███▍        | 23/79 [03:57<09:32, 10.22s/it, train_loss=0.2525]\u001b[A\n",
      "Epoch 2/10:  29%|███▍        | 23/79 [04:07<09:32, 10.22s/it, train_loss=0.2501]\u001b[A\n",
      "Epoch 2/10:  30%|███▋        | 24/79 [04:07<09:22, 10.22s/it, train_loss=0.2501]\u001b[A\n",
      "Epoch 2/10:  30%|███▋        | 24/79 [04:17<09:22, 10.22s/it, train_loss=0.2475]\u001b[A\n",
      "Epoch 2/10:  32%|███▊        | 25/79 [04:17<09:11, 10.22s/it, train_loss=0.2475]\u001b[A\n",
      "Epoch 2/10:  32%|███▊        | 25/79 [04:27<09:11, 10.22s/it, train_loss=0.2472]\u001b[A\n",
      "Epoch 2/10:  33%|███▉        | 26/79 [04:28<09:03, 10.25s/it, train_loss=0.2472]\u001b[A\n",
      "Epoch 2/10:  33%|███▉        | 26/79 [04:38<09:03, 10.25s/it, train_loss=0.2481]\u001b[A\n",
      "Epoch 2/10:  34%|████        | 27/79 [04:38<08:55, 10.30s/it, train_loss=0.2481]\u001b[A\n",
      "Epoch 2/10:  34%|████        | 27/79 [04:48<08:55, 10.30s/it, train_loss=0.2499]\u001b[A\n",
      "Epoch 2/10:  35%|████▎       | 28/79 [04:48<08:43, 10.26s/it, train_loss=0.2499]\u001b[A\n",
      "Epoch 2/10:  35%|████▎       | 28/79 [04:58<08:43, 10.26s/it, train_loss=0.2489]\u001b[A\n",
      "Epoch 2/10:  37%|████▍       | 29/79 [04:58<08:32, 10.24s/it, train_loss=0.2489]\u001b[A\n",
      "Epoch 2/10:  37%|████▍       | 29/79 [05:08<08:32, 10.24s/it, train_loss=0.2501]\u001b[A\n",
      "Epoch 2/10:  38%|████▌       | 30/79 [05:09<08:23, 10.28s/it, train_loss=0.2501]\u001b[A\n",
      "Epoch 2/10:  38%|████▌       | 30/79 [05:19<08:23, 10.28s/it, train_loss=0.2537]\u001b[A\n",
      "Epoch 2/10:  39%|████▋       | 31/79 [05:19<08:12, 10.26s/it, train_loss=0.2537]\u001b[A\n",
      "Epoch 2/10:  39%|████▋       | 31/79 [05:29<08:12, 10.26s/it, train_loss=0.2531]\u001b[A\n",
      "Epoch 2/10:  41%|████▊       | 32/79 [05:29<08:01, 10.25s/it, train_loss=0.2531]\u001b[A\n",
      "Epoch 2/10:  41%|████▊       | 32/79 [05:39<08:01, 10.25s/it, train_loss=0.2499]\u001b[A\n",
      "Epoch 2/10:  42%|█████       | 33/79 [05:39<07:50, 10.23s/it, train_loss=0.2499]\u001b[A\n",
      "Epoch 2/10:  42%|█████       | 33/79 [05:49<07:50, 10.23s/it, train_loss=0.2518]\u001b[A\n",
      "Epoch 2/10:  43%|█████▏      | 34/79 [05:50<07:40, 10.22s/it, train_loss=0.2518]\u001b[A\n",
      "Epoch 2/10:  43%|█████▏      | 34/79 [05:59<07:40, 10.22s/it, train_loss=0.2508]\u001b[A\n",
      "Epoch 2/10:  44%|█████▎      | 35/79 [06:00<07:29, 10.22s/it, train_loss=0.2508]\u001b[A\n",
      "Epoch 2/10:  44%|█████▎      | 35/79 [06:10<07:29, 10.22s/it, train_loss=0.2524]\u001b[A\n",
      "Epoch 2/10:  46%|█████▍      | 36/79 [06:10<07:18, 10.19s/it, train_loss=0.2524]\u001b[A\n",
      "Epoch 2/10:  46%|█████▍      | 36/79 [06:20<07:18, 10.19s/it, train_loss=0.2514]\u001b[A\n",
      "Epoch 2/10:  47%|█████▌      | 37/79 [06:20<07:07, 10.18s/it, train_loss=0.2514]\u001b[A\n",
      "Epoch 2/10:  47%|█████▌      | 37/79 [06:30<07:07, 10.18s/it, train_loss=0.2534]\u001b[A\n",
      "Epoch 2/10:  48%|█████▊      | 38/79 [06:30<06:58, 10.21s/it, train_loss=0.2534]\u001b[A\n",
      "Epoch 2/10:  48%|█████▊      | 38/79 [06:40<06:58, 10.21s/it, train_loss=0.2537]\u001b[A\n",
      "Epoch 2/10:  49%|█████▉      | 39/79 [06:41<06:50, 10.25s/it, train_loss=0.2537]\u001b[A\n",
      "Epoch 2/10:  49%|█████▉      | 39/79 [06:51<06:50, 10.25s/it, train_loss=0.2574]\u001b[A\n",
      "Epoch 2/10:  51%|██████      | 40/79 [06:51<06:39, 10.25s/it, train_loss=0.2574]\u001b[A\n",
      "Epoch 2/10:  51%|██████      | 40/79 [07:01<06:39, 10.25s/it, train_loss=0.2565]\u001b[A\n",
      "Epoch 2/10:  52%|██████▏     | 41/79 [07:01<06:30, 10.29s/it, train_loss=0.2565]\u001b[A\n",
      "Epoch 2/10:  52%|██████▏     | 41/79 [07:11<06:30, 10.29s/it, train_loss=0.2551]\u001b[A\n",
      "Epoch 2/10:  53%|██████▍     | 42/79 [07:11<06:19, 10.26s/it, train_loss=0.2551]\u001b[A\n",
      "Epoch 2/10:  53%|██████▍     | 42/79 [07:21<06:19, 10.26s/it, train_loss=0.2565]\u001b[A\n",
      "Epoch 2/10:  54%|██████▌     | 43/79 [07:22<06:08, 10.23s/it, train_loss=0.2565]\u001b[A\n",
      "Epoch 2/10:  54%|██████▌     | 43/79 [07:31<06:08, 10.23s/it, train_loss=0.2547]\u001b[A\n",
      "Epoch 2/10:  56%|██████▋     | 44/79 [07:32<05:56, 10.20s/it, train_loss=0.2547]\u001b[A\n",
      "Epoch 2/10:  56%|██████▋     | 44/79 [07:42<05:56, 10.20s/it, train_loss=0.2534]\u001b[A\n",
      "Epoch 2/10:  57%|██████▊     | 45/79 [07:42<05:46, 10.18s/it, train_loss=0.2534]\u001b[A\n",
      "Epoch 2/10:  57%|██████▊     | 45/79 [07:52<05:46, 10.18s/it, train_loss=0.2511]\u001b[A\n",
      "Epoch 2/10:  58%|██████▉     | 46/79 [07:52<05:35, 10.16s/it, train_loss=0.2511]\u001b[A\n",
      "Epoch 2/10:  58%|██████▉     | 46/79 [08:02<05:35, 10.16s/it, train_loss=0.2506]\u001b[A\n",
      "Epoch 2/10:  59%|███████▏    | 47/79 [08:02<05:25, 10.18s/it, train_loss=0.2506]\u001b[A\n",
      "Epoch 2/10:  59%|███████▏    | 47/79 [08:12<05:25, 10.18s/it, train_loss=0.2502]\u001b[A\n",
      "Epoch 2/10:  61%|███████▎    | 48/79 [08:13<05:17, 10.23s/it, train_loss=0.2502]\u001b[A\n",
      "Epoch 2/10:  61%|███████▎    | 48/79 [08:23<05:17, 10.23s/it, train_loss=0.2493]\u001b[A\n",
      "Epoch 2/10:  62%|███████▍    | 49/79 [08:23<05:09, 10.30s/it, train_loss=0.2493]\u001b[A\n",
      "Epoch 2/10:  62%|███████▍    | 49/79 [08:33<05:09, 10.30s/it, train_loss=0.2483]\u001b[A\n",
      "Epoch 2/10:  63%|███████▌    | 50/79 [08:33<04:57, 10.26s/it, train_loss=0.2483]\u001b[A\n",
      "Epoch 2/10:  63%|███████▌    | 50/79 [08:43<04:57, 10.26s/it, train_loss=0.2463]\u001b[A\n",
      "Epoch 2/10:  65%|███████▋    | 51/79 [08:43<04:46, 10.22s/it, train_loss=0.2463]\u001b[A\n",
      "Epoch 2/10:  65%|███████▋    | 51/79 [08:53<04:46, 10.22s/it, train_loss=0.2459]\u001b[A\n",
      "Epoch 2/10:  66%|███████▉    | 52/79 [08:54<04:36, 10.25s/it, train_loss=0.2459]\u001b[A\n",
      "Epoch 2/10:  66%|███████▉    | 52/79 [09:03<04:36, 10.25s/it, train_loss=0.2443]\u001b[A\n",
      "Epoch 2/10:  67%|████████    | 53/79 [09:04<04:25, 10.19s/it, train_loss=0.2443]\u001b[A\n",
      "Epoch 2/10:  67%|████████    | 53/79 [09:14<04:25, 10.19s/it, train_loss=0.2442]\u001b[A\n",
      "Epoch 2/10:  68%|████████▏   | 54/79 [09:14<04:14, 10.18s/it, train_loss=0.2442]\u001b[A\n",
      "Epoch 2/10:  68%|████████▏   | 54/79 [09:24<04:14, 10.18s/it, train_loss=0.2442]\u001b[A\n",
      "Epoch 2/10:  70%|████████▎   | 55/79 [09:24<04:03, 10.15s/it, train_loss=0.2442]\u001b[A\n",
      "Epoch 2/10:  70%|████████▎   | 55/79 [09:34<04:03, 10.15s/it, train_loss=0.2464]\u001b[A\n",
      "Epoch 2/10:  71%|████████▌   | 56/79 [09:34<03:53, 10.15s/it, train_loss=0.2464]\u001b[A\n",
      "Epoch 2/10:  71%|████████▌   | 56/79 [09:44<03:53, 10.15s/it, train_loss=0.2468]\u001b[A\n",
      "Epoch 2/10:  72%|████████▋   | 57/79 [09:45<03:45, 10.25s/it, train_loss=0.2468]\u001b[A\n",
      "Epoch 2/10:  72%|████████▋   | 57/79 [09:55<03:45, 10.25s/it, train_loss=0.2474]\u001b[A\n",
      "Epoch 2/10:  73%|████████▊   | 58/79 [09:55<03:36, 10.31s/it, train_loss=0.2474]\u001b[A\n",
      "Epoch 2/10:  73%|████████▊   | 58/79 [10:05<03:36, 10.31s/it, train_loss=0.2468]\u001b[A\n",
      "Epoch 2/10:  75%|████████▉   | 59/79 [10:05<03:26, 10.30s/it, train_loss=0.2468]\u001b[A\n",
      "Epoch 2/10:  75%|████████▉   | 59/79 [10:15<03:26, 10.30s/it, train_loss=0.2460]\u001b[A\n",
      "Epoch 2/10:  76%|█████████   | 60/79 [10:16<03:15, 10.28s/it, train_loss=0.2460]\u001b[A\n",
      "Epoch 2/10:  76%|█████████   | 60/79 [10:25<03:15, 10.28s/it, train_loss=0.2470]\u001b[A\n",
      "Epoch 2/10:  77%|█████████▎  | 61/79 [10:26<03:04, 10.25s/it, train_loss=0.2470]\u001b[A\n",
      "Epoch 2/10:  77%|█████████▎  | 61/79 [10:36<03:04, 10.25s/it, train_loss=0.2459]\u001b[A\n",
      "Epoch 2/10:  78%|█████████▍  | 62/79 [10:36<02:53, 10.20s/it, train_loss=0.2459]\u001b[A\n",
      "Epoch 2/10:  78%|█████████▍  | 62/79 [10:46<02:53, 10.20s/it, train_loss=0.2478]\u001b[A\n",
      "Epoch 2/10:  80%|█████████▌  | 63/79 [10:46<02:42, 10.15s/it, train_loss=0.2478]\u001b[A\n",
      "Epoch 2/10:  80%|█████████▌  | 63/79 [10:56<02:42, 10.15s/it, train_loss=0.2489]\u001b[A\n",
      "Epoch 2/10:  81%|█████████▋  | 64/79 [10:56<02:33, 10.22s/it, train_loss=0.2489]\u001b[A\n",
      "Epoch 2/10:  81%|█████████▋  | 64/79 [11:06<02:33, 10.22s/it, train_loss=0.2499]\u001b[A\n",
      "Epoch 2/10:  82%|█████████▊  | 65/79 [11:06<02:22, 10.19s/it, train_loss=0.2499]\u001b[A\n",
      "Epoch 2/10:  82%|█████████▊  | 65/79 [11:16<02:22, 10.19s/it, train_loss=0.2494]\u001b[A\n",
      "Epoch 2/10:  84%|██████████  | 66/79 [11:16<02:12, 10.18s/it, train_loss=0.2494]\u001b[A\n",
      "Epoch 2/10:  84%|██████████  | 66/79 [11:27<02:12, 10.18s/it, train_loss=0.2490]\u001b[A\n",
      "Epoch 2/10:  85%|██████████▏ | 67/79 [11:27<02:03, 10.25s/it, train_loss=0.2490]\u001b[A\n",
      "Epoch 2/10:  85%|██████████▏ | 67/79 [11:37<02:03, 10.25s/it, train_loss=0.2485]\u001b[A\n",
      "Epoch 2/10:  86%|██████████▎ | 68/79 [11:37<01:52, 10.25s/it, train_loss=0.2485]\u001b[A\n",
      "Epoch 2/10:  86%|██████████▎ | 68/79 [11:47<01:52, 10.25s/it, train_loss=0.2473]\u001b[A\n",
      "Epoch 2/10:  87%|██████████▍ | 69/79 [11:48<01:42, 10.28s/it, train_loss=0.2473]\u001b[A\n",
      "Epoch 2/10:  87%|██████████▍ | 69/79 [11:58<01:42, 10.28s/it, train_loss=0.2456]\u001b[A\n",
      "Epoch 2/10:  89%|██████████▋ | 70/79 [11:58<01:32, 10.27s/it, train_loss=0.2456]\u001b[A\n",
      "Epoch 2/10:  89%|██████████▋ | 70/79 [12:08<01:32, 10.27s/it, train_loss=0.2449]\u001b[A\n",
      "Epoch 2/10:  90%|██████████▊ | 71/79 [12:08<01:22, 10.26s/it, train_loss=0.2449]\u001b[A\n",
      "Epoch 2/10:  90%|██████████▊ | 71/79 [12:18<01:22, 10.26s/it, train_loss=0.2446]\u001b[A\n",
      "Epoch 2/10:  91%|██████████▉ | 72/79 [12:18<01:11, 10.22s/it, train_loss=0.2446]\u001b[A\n",
      "Epoch 2/10:  91%|██████████▉ | 72/79 [12:28<01:11, 10.22s/it, train_loss=0.2435]\u001b[A\n",
      "Epoch 2/10:  92%|███████████ | 73/79 [12:28<01:01, 10.21s/it, train_loss=0.2435]\u001b[A\n",
      "Epoch 2/10:  92%|███████████ | 73/79 [12:38<01:01, 10.21s/it, train_loss=0.2419]\u001b[A\n",
      "Epoch 2/10:  94%|███████████▏| 74/79 [12:39<00:51, 10.22s/it, train_loss=0.2419]\u001b[A\n",
      "Epoch 2/10:  94%|███████████▏| 74/79 [12:48<00:51, 10.22s/it, train_loss=0.2415]\u001b[A\n",
      "Epoch 2/10:  95%|███████████▍| 75/79 [12:49<00:40, 10.18s/it, train_loss=0.2415]\u001b[A\n",
      "Epoch 2/10:  95%|███████████▍| 75/79 [12:59<00:40, 10.18s/it, train_loss=0.2416]\u001b[A\n",
      "Epoch 2/10:  96%|███████████▌| 76/79 [12:59<00:30, 10.19s/it, train_loss=0.2416]\u001b[A\n",
      "Epoch 2/10:  96%|███████████▌| 76/79 [13:09<00:30, 10.19s/it, train_loss=0.2404]\u001b[A\n",
      "Epoch 2/10:  97%|███████████▋| 77/79 [13:09<00:20, 10.17s/it, train_loss=0.2404]\u001b[A\n",
      "Epoch 2/10:  97%|███████████▋| 77/79 [13:19<00:20, 10.17s/it, train_loss=0.2400]\u001b[A\n",
      "Epoch 2/10:  99%|███████████▊| 78/79 [13:20<00:10, 10.30s/it, train_loss=0.2400]\u001b[A\n",
      "Epoch 2/10:  99%|███████████▊| 78/79 [13:21<00:10, 10.30s/it, train_loss=1.9035]\u001b[A\n",
      "Epoch 2/10: 100%|████████████| 79/79 [13:22<00:00,  7.79s/it, train_loss=1.9035]\u001b[A\n",
      "Overall:  20%|██████▍                         | 2/10 [28:13<1:53:17, 849.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 • Train loss=0.2406 (802.0s) • Val Acc=0.9190 • Prec=0.9182 • Recall=0.9125 • F1=0.9154 • AUC=0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10:   0%|                                        | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3/10:   0%|                     | 0/79 [00:10<?, ?it/s, train_loss=0.1169]\u001b[A\n",
      "Epoch 3/10:   1%|▏            | 1/79 [00:10<13:44, 10.57s/it, train_loss=0.1169]\u001b[A\n",
      "Epoch 3/10:   1%|▏            | 1/79 [00:20<13:44, 10.57s/it, train_loss=0.1413]\u001b[A\n",
      "Epoch 3/10:   3%|▎            | 2/79 [00:20<13:15, 10.34s/it, train_loss=0.1413]\u001b[A\n",
      "Epoch 3/10:   3%|▎            | 2/79 [00:30<13:15, 10.34s/it, train_loss=0.1418]\u001b[A\n",
      "Epoch 3/10:   4%|▍            | 3/79 [00:30<12:59, 10.26s/it, train_loss=0.1418]\u001b[A\n",
      "Epoch 3/10:   4%|▍            | 3/79 [00:40<12:59, 10.26s/it, train_loss=0.1522]\u001b[A\n",
      "Epoch 3/10:   5%|▋            | 4/79 [00:41<12:47, 10.24s/it, train_loss=0.1522]\u001b[A\n",
      "Epoch 3/10:   5%|▋            | 4/79 [00:51<12:47, 10.24s/it, train_loss=0.1490]\u001b[A\n",
      "Epoch 3/10:   6%|▊            | 5/79 [00:51<12:36, 10.22s/it, train_loss=0.1490]\u001b[A\n",
      "Epoch 3/10:   6%|▊            | 5/79 [01:01<12:36, 10.22s/it, train_loss=0.1802]\u001b[A\n",
      "Epoch 3/10:   8%|▉            | 6/79 [01:01<12:28, 10.25s/it, train_loss=0.1802]\u001b[A\n",
      "Epoch 3/10:   8%|▉            | 6/79 [01:11<12:28, 10.25s/it, train_loss=0.1921]\u001b[A\n",
      "Epoch 3/10:   9%|█▏           | 7/79 [01:12<12:26, 10.37s/it, train_loss=0.1921]\u001b[A\n",
      "Epoch 3/10:   9%|█▏           | 7/79 [01:22<12:26, 10.37s/it, train_loss=0.1953]\u001b[A\n",
      "Epoch 3/10:  10%|█▎           | 8/79 [01:22<12:11, 10.30s/it, train_loss=0.1953]\u001b[A\n",
      "Epoch 3/10:  10%|█▎           | 8/79 [01:32<12:11, 10.30s/it, train_loss=0.1960]\u001b[A\n",
      "Epoch 3/10:  11%|█▍           | 9/79 [01:33<12:08, 10.41s/it, train_loss=0.1960]\u001b[A\n",
      "Epoch 3/10:  11%|█▍           | 9/79 [01:42<12:08, 10.41s/it, train_loss=0.1993]\u001b[A\n",
      "Epoch 3/10:  13%|█▌          | 10/79 [01:43<11:51, 10.32s/it, train_loss=0.1993]\u001b[A\n",
      "Epoch 3/10:  13%|█▌          | 10/79 [01:53<11:51, 10.32s/it, train_loss=0.1952]\u001b[A\n",
      "Epoch 3/10:  14%|█▋          | 11/79 [01:53<11:37, 10.26s/it, train_loss=0.1952]\u001b[A\n",
      "Epoch 3/10:  14%|█▋          | 11/79 [02:03<11:37, 10.26s/it, train_loss=0.2027]\u001b[A\n",
      "Epoch 3/10:  15%|█▊          | 12/79 [02:03<11:34, 10.37s/it, train_loss=0.2027]\u001b[A\n",
      "Epoch 3/10:  15%|█▊          | 12/79 [02:13<11:34, 10.37s/it, train_loss=0.2087]\u001b[A\n",
      "Epoch 3/10:  16%|█▉          | 13/79 [02:14<11:21, 10.32s/it, train_loss=0.2087]\u001b[A\n",
      "Epoch 3/10:  16%|█▉          | 13/79 [02:24<11:21, 10.32s/it, train_loss=0.2083]\u001b[A\n",
      "Epoch 3/10:  18%|██▏         | 14/79 [02:24<11:08, 10.29s/it, train_loss=0.2083]\u001b[A\n",
      "Epoch 3/10:  18%|██▏         | 14/79 [02:34<11:08, 10.29s/it, train_loss=0.2077]\u001b[A\n",
      "Epoch 3/10:  19%|██▎         | 15/79 [02:34<10:57, 10.27s/it, train_loss=0.2077]\u001b[A\n",
      "Epoch 3/10:  19%|██▎         | 15/79 [02:44<10:57, 10.27s/it, train_loss=0.2128]\u001b[A\n",
      "Epoch 3/10:  20%|██▍         | 16/79 [02:44<10:46, 10.26s/it, train_loss=0.2128]\u001b[A\n",
      "Epoch 3/10:  20%|██▍         | 16/79 [02:54<10:46, 10.26s/it, train_loss=0.2217]\u001b[A\n",
      "Epoch 3/10:  22%|██▌         | 17/79 [02:55<10:39, 10.31s/it, train_loss=0.2217]\u001b[A\n",
      "Epoch 3/10:  22%|██▌         | 17/79 [03:05<10:39, 10.31s/it, train_loss=0.2208]\u001b[A\n",
      "Epoch 3/10:  23%|██▋         | 18/79 [03:05<10:29, 10.32s/it, train_loss=0.2208]\u001b[A\n",
      "Epoch 3/10:  23%|██▋         | 18/79 [03:15<10:29, 10.32s/it, train_loss=0.2300]\u001b[A\n",
      "Epoch 3/10:  24%|██▉         | 19/79 [03:15<10:20, 10.34s/it, train_loss=0.2300]\u001b[A\n",
      "Epoch 3/10:  24%|██▉         | 19/79 [03:25<10:20, 10.34s/it, train_loss=0.2252]\u001b[A\n",
      "Epoch 3/10:  25%|███         | 20/79 [03:26<10:08, 10.31s/it, train_loss=0.2252]\u001b[A\n",
      "Epoch 3/10:  25%|███         | 20/79 [03:36<10:08, 10.31s/it, train_loss=0.2296]\u001b[A\n",
      "Epoch 3/10:  27%|███▏        | 21/79 [03:36<09:55, 10.26s/it, train_loss=0.2296]\u001b[A\n",
      "Epoch 3/10:  27%|███▏        | 21/79 [03:46<09:55, 10.26s/it, train_loss=0.2320]\u001b[A\n",
      "Epoch 3/10:  28%|███▎        | 22/79 [03:46<09:45, 10.28s/it, train_loss=0.2320]\u001b[A\n",
      "Epoch 3/10:  28%|███▎        | 22/79 [03:56<09:45, 10.28s/it, train_loss=0.2336]\u001b[A\n",
      "Epoch 3/10:  29%|███▍        | 23/79 [03:56<09:33, 10.25s/it, train_loss=0.2336]\u001b[A\n",
      "Epoch 3/10:  29%|███▍        | 23/79 [04:06<09:33, 10.25s/it, train_loss=0.2335]\u001b[A\n",
      "Epoch 3/10:  30%|███▋        | 24/79 [04:07<09:23, 10.24s/it, train_loss=0.2335]\u001b[A\n",
      "Epoch 3/10:  30%|███▋        | 24/79 [04:16<09:23, 10.24s/it, train_loss=0.2299]\u001b[A\n",
      "Epoch 3/10:  32%|███▊        | 25/79 [04:17<09:10, 10.20s/it, train_loss=0.2299]\u001b[A\n",
      "Epoch 3/10:  32%|███▊        | 25/79 [04:27<09:10, 10.20s/it, train_loss=0.2288]\u001b[A\n",
      "Epoch 3/10:  33%|███▉        | 26/79 [04:27<09:04, 10.28s/it, train_loss=0.2288]\u001b[A\n",
      "Epoch 3/10:  33%|███▉        | 26/79 [04:37<09:04, 10.28s/it, train_loss=0.2272]\u001b[A\n",
      "Epoch 3/10:  34%|████        | 27/79 [04:37<08:50, 10.20s/it, train_loss=0.2272]\u001b[A\n",
      "Epoch 3/10:  34%|████        | 27/79 [04:47<08:50, 10.20s/it, train_loss=0.2303]\u001b[A\n",
      "Epoch 3/10:  35%|████▎       | 28/79 [04:47<08:40, 10.20s/it, train_loss=0.2303]\u001b[A\n",
      "Epoch 3/10:  35%|████▎       | 28/79 [04:58<08:40, 10.20s/it, train_loss=0.2327]\u001b[A\n",
      "Epoch 3/10:  37%|████▍       | 29/79 [04:58<08:34, 10.29s/it, train_loss=0.2327]\u001b[A\n",
      "Epoch 3/10:  37%|████▍       | 29/79 [05:08<08:34, 10.29s/it, train_loss=0.2318]\u001b[A\n",
      "Epoch 3/10:  38%|████▌       | 30/79 [05:08<08:25, 10.31s/it, train_loss=0.2318]\u001b[A\n",
      "Epoch 3/10:  38%|████▌       | 30/79 [05:18<08:25, 10.31s/it, train_loss=0.2326]\u001b[A\n",
      "Epoch 3/10:  39%|████▋       | 31/79 [05:18<08:13, 10.27s/it, train_loss=0.2326]\u001b[A\n",
      "Epoch 3/10:  39%|████▋       | 31/79 [05:28<08:13, 10.27s/it, train_loss=0.2318]\u001b[A\n",
      "Epoch 3/10:  41%|████▊       | 32/79 [05:29<08:00, 10.23s/it, train_loss=0.2318]\u001b[A\n",
      "Epoch 3/10:  41%|████▊       | 32/79 [05:38<08:00, 10.23s/it, train_loss=0.2288]\u001b[A\n",
      "Epoch 3/10:  42%|█████       | 33/79 [05:39<07:49, 10.20s/it, train_loss=0.2288]\u001b[A\n",
      "Epoch 3/10:  42%|█████       | 33/79 [05:49<07:49, 10.20s/it, train_loss=0.2283]\u001b[A\n",
      "Epoch 3/10:  43%|█████▏      | 34/79 [05:49<07:40, 10.23s/it, train_loss=0.2283]\u001b[A\n",
      "Epoch 3/10:  43%|█████▏      | 34/79 [05:59<07:40, 10.23s/it, train_loss=0.2278]\u001b[A\n",
      "Epoch 3/10:  44%|█████▎      | 35/79 [05:59<07:33, 10.30s/it, train_loss=0.2278]\u001b[A\n",
      "Epoch 3/10:  44%|█████▎      | 35/79 [06:09<07:33, 10.30s/it, train_loss=0.2277]\u001b[A\n",
      "Epoch 3/10:  46%|█████▍      | 36/79 [06:10<07:20, 10.24s/it, train_loss=0.2277]\u001b[A\n",
      "Epoch 3/10:  46%|█████▍      | 36/79 [06:19<07:20, 10.24s/it, train_loss=0.2281]\u001b[A\n",
      "Epoch 3/10:  47%|█████▌      | 37/79 [06:20<07:08, 10.21s/it, train_loss=0.2281]\u001b[A\n",
      "Epoch 3/10:  47%|█████▌      | 37/79 [06:30<07:08, 10.21s/it, train_loss=0.2260]\u001b[A\n",
      "Epoch 3/10:  48%|█████▊      | 38/79 [06:30<06:58, 10.20s/it, train_loss=0.2260]\u001b[A\n",
      "Epoch 3/10:  48%|█████▊      | 38/79 [06:40<06:58, 10.20s/it, train_loss=0.2268]\u001b[A\n",
      "Epoch 3/10:  49%|█████▉      | 39/79 [06:40<06:48, 10.21s/it, train_loss=0.2268]\u001b[A\n",
      "Epoch 3/10:  49%|█████▉      | 39/79 [06:50<06:48, 10.21s/it, train_loss=0.2273]\u001b[A\n",
      "Epoch 3/10:  51%|██████      | 40/79 [06:50<06:39, 10.24s/it, train_loss=0.2273]\u001b[A\n",
      "Epoch 3/10:  51%|██████      | 40/79 [07:00<06:39, 10.24s/it, train_loss=0.2266]\u001b[A\n",
      "Epoch 3/10:  52%|██████▏     | 41/79 [07:01<06:28, 10.23s/it, train_loss=0.2266]\u001b[A\n",
      "Epoch 3/10:  52%|██████▏     | 41/79 [07:10<06:28, 10.23s/it, train_loss=0.2251]\u001b[A\n",
      "Epoch 3/10:  53%|██████▍     | 42/79 [07:11<06:17, 10.19s/it, train_loss=0.2251]\u001b[A\n",
      "Epoch 3/10:  53%|██████▍     | 42/79 [07:21<06:17, 10.19s/it, train_loss=0.2242]\u001b[A\n",
      "Epoch 3/10:  54%|██████▌     | 43/79 [07:21<06:08, 10.23s/it, train_loss=0.2242]\u001b[A\n",
      "Epoch 3/10:  54%|██████▌     | 43/79 [07:31<06:08, 10.23s/it, train_loss=0.2255]\u001b[A\n",
      "Epoch 3/10:  56%|██████▋     | 44/79 [07:31<05:57, 10.20s/it, train_loss=0.2255]\u001b[A\n",
      "Epoch 3/10:  56%|██████▋     | 44/79 [07:41<05:57, 10.20s/it, train_loss=0.2258]\u001b[A\n",
      "Epoch 3/10:  57%|██████▊     | 45/79 [07:41<05:46, 10.18s/it, train_loss=0.2258]\u001b[A\n",
      "Epoch 3/10:  57%|██████▊     | 45/79 [07:51<05:46, 10.18s/it, train_loss=0.2266]\u001b[A\n",
      "Epoch 3/10:  58%|██████▉     | 46/79 [07:51<05:36, 10.20s/it, train_loss=0.2266]\u001b[A\n",
      "Epoch 3/10:  58%|██████▉     | 46/79 [08:01<05:36, 10.20s/it, train_loss=0.2258]\u001b[A\n",
      "Epoch 3/10:  59%|███████▏    | 47/79 [08:02<05:26, 10.20s/it, train_loss=0.2258]\u001b[A\n",
      "Epoch 3/10:  59%|███████▏    | 47/79 [08:12<05:26, 10.20s/it, train_loss=0.2279]\u001b[A\n",
      "Epoch 3/10:  61%|███████▎    | 48/79 [08:12<05:16, 10.22s/it, train_loss=0.2279]\u001b[A\n",
      "Epoch 3/10:  61%|███████▎    | 48/79 [08:22<05:16, 10.22s/it, train_loss=0.2258]\u001b[A\n",
      "Epoch 3/10:  62%|███████▍    | 49/79 [08:22<05:06, 10.22s/it, train_loss=0.2258]\u001b[A\n",
      "Epoch 3/10:  62%|███████▍    | 49/79 [08:32<05:06, 10.22s/it, train_loss=0.2247]\u001b[A\n",
      "Epoch 3/10:  63%|███████▌    | 50/79 [08:32<04:56, 10.24s/it, train_loss=0.2247]\u001b[A\n",
      "Epoch 3/10:  63%|███████▌    | 50/79 [08:42<04:56, 10.24s/it, train_loss=0.2246]\u001b[A\n",
      "Epoch 3/10:  65%|███████▋    | 51/79 [08:43<04:46, 10.22s/it, train_loss=0.2246]\u001b[A\n",
      "Epoch 3/10:  65%|███████▋    | 51/79 [08:53<04:46, 10.22s/it, train_loss=0.2224]\u001b[A\n",
      "Epoch 3/10:  66%|███████▉    | 52/79 [08:53<04:35, 10.20s/it, train_loss=0.2224]\u001b[A\n",
      "Epoch 3/10:  66%|███████▉    | 52/79 [09:03<04:35, 10.20s/it, train_loss=0.2224]\u001b[A\n",
      "Epoch 3/10:  67%|████████    | 53/79 [09:03<04:27, 10.27s/it, train_loss=0.2224]\u001b[A\n",
      "Epoch 3/10:  67%|████████    | 53/79 [09:13<04:27, 10.27s/it, train_loss=0.2211]\u001b[A\n",
      "Epoch 3/10:  68%|████████▏   | 54/79 [09:14<04:17, 10.31s/it, train_loss=0.2211]\u001b[A\n",
      "Epoch 3/10:  68%|████████▏   | 54/79 [09:24<04:17, 10.31s/it, train_loss=0.2203]\u001b[A\n",
      "Epoch 3/10:  70%|████████▎   | 55/79 [09:24<04:06, 10.27s/it, train_loss=0.2203]\u001b[A\n",
      "Epoch 3/10:  70%|████████▎   | 55/79 [09:34<04:06, 10.27s/it, train_loss=0.2199]\u001b[A\n",
      "Epoch 3/10:  71%|████████▌   | 56/79 [09:34<03:55, 10.24s/it, train_loss=0.2199]\u001b[A\n",
      "Epoch 3/10:  71%|████████▌   | 56/79 [09:44<03:55, 10.24s/it, train_loss=0.2183]\u001b[A\n",
      "Epoch 3/10:  72%|████████▋   | 57/79 [09:44<03:46, 10.28s/it, train_loss=0.2183]\u001b[A\n",
      "Epoch 3/10:  72%|████████▋   | 57/79 [09:54<03:46, 10.28s/it, train_loss=0.2190]\u001b[A\n",
      "Epoch 3/10:  73%|████████▊   | 58/79 [09:55<03:35, 10.27s/it, train_loss=0.2190]\u001b[A\n",
      "Epoch 3/10:  73%|████████▊   | 58/79 [10:05<03:35, 10.27s/it, train_loss=0.2184]\u001b[A\n",
      "Epoch 3/10:  75%|████████▉   | 59/79 [10:05<03:26, 10.30s/it, train_loss=0.2184]\u001b[A\n",
      "Epoch 3/10:  75%|████████▉   | 59/79 [10:15<03:26, 10.30s/it, train_loss=0.2192]\u001b[A\n",
      "Epoch 3/10:  76%|█████████   | 60/79 [10:15<03:14, 10.24s/it, train_loss=0.2192]\u001b[A\n",
      "Epoch 3/10:  76%|█████████   | 60/79 [10:25<03:14, 10.24s/it, train_loss=0.2183]\u001b[A\n",
      "Epoch 3/10:  77%|█████████▎  | 61/79 [10:25<03:04, 10.27s/it, train_loss=0.2183]\u001b[A\n",
      "Epoch 3/10:  77%|█████████▎  | 61/79 [10:35<03:04, 10.27s/it, train_loss=0.2175]\u001b[A\n",
      "Epoch 3/10:  78%|█████████▍  | 62/79 [10:36<02:54, 10.26s/it, train_loss=0.2175]\u001b[A\n",
      "Epoch 3/10:  78%|█████████▍  | 62/79 [10:46<02:54, 10.26s/it, train_loss=0.2181]\u001b[A\n",
      "Epoch 3/10:  80%|█████████▌  | 63/79 [10:46<02:43, 10.24s/it, train_loss=0.2181]\u001b[A\n",
      "Epoch 3/10:  80%|█████████▌  | 63/79 [10:56<02:43, 10.24s/it, train_loss=0.2163]\u001b[A\n",
      "Epoch 3/10:  81%|█████████▋  | 64/79 [10:56<02:33, 10.25s/it, train_loss=0.2163]\u001b[A\n",
      "Epoch 3/10:  81%|█████████▋  | 64/79 [11:06<02:33, 10.25s/it, train_loss=0.2156]\u001b[A\n",
      "Epoch 3/10:  82%|█████████▊  | 65/79 [11:06<02:23, 10.24s/it, train_loss=0.2156]\u001b[A\n",
      "Epoch 3/10:  82%|█████████▊  | 65/79 [11:16<02:23, 10.24s/it, train_loss=0.2142]\u001b[A\n",
      "Epoch 3/10:  84%|██████████  | 66/79 [11:17<02:12, 10.22s/it, train_loss=0.2142]\u001b[A\n",
      "Epoch 3/10:  84%|██████████  | 66/79 [11:27<02:12, 10.22s/it, train_loss=0.2145]\u001b[A\n",
      "Epoch 3/10:  85%|██████████▏ | 67/79 [11:27<02:02, 10.23s/it, train_loss=0.2145]\u001b[A\n",
      "Epoch 3/10:  85%|██████████▏ | 67/79 [11:37<02:02, 10.23s/it, train_loss=0.2144]\u001b[A\n",
      "Epoch 3/10:  86%|██████████▎ | 68/79 [11:37<01:52, 10.20s/it, train_loss=0.2144]\u001b[A\n",
      "Epoch 3/10:  86%|██████████▎ | 68/79 [11:47<01:52, 10.20s/it, train_loss=0.2147]\u001b[A\n",
      "Epoch 3/10:  87%|██████████▍ | 69/79 [11:47<01:41, 10.19s/it, train_loss=0.2147]\u001b[A\n",
      "Epoch 3/10:  87%|██████████▍ | 69/79 [11:57<01:41, 10.19s/it, train_loss=0.2138]\u001b[A\n",
      "Epoch 3/10:  89%|██████████▋ | 70/79 [11:57<01:31, 10.21s/it, train_loss=0.2138]\u001b[A\n",
      "Epoch 3/10:  89%|██████████▋ | 70/79 [12:07<01:31, 10.21s/it, train_loss=0.2140]\u001b[A\n",
      "Epoch 3/10:  90%|██████████▊ | 71/79 [12:08<01:21, 10.21s/it, train_loss=0.2140]\u001b[A\n",
      "Epoch 3/10:  90%|██████████▊ | 71/79 [12:18<01:21, 10.21s/it, train_loss=0.2141]\u001b[A\n",
      "Epoch 3/10:  91%|██████████▉ | 72/79 [12:18<01:11, 10.24s/it, train_loss=0.2141]\u001b[A\n",
      "Epoch 3/10:  91%|██████████▉ | 72/79 [12:28<01:11, 10.24s/it, train_loss=0.2138]\u001b[A\n",
      "Epoch 3/10:  92%|███████████ | 73/79 [12:28<01:01, 10.23s/it, train_loss=0.2138]\u001b[A\n",
      "Epoch 3/10:  92%|███████████ | 73/79 [12:38<01:01, 10.23s/it, train_loss=0.2130]\u001b[A\n",
      "Epoch 3/10:  94%|███████████▏| 74/79 [12:38<00:51, 10.25s/it, train_loss=0.2130]\u001b[A\n",
      "Epoch 3/10:  94%|███████████▏| 74/79 [12:48<00:51, 10.25s/it, train_loss=0.2125]\u001b[A\n",
      "Epoch 3/10:  95%|███████████▍| 75/79 [12:49<00:40, 10.22s/it, train_loss=0.2125]\u001b[A\n",
      "Epoch 3/10:  95%|███████████▍| 75/79 [12:59<00:40, 10.22s/it, train_loss=0.2125]\u001b[A\n",
      "Epoch 3/10:  96%|███████████▌| 76/79 [12:59<00:30, 10.28s/it, train_loss=0.2125]\u001b[A\n",
      "Epoch 3/10:  96%|███████████▌| 76/79 [13:09<00:30, 10.28s/it, train_loss=0.2118]\u001b[A\n",
      "Epoch 3/10:  97%|███████████▋| 77/79 [13:09<00:20, 10.27s/it, train_loss=0.2118]\u001b[A\n",
      "Epoch 3/10:  97%|███████████▋| 77/79 [13:19<00:20, 10.27s/it, train_loss=0.2113]\u001b[A\n",
      "Epoch 3/10:  99%|███████████▊| 78/79 [13:19<00:10, 10.19s/it, train_loss=0.2113]\u001b[A\n",
      "Epoch 3/10:  99%|███████████▊| 78/79 [13:21<00:10, 10.19s/it, train_loss=1.6729]\u001b[A\n",
      "Epoch 3/10: 100%|████████████| 79/79 [13:21<00:00,  7.65s/it, train_loss=1.6729]\u001b[A\n",
      "Overall:  30%|█████████▌                      | 3/10 [42:39<1:39:59, 857.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 • Train loss=0.2115 (801.4s) • Val Acc=0.9180 • Prec=0.9146 • Recall=0.9146 • F1=0.9146 • AUC=0.9759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10:   0%|                                        | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4/10:   0%|                     | 0/79 [00:10<?, ?it/s, train_loss=0.2839]\u001b[A\n",
      "Epoch 4/10:   1%|▏            | 1/79 [00:10<14:03, 10.82s/it, train_loss=0.2839]\u001b[A\n",
      "Epoch 4/10:   1%|▏            | 1/79 [00:20<14:03, 10.82s/it, train_loss=0.2290]\u001b[A\n",
      "Epoch 4/10:   3%|▎            | 2/79 [00:21<13:26, 10.48s/it, train_loss=0.2290]\u001b[A\n",
      "Epoch 4/10:   3%|▎            | 2/79 [00:31<13:26, 10.48s/it, train_loss=0.2144]\u001b[A\n",
      "Epoch 4/10:   4%|▍            | 3/79 [00:31<13:09, 10.39s/it, train_loss=0.2144]\u001b[A\n",
      "Epoch 4/10:   4%|▍            | 3/79 [00:41<13:09, 10.39s/it, train_loss=0.1920]\u001b[A\n",
      "Epoch 4/10:   5%|▋            | 4/79 [00:41<12:55, 10.34s/it, train_loss=0.1920]\u001b[A\n",
      "Epoch 4/10:   5%|▋            | 4/79 [00:51<12:55, 10.34s/it, train_loss=0.1808]\u001b[A\n",
      "Epoch 4/10:   6%|▊            | 5/79 [00:51<12:44, 10.33s/it, train_loss=0.1808]\u001b[A\n",
      "Epoch 4/10:   6%|▊            | 5/79 [01:01<12:44, 10.33s/it, train_loss=0.1705]\u001b[A\n",
      "Epoch 4/10:   8%|▉            | 6/79 [01:02<12:33, 10.32s/it, train_loss=0.1705]\u001b[A\n",
      "Epoch 4/10:   8%|▉            | 6/79 [01:12<12:33, 10.32s/it, train_loss=0.1704]\u001b[A\n",
      "Epoch 4/10:   9%|█▏           | 7/79 [01:12<12:18, 10.25s/it, train_loss=0.1704]\u001b[A\n",
      "Epoch 4/10:   9%|█▏           | 7/79 [01:22<12:18, 10.25s/it, train_loss=0.1679]\u001b[A\n",
      "Epoch 4/10:  10%|█▎           | 8/79 [01:22<12:07, 10.25s/it, train_loss=0.1679]\u001b[A\n",
      "Epoch 4/10:  10%|█▎           | 8/79 [01:32<12:07, 10.25s/it, train_loss=0.1723]\u001b[A\n",
      "Epoch 4/10:  11%|█▍           | 9/79 [01:32<11:57, 10.25s/it, train_loss=0.1723]\u001b[A\n",
      "Epoch 4/10:  11%|█▍           | 9/79 [01:42<11:57, 10.25s/it, train_loss=0.1673]\u001b[A\n",
      "Epoch 4/10:  13%|█▌          | 10/79 [01:42<11:45, 10.22s/it, train_loss=0.1673]\u001b[A\n",
      "Epoch 4/10:  13%|█▌          | 10/79 [01:52<11:45, 10.22s/it, train_loss=0.1735]\u001b[A\n",
      "Epoch 4/10:  14%|█▋          | 11/79 [01:53<11:35, 10.23s/it, train_loss=0.1735]\u001b[A\n",
      "Epoch 4/10:  14%|█▋          | 11/79 [02:03<11:35, 10.23s/it, train_loss=0.1766]\u001b[A\n",
      "Epoch 4/10:  15%|█▊          | 12/79 [02:03<11:25, 10.24s/it, train_loss=0.1766]\u001b[A\n",
      "Epoch 4/10:  15%|█▊          | 12/79 [02:13<11:25, 10.24s/it, train_loss=0.1772]\u001b[A\n",
      "Epoch 4/10:  16%|█▉          | 13/79 [02:13<11:14, 10.22s/it, train_loss=0.1772]\u001b[A\n",
      "Epoch 4/10:  16%|█▉          | 13/79 [02:23<11:14, 10.22s/it, train_loss=0.1774]\u001b[A\n",
      "Epoch 4/10:  18%|██▏         | 14/79 [02:23<11:05, 10.23s/it, train_loss=0.1774]\u001b[A\n",
      "Epoch 4/10:  18%|██▏         | 14/79 [02:33<11:05, 10.23s/it, train_loss=0.1731]\u001b[A\n",
      "Epoch 4/10:  19%|██▎         | 15/79 [02:34<10:53, 10.22s/it, train_loss=0.1731]\u001b[A\n",
      "Epoch 4/10:  19%|██▎         | 15/79 [02:44<10:53, 10.22s/it, train_loss=0.1816]\u001b[A\n",
      "Epoch 4/10:  20%|██▍         | 16/79 [02:44<10:48, 10.29s/it, train_loss=0.1816]\u001b[A\n",
      "Epoch 4/10:  20%|██▍         | 16/79 [02:54<10:48, 10.29s/it, train_loss=0.1853]\u001b[A\n",
      "Epoch 4/10:  22%|██▌         | 17/79 [02:54<10:35, 10.25s/it, train_loss=0.1853]\u001b[A\n",
      "Epoch 4/10:  22%|██▌         | 17/79 [03:04<10:35, 10.25s/it, train_loss=0.1848]\u001b[A\n",
      "Epoch 4/10:  23%|██▋         | 18/79 [03:04<10:22, 10.21s/it, train_loss=0.1848]\u001b[A\n",
      "Epoch 4/10:  23%|██▋         | 18/79 [03:14<10:22, 10.21s/it, train_loss=0.1906]\u001b[A\n",
      "Epoch 4/10:  24%|██▉         | 19/79 [03:15<10:12, 10.21s/it, train_loss=0.1906]\u001b[A\n",
      "Epoch 4/10:  24%|██▉         | 19/79 [03:25<10:12, 10.21s/it, train_loss=0.1927]\u001b[A\n",
      "Epoch 4/10:  25%|███         | 20/79 [03:25<10:02, 10.21s/it, train_loss=0.1927]\u001b[A\n",
      "Epoch 4/10:  25%|███         | 20/79 [03:35<10:02, 10.21s/it, train_loss=0.1935]\u001b[A\n",
      "Epoch 4/10:  27%|███▏        | 21/79 [03:35<09:51, 10.20s/it, train_loss=0.1935]\u001b[A\n",
      "Epoch 4/10:  27%|███▏        | 21/79 [03:45<09:51, 10.20s/it, train_loss=0.1913]\u001b[A\n",
      "Epoch 4/10:  28%|███▎        | 22/79 [03:45<09:46, 10.30s/it, train_loss=0.1913]\u001b[A\n",
      "Epoch 4/10:  28%|███▎        | 22/79 [03:55<09:46, 10.30s/it, train_loss=0.1938]\u001b[A\n",
      "Epoch 4/10:  29%|███▍        | 23/79 [03:56<09:34, 10.26s/it, train_loss=0.1938]\u001b[A\n",
      "Epoch 4/10:  29%|███▍        | 23/79 [04:06<09:34, 10.26s/it, train_loss=0.1935]\u001b[A\n",
      "Epoch 4/10:  30%|███▋        | 24/79 [04:06<09:22, 10.23s/it, train_loss=0.1935]\u001b[A\n",
      "Epoch 4/10:  30%|███▋        | 24/79 [04:16<09:22, 10.23s/it, train_loss=0.1910]\u001b[A\n",
      "Epoch 4/10:  32%|███▊        | 25/79 [04:16<09:12, 10.24s/it, train_loss=0.1910]\u001b[A\n",
      "Epoch 4/10:  32%|███▊        | 25/79 [04:26<09:12, 10.24s/it, train_loss=0.1897]\u001b[A\n",
      "Epoch 4/10:  33%|███▉        | 26/79 [04:26<09:01, 10.21s/it, train_loss=0.1897]\u001b[A\n",
      "Epoch 4/10:  33%|███▉        | 26/79 [04:36<09:01, 10.21s/it, train_loss=0.1890]\u001b[A\n",
      "Epoch 4/10:  34%|████        | 27/79 [04:37<08:56, 10.31s/it, train_loss=0.1890]\u001b[A\n",
      "Epoch 4/10:  34%|████        | 27/79 [04:47<08:56, 10.31s/it, train_loss=0.1909]\u001b[A\n",
      "Epoch 4/10:  35%|████▎       | 28/79 [04:47<08:45, 10.31s/it, train_loss=0.1909]\u001b[A\n",
      "Epoch 4/10:  35%|████▎       | 28/79 [04:57<08:45, 10.31s/it, train_loss=0.1898]\u001b[A\n",
      "Epoch 4/10:  37%|████▍       | 29/79 [04:57<08:33, 10.27s/it, train_loss=0.1898]\u001b[A\n",
      "Epoch 4/10:  37%|████▍       | 29/79 [05:07<08:33, 10.27s/it, train_loss=0.1902]\u001b[A\n",
      "Epoch 4/10:  38%|████▌       | 30/79 [05:07<08:23, 10.27s/it, train_loss=0.1902]\u001b[A\n",
      "Epoch 4/10:  38%|████▌       | 30/79 [05:17<08:23, 10.27s/it, train_loss=0.1883]\u001b[A\n",
      "Epoch 4/10:  39%|████▋       | 31/79 [05:18<08:12, 10.26s/it, train_loss=0.1883]\u001b[A\n",
      "Epoch 4/10:  39%|████▋       | 31/79 [05:28<08:12, 10.26s/it, train_loss=0.1900]\u001b[A\n",
      "Epoch 4/10:  41%|████▊       | 32/79 [05:28<08:05, 10.34s/it, train_loss=0.1900]\u001b[A\n",
      "Epoch 4/10:  41%|████▊       | 32/79 [05:38<08:05, 10.34s/it, train_loss=0.1916]\u001b[A\n",
      "Epoch 4/10:  42%|█████       | 33/79 [05:39<07:54, 10.31s/it, train_loss=0.1916]\u001b[A\n",
      "Epoch 4/10:  42%|█████       | 33/79 [05:48<07:54, 10.31s/it, train_loss=0.1932]\u001b[A\n",
      "Epoch 4/10:  43%|█████▏      | 34/79 [05:49<07:42, 10.27s/it, train_loss=0.1932]\u001b[A\n",
      "Epoch 4/10:  43%|█████▏      | 34/79 [05:59<07:42, 10.27s/it, train_loss=0.1926]\u001b[A\n",
      "Epoch 4/10:  44%|█████▎      | 35/79 [05:59<07:31, 10.25s/it, train_loss=0.1926]\u001b[A\n",
      "Epoch 4/10:  44%|█████▎      | 35/79 [06:09<07:31, 10.25s/it, train_loss=0.1913]\u001b[A\n",
      "Epoch 4/10:  46%|█████▍      | 36/79 [06:09<07:18, 10.21s/it, train_loss=0.1913]\u001b[A\n",
      "Epoch 4/10:  46%|█████▍      | 36/79 [06:19<07:18, 10.21s/it, train_loss=0.1926]\u001b[A\n",
      "Epoch 4/10:  47%|█████▌      | 37/79 [06:19<07:09, 10.23s/it, train_loss=0.1926]\u001b[A\n",
      "Epoch 4/10:  47%|█████▌      | 37/79 [06:29<07:09, 10.23s/it, train_loss=0.1936]\u001b[A\n",
      "Epoch 4/10:  48%|█████▊      | 38/79 [06:30<06:59, 10.23s/it, train_loss=0.1936]\u001b[A\n",
      "Epoch 4/10:  48%|█████▊      | 38/79 [06:39<06:59, 10.23s/it, train_loss=0.1951]\u001b[A\n",
      "Epoch 4/10:  49%|█████▉      | 39/79 [06:40<06:48, 10.21s/it, train_loss=0.1951]\u001b[A\n",
      "Epoch 4/10:  49%|█████▉      | 39/79 [06:50<06:48, 10.21s/it, train_loss=0.1966]\u001b[A\n",
      "Epoch 4/10:  51%|██████      | 40/79 [06:50<06:38, 10.22s/it, train_loss=0.1966]\u001b[A\n",
      "Epoch 4/10:  51%|██████      | 40/79 [07:00<06:38, 10.22s/it, train_loss=0.1962]\u001b[A\n",
      "Epoch 4/10:  52%|██████▏     | 41/79 [07:00<06:30, 10.27s/it, train_loss=0.1962]\u001b[A\n",
      "Epoch 4/10:  52%|██████▏     | 41/79 [07:10<06:30, 10.27s/it, train_loss=0.1966]\u001b[A\n",
      "Epoch 4/10:  53%|██████▍     | 42/79 [07:11<06:19, 10.27s/it, train_loss=0.1966]\u001b[A\n",
      "Epoch 4/10:  53%|██████▍     | 42/79 [07:21<06:19, 10.27s/it, train_loss=0.1951]\u001b[A\n",
      "Epoch 4/10:  54%|██████▌     | 43/79 [07:21<06:09, 10.26s/it, train_loss=0.1951]\u001b[A\n",
      "Epoch 4/10:  54%|██████▌     | 43/79 [07:31<06:09, 10.26s/it, train_loss=0.1950]\u001b[A\n",
      "Epoch 4/10:  56%|██████▋     | 44/79 [07:31<05:58, 10.26s/it, train_loss=0.1950]\u001b[A\n",
      "Epoch 4/10:  56%|██████▋     | 44/79 [07:41<05:58, 10.26s/it, train_loss=0.1948]\u001b[A\n",
      "Epoch 4/10:  57%|██████▊     | 45/79 [07:41<05:47, 10.23s/it, train_loss=0.1948]\u001b[A\n",
      "Epoch 4/10:  57%|██████▊     | 45/79 [07:51<05:47, 10.23s/it, train_loss=0.1934]\u001b[A\n",
      "Epoch 4/10:  58%|██████▉     | 46/79 [07:51<05:36, 10.19s/it, train_loss=0.1934]\u001b[A\n",
      "Epoch 4/10:  58%|██████▉     | 46/79 [08:01<05:36, 10.19s/it, train_loss=0.1947]\u001b[A\n",
      "Epoch 4/10:  59%|███████▏    | 47/79 [08:02<05:26, 10.20s/it, train_loss=0.1947]\u001b[A\n",
      "Epoch 4/10:  59%|███████▏    | 47/79 [08:12<05:26, 10.20s/it, train_loss=0.1968]\u001b[A\n",
      "Epoch 4/10:  61%|███████▎    | 48/79 [08:12<05:16, 10.23s/it, train_loss=0.1968]\u001b[A\n",
      "Epoch 4/10:  61%|███████▎    | 48/79 [08:22<05:16, 10.23s/it, train_loss=0.1977]\u001b[A\n",
      "Epoch 4/10:  62%|███████▍    | 49/79 [08:22<05:06, 10.21s/it, train_loss=0.1977]\u001b[A\n",
      "Epoch 4/10:  62%|███████▍    | 49/79 [08:32<05:06, 10.21s/it, train_loss=0.1972]\u001b[A\n",
      "Epoch 4/10:  63%|███████▌    | 50/79 [08:32<04:56, 10.21s/it, train_loss=0.1972]\u001b[A\n",
      "Epoch 4/10:  63%|███████▌    | 50/79 [08:42<04:56, 10.21s/it, train_loss=0.1954]\u001b[A\n",
      "Epoch 4/10:  65%|███████▋    | 51/79 [08:42<04:45, 10.19s/it, train_loss=0.1954]\u001b[A\n",
      "Epoch 4/10:  65%|███████▋    | 51/79 [08:52<04:45, 10.19s/it, train_loss=0.1958]\u001b[A\n",
      "Epoch 4/10:  66%|███████▉    | 52/79 [08:53<04:35, 10.21s/it, train_loss=0.1958]\u001b[A\n",
      "Epoch 4/10:  66%|███████▉    | 52/79 [09:03<04:35, 10.21s/it, train_loss=0.1949]\u001b[A\n",
      "Epoch 4/10:  67%|████████    | 53/79 [09:03<04:25, 10.22s/it, train_loss=0.1949]\u001b[A\n",
      "Epoch 4/10:  67%|████████    | 53/79 [09:13<04:25, 10.22s/it, train_loss=0.1972]\u001b[A\n",
      "Epoch 4/10:  68%|████████▏   | 54/79 [09:13<04:15, 10.20s/it, train_loss=0.1972]\u001b[A\n",
      "Epoch 4/10:  68%|████████▏   | 54/79 [09:23<04:15, 10.20s/it, train_loss=0.1984]\u001b[A\n",
      "Epoch 4/10:  70%|████████▎   | 55/79 [09:23<04:05, 10.23s/it, train_loss=0.1984]\u001b[A\n",
      "Epoch 4/10:  70%|████████▎   | 55/79 [09:33<04:05, 10.23s/it, train_loss=0.1984]\u001b[A\n",
      "Epoch 4/10:  71%|████████▌   | 56/79 [09:34<03:55, 10.24s/it, train_loss=0.1984]\u001b[A\n",
      "Epoch 4/10:  71%|████████▌   | 56/79 [09:44<03:55, 10.24s/it, train_loss=0.1977]\u001b[A\n",
      "Epoch 4/10:  72%|████████▋   | 57/79 [09:44<03:45, 10.26s/it, train_loss=0.1977]\u001b[A\n",
      "Epoch 4/10:  72%|████████▋   | 57/79 [09:54<03:45, 10.26s/it, train_loss=0.1995]\u001b[A\n",
      "Epoch 4/10:  73%|████████▊   | 58/79 [09:54<03:35, 10.25s/it, train_loss=0.1995]\u001b[A\n",
      "Epoch 4/10:  73%|████████▊   | 58/79 [10:04<03:35, 10.25s/it, train_loss=0.2003]\u001b[A\n",
      "Epoch 4/10:  75%|████████▉   | 59/79 [10:04<03:25, 10.25s/it, train_loss=0.2003]\u001b[A\n",
      "Epoch 4/10:  75%|████████▉   | 59/79 [10:14<03:25, 10.25s/it, train_loss=0.2001]\u001b[A\n",
      "Epoch 4/10:  76%|█████████   | 60/79 [10:15<03:14, 10.24s/it, train_loss=0.2001]\u001b[A\n",
      "Epoch 4/10:  76%|█████████   | 60/79 [10:25<03:14, 10.24s/it, train_loss=0.2011]\u001b[A\n",
      "Epoch 4/10:  77%|█████████▎  | 61/79 [10:25<03:04, 10.24s/it, train_loss=0.2011]\u001b[A\n",
      "Epoch 4/10:  77%|█████████▎  | 61/79 [10:35<03:04, 10.24s/it, train_loss=0.1999]\u001b[A\n",
      "Epoch 4/10:  78%|█████████▍  | 62/79 [10:35<02:54, 10.26s/it, train_loss=0.1999]\u001b[A\n",
      "Epoch 4/10:  78%|█████████▍  | 62/79 [10:45<02:54, 10.26s/it, train_loss=0.2007]\u001b[A\n",
      "Epoch 4/10:  80%|█████████▌  | 63/79 [10:45<02:44, 10.26s/it, train_loss=0.2007]\u001b[A\n",
      "Epoch 4/10:  80%|█████████▌  | 63/79 [10:56<02:44, 10.26s/it, train_loss=0.2008]\u001b[A\n",
      "Epoch 4/10:  81%|█████████▋  | 64/79 [10:56<02:35, 10.37s/it, train_loss=0.2008]\u001b[A\n",
      "Epoch 4/10:  81%|█████████▋  | 64/79 [11:06<02:35, 10.37s/it, train_loss=0.2020]\u001b[A\n",
      "Epoch 4/10:  82%|█████████▊  | 65/79 [11:06<02:25, 10.39s/it, train_loss=0.2020]\u001b[A\n",
      "Epoch 4/10:  82%|█████████▊  | 65/79 [11:16<02:25, 10.39s/it, train_loss=0.2017]\u001b[A\n",
      "Epoch 4/10:  84%|██████████  | 66/79 [11:17<02:14, 10.33s/it, train_loss=0.2017]\u001b[A\n",
      "Epoch 4/10:  84%|██████████  | 66/79 [11:27<02:14, 10.33s/it, train_loss=0.2023]\u001b[A\n",
      "Epoch 4/10:  85%|██████████▏ | 67/79 [11:27<02:03, 10.29s/it, train_loss=0.2023]\u001b[A\n",
      "Epoch 4/10:  85%|██████████▏ | 67/79 [11:37<02:03, 10.29s/it, train_loss=0.2014]\u001b[A\n",
      "Epoch 4/10:  86%|██████████▎ | 68/79 [11:37<01:53, 10.30s/it, train_loss=0.2014]\u001b[A\n",
      "Epoch 4/10:  86%|██████████▎ | 68/79 [11:47<01:53, 10.30s/it, train_loss=0.2019]\u001b[A\n",
      "Epoch 4/10:  87%|██████████▍ | 69/79 [11:47<01:42, 10.28s/it, train_loss=0.2019]\u001b[A\n",
      "Epoch 4/10:  87%|██████████▍ | 69/79 [11:57<01:42, 10.28s/it, train_loss=0.2007]\u001b[A\n",
      "Epoch 4/10:  89%|██████████▋ | 70/79 [11:58<01:32, 10.30s/it, train_loss=0.2007]\u001b[A\n",
      "Epoch 4/10:  89%|██████████▋ | 70/79 [12:08<01:32, 10.30s/it, train_loss=0.1990]\u001b[A\n",
      "Epoch 4/10:  90%|██████████▊ | 71/79 [12:08<01:22, 10.26s/it, train_loss=0.1990]\u001b[A\n",
      "Epoch 4/10:  90%|██████████▊ | 71/79 [12:18<01:22, 10.26s/it, train_loss=0.1990]\u001b[A\n",
      "Epoch 4/10:  91%|██████████▉ | 72/79 [12:18<01:11, 10.26s/it, train_loss=0.1990]\u001b[A\n",
      "Epoch 4/10:  91%|██████████▉ | 72/79 [12:28<01:11, 10.26s/it, train_loss=0.1992]\u001b[A\n",
      "Epoch 4/10:  92%|███████████ | 73/79 [12:28<01:01, 10.26s/it, train_loss=0.1992]\u001b[A\n",
      "Epoch 4/10:  92%|███████████ | 73/79 [12:38<01:01, 10.26s/it, train_loss=0.1980]\u001b[A\n",
      "Epoch 4/10:  94%|███████████▏| 74/79 [12:39<00:51, 10.25s/it, train_loss=0.1980]\u001b[A\n",
      "Epoch 4/10:  94%|███████████▏| 74/79 [12:49<00:51, 10.25s/it, train_loss=0.1979]\u001b[A\n",
      "Epoch 4/10:  95%|███████████▍| 75/79 [12:49<00:40, 10.22s/it, train_loss=0.1979]\u001b[A\n",
      "Epoch 4/10:  95%|███████████▍| 75/79 [12:59<00:40, 10.22s/it, train_loss=0.1972]\u001b[A\n",
      "Epoch 4/10:  96%|███████████▌| 76/79 [12:59<00:30, 10.23s/it, train_loss=0.1972]\u001b[A\n",
      "Epoch 4/10:  96%|███████████▌| 76/79 [13:09<00:30, 10.23s/it, train_loss=0.1965]\u001b[A\n",
      "Epoch 4/10:  97%|███████████▋| 77/79 [13:09<00:20, 10.21s/it, train_loss=0.1965]\u001b[A\n",
      "Epoch 4/10:  97%|███████████▋| 77/79 [13:19<00:20, 10.21s/it, train_loss=0.1954]\u001b[A\n",
      "Epoch 4/10:  99%|███████████▊| 78/79 [13:20<00:10, 10.24s/it, train_loss=0.1954]\u001b[A\n",
      "Epoch 4/10:  99%|███████████▊| 78/79 [13:21<00:10, 10.24s/it, train_loss=1.5472]\u001b[A\n",
      "Epoch 4/10: 100%|████████████| 79/79 [13:21<00:00,  7.69s/it, train_loss=1.5472]\u001b[A\n",
      "Overall:  40%|████████████▊                   | 4/10 [57:04<1:26:01, 860.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 • Train loss=0.1956 (801.7s) • Val Acc=0.9190 • Prec=0.9030 • Recall=0.9313 • F1=0.9169 • AUC=0.9761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10:   0%|                                        | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5/10:   0%|                     | 0/79 [00:10<?, ?it/s, train_loss=0.3572]\u001b[A\n",
      "Epoch 5/10:   1%|▏            | 1/79 [00:10<13:56, 10.72s/it, train_loss=0.3572]\u001b[A\n",
      "Epoch 5/10:   1%|▏            | 1/79 [00:20<13:56, 10.72s/it, train_loss=0.3136]\u001b[A\n",
      "Epoch 5/10:   3%|▎            | 2/79 [00:21<13:31, 10.54s/it, train_loss=0.3136]\u001b[A\n",
      "Epoch 5/10:   3%|▎            | 2/79 [00:31<13:31, 10.54s/it, train_loss=0.2788]\u001b[A\n",
      "Epoch 5/10:   4%|▍            | 3/79 [00:31<13:12, 10.42s/it, train_loss=0.2788]\u001b[A\n",
      "Epoch 5/10:   4%|▍            | 3/79 [00:41<13:12, 10.42s/it, train_loss=0.2453]\u001b[A\n",
      "Epoch 5/10:   5%|▋            | 4/79 [00:41<13:01, 10.43s/it, train_loss=0.2453]\u001b[A\n",
      "Epoch 5/10:   5%|▋            | 4/79 [00:52<13:01, 10.43s/it, train_loss=0.2225]\u001b[A\n",
      "Epoch 5/10:   6%|▊            | 5/79 [00:52<12:54, 10.46s/it, train_loss=0.2225]\u001b[A\n",
      "Epoch 5/10:   6%|▊            | 5/79 [01:02<12:54, 10.46s/it, train_loss=0.2081]\u001b[A\n",
      "Epoch 5/10:   8%|▉            | 6/79 [01:02<12:45, 10.49s/it, train_loss=0.2081]\u001b[A\n",
      "Epoch 5/10:   8%|▉            | 6/79 [01:12<12:45, 10.49s/it, train_loss=0.2072]\u001b[A\n",
      "Epoch 5/10:   9%|█▏           | 7/79 [01:13<12:30, 10.42s/it, train_loss=0.2072]\u001b[A\n",
      "Epoch 5/10:   9%|█▏           | 7/79 [01:23<12:30, 10.42s/it, train_loss=0.1984]\u001b[A\n",
      "Epoch 5/10:  10%|█▎           | 8/79 [01:23<12:17, 10.39s/it, train_loss=0.1984]\u001b[A\n",
      "Epoch 5/10:  10%|█▎           | 8/79 [01:33<12:17, 10.39s/it, train_loss=0.1967]\u001b[A\n",
      "Epoch 5/10:  11%|█▍           | 9/79 [01:33<12:03, 10.33s/it, train_loss=0.1967]\u001b[A\n",
      "Epoch 5/10:  11%|█▍           | 9/79 [01:43<12:03, 10.33s/it, train_loss=0.1977]\u001b[A\n",
      "Epoch 5/10:  13%|█▌          | 10/79 [01:43<11:50, 10.29s/it, train_loss=0.1977]\u001b[A\n",
      "Epoch 5/10:  13%|█▌          | 10/79 [01:53<11:50, 10.29s/it, train_loss=0.1931]\u001b[A\n",
      "Epoch 5/10:  14%|█▋          | 11/79 [01:54<11:40, 10.30s/it, train_loss=0.1931]\u001b[A\n",
      "Epoch 5/10:  14%|█▋          | 11/79 [02:04<11:40, 10.30s/it, train_loss=0.1954]\u001b[A\n",
      "Epoch 5/10:  15%|█▊          | 12/79 [02:04<11:33, 10.34s/it, train_loss=0.1954]\u001b[A\n",
      "Epoch 5/10:  15%|█▊          | 12/79 [02:16<11:33, 10.34s/it, train_loss=0.1894]\u001b[A\n",
      "Epoch 5/10:  16%|█▉          | 13/79 [02:16<11:47, 10.72s/it, train_loss=0.1894]\u001b[A\n",
      "Epoch 5/10:  16%|█▉          | 13/79 [02:26<11:47, 10.72s/it, train_loss=0.1896]\u001b[A\n",
      "Epoch 5/10:  18%|██▏         | 14/79 [02:26<11:34, 10.69s/it, train_loss=0.1896]\u001b[A\n",
      "Epoch 5/10:  18%|██▏         | 14/79 [02:37<11:34, 10.69s/it, train_loss=0.1848]\u001b[A\n",
      "Epoch 5/10:  19%|██▎         | 15/79 [02:38<11:35, 10.87s/it, train_loss=0.1848]\u001b[A\n",
      "Epoch 5/10:  19%|██▎         | 15/79 [02:49<11:35, 10.87s/it, train_loss=0.1851]\u001b[A\n",
      "Epoch 5/10:  20%|██▍         | 16/79 [02:49<11:42, 11.15s/it, train_loss=0.1851]\u001b[A\n",
      "Epoch 5/10:  20%|██▍         | 16/79 [03:02<11:42, 11.15s/it, train_loss=0.1826]\u001b[A\n",
      "Epoch 5/10:  22%|██▌         | 17/79 [03:03<12:06, 11.71s/it, train_loss=0.1826]\u001b[A\n",
      "Epoch 5/10:  22%|██▌         | 17/79 [03:15<12:06, 11.71s/it, train_loss=0.1825]\u001b[A\n",
      "Epoch 5/10:  23%|██▋         | 18/79 [03:15<12:17, 12.09s/it, train_loss=0.1825]\u001b[A\n",
      "Epoch 5/10:  23%|██▋         | 18/79 [03:29<12:17, 12.09s/it, train_loss=0.1821]\u001b[A\n",
      "Epoch 5/10:  24%|██▉         | 19/79 [03:29<12:35, 12.59s/it, train_loss=0.1821]\u001b[A\n",
      "Epoch 5/10:  24%|██▉         | 19/79 [03:42<12:35, 12.59s/it, train_loss=0.1807]\u001b[A\n",
      "Epoch 5/10:  25%|███         | 20/79 [03:42<12:28, 12.69s/it, train_loss=0.1807]\u001b[A\n",
      "Epoch 5/10:  25%|███         | 20/79 [03:53<12:28, 12.69s/it, train_loss=0.1787]\u001b[A\n",
      "Epoch 5/10:  27%|███▏        | 21/79 [03:54<11:54, 12.32s/it, train_loss=0.1787]\u001b[A\n",
      "Epoch 5/10:  27%|███▏        | 21/79 [04:05<11:54, 12.32s/it, train_loss=0.1804]\u001b[A\n",
      "Epoch 5/10:  28%|███▎        | 22/79 [04:05<11:27, 12.05s/it, train_loss=0.1804]\u001b[A\n",
      "Epoch 5/10:  28%|███▎        | 22/79 [04:16<11:27, 12.05s/it, train_loss=0.1767]\u001b[A\n",
      "Epoch 5/10:  29%|███▍        | 23/79 [04:16<10:58, 11.76s/it, train_loss=0.1767]\u001b[A\n",
      "Epoch 5/10:  29%|███▍        | 23/79 [04:27<10:58, 11.76s/it, train_loss=0.1763]\u001b[A\n",
      "Epoch 5/10:  30%|███▋        | 24/79 [04:27<10:34, 11.54s/it, train_loss=0.1763]\u001b[A\n",
      "Epoch 5/10:  30%|███▋        | 24/79 [04:38<10:34, 11.54s/it, train_loss=0.1754]\u001b[A\n",
      "Epoch 5/10:  32%|███▊        | 25/79 [04:38<10:13, 11.37s/it, train_loss=0.1754]\u001b[A\n",
      "Epoch 5/10:  32%|███▊        | 25/79 [04:49<10:13, 11.37s/it, train_loss=0.1771]\u001b[A\n",
      "Epoch 5/10:  33%|███▉        | 26/79 [04:49<09:55, 11.24s/it, train_loss=0.1771]\u001b[A\n",
      "Epoch 5/10:  33%|███▉        | 26/79 [05:00<09:55, 11.24s/it, train_loss=0.1802]\u001b[A\n",
      "Epoch 5/10:  34%|████        | 27/79 [05:00<09:38, 11.13s/it, train_loss=0.1802]\u001b[A\n",
      "Epoch 5/10:  34%|████        | 27/79 [05:11<09:38, 11.13s/it, train_loss=0.1831]\u001b[A\n",
      "Epoch 5/10:  35%|████▎       | 28/79 [05:11<09:27, 11.12s/it, train_loss=0.1831]\u001b[A\n",
      "Epoch 5/10:  35%|████▎       | 28/79 [05:22<09:27, 11.12s/it, train_loss=0.1852]\u001b[A\n",
      "Epoch 5/10:  37%|████▍       | 29/79 [05:22<09:12, 11.05s/it, train_loss=0.1852]\u001b[A\n",
      "Epoch 5/10:  37%|████▍       | 29/79 [05:33<09:12, 11.05s/it, train_loss=0.1844]\u001b[A\n",
      "Epoch 5/10:  38%|████▌       | 30/79 [05:33<09:00, 11.03s/it, train_loss=0.1844]\u001b[A\n",
      "Epoch 5/10:  38%|████▌       | 30/79 [05:44<09:00, 11.03s/it, train_loss=0.1842]\u001b[A\n",
      "Epoch 5/10:  39%|████▋       | 31/79 [05:44<08:49, 11.03s/it, train_loss=0.1842]\u001b[A\n",
      "Epoch 5/10:  39%|████▋       | 31/79 [05:55<08:49, 11.03s/it, train_loss=0.1846]\u001b[A\n",
      "Epoch 5/10:  41%|████▊       | 32/79 [05:55<08:39, 11.05s/it, train_loss=0.1846]\u001b[A\n",
      "Epoch 5/10:  41%|████▊       | 32/79 [06:07<08:39, 11.05s/it, train_loss=0.1854]\u001b[A\n",
      "Epoch 5/10:  42%|█████       | 33/79 [06:07<08:39, 11.30s/it, train_loss=0.1854]\u001b[A\n",
      "Epoch 5/10:  42%|█████       | 33/79 [06:18<08:39, 11.30s/it, train_loss=0.1865]\u001b[A\n",
      "Epoch 5/10:  43%|█████▏      | 34/79 [06:18<08:31, 11.36s/it, train_loss=0.1865]\u001b[A\n",
      "Epoch 5/10:  43%|█████▏      | 34/79 [06:29<08:31, 11.36s/it, train_loss=0.1863]\u001b[A\n",
      "Epoch 5/10:  44%|█████▎      | 35/79 [06:30<08:19, 11.36s/it, train_loss=0.1863]\u001b[A\n",
      "Epoch 5/10:  44%|█████▎      | 35/79 [06:41<08:19, 11.36s/it, train_loss=0.1871]\u001b[A\n",
      "Epoch 5/10:  46%|█████▍      | 36/79 [06:41<08:09, 11.39s/it, train_loss=0.1871]\u001b[A\n",
      "Epoch 5/10:  46%|█████▍      | 36/79 [06:53<08:09, 11.39s/it, train_loss=0.1868]\u001b[A\n",
      "Epoch 5/10:  47%|█████▌      | 37/79 [06:53<08:06, 11.57s/it, train_loss=0.1868]\u001b[A\n",
      "Epoch 5/10:  47%|█████▌      | 37/79 [07:04<08:06, 11.57s/it, train_loss=0.1849]\u001b[A\n",
      "Epoch 5/10:  48%|█████▊      | 38/79 [07:05<07:51, 11.51s/it, train_loss=0.1849]\u001b[A\n",
      "Epoch 5/10:  48%|█████▊      | 38/79 [07:16<07:51, 11.51s/it, train_loss=0.1829]\u001b[A\n",
      "Epoch 5/10:  49%|█████▉      | 39/79 [07:16<07:37, 11.43s/it, train_loss=0.1829]\u001b[A\n",
      "Epoch 5/10:  49%|█████▉      | 39/79 [07:27<07:37, 11.43s/it, train_loss=0.1815]\u001b[A\n",
      "Epoch 5/10:  51%|██████      | 40/79 [07:27<07:27, 11.47s/it, train_loss=0.1815]\u001b[A\n",
      "Epoch 5/10:  51%|██████      | 40/79 [07:38<07:27, 11.47s/it, train_loss=0.1811]\u001b[A\n",
      "Epoch 5/10:  52%|██████▏     | 41/79 [07:39<07:13, 11.40s/it, train_loss=0.1811]\u001b[A\n",
      "Epoch 5/10:  52%|██████▏     | 41/79 [07:49<07:13, 11.40s/it, train_loss=0.1802]\u001b[A\n",
      "Epoch 5/10:  53%|██████▍     | 42/79 [07:49<06:55, 11.22s/it, train_loss=0.1802]\u001b[A\n",
      "Epoch 5/10:  53%|██████▍     | 42/79 [08:00<06:55, 11.22s/it, train_loss=0.1828]\u001b[A\n",
      "Epoch 5/10:  54%|██████▌     | 43/79 [08:00<06:41, 11.14s/it, train_loss=0.1828]\u001b[A\n",
      "Epoch 5/10:  54%|██████▌     | 43/79 [08:11<06:41, 11.14s/it, train_loss=0.1837]\u001b[A\n",
      "Epoch 5/10:  56%|██████▋     | 44/79 [08:11<06:28, 11.10s/it, train_loss=0.1837]\u001b[A\n",
      "Epoch 5/10:  56%|██████▋     | 44/79 [08:23<06:28, 11.10s/it, train_loss=0.1818]\u001b[A\n",
      "Epoch 5/10:  57%|██████▊     | 45/79 [08:23<06:21, 11.22s/it, train_loss=0.1818]\u001b[A\n",
      "Epoch 5/10:  57%|██████▊     | 45/79 [08:35<06:21, 11.22s/it, train_loss=0.1811]\u001b[A\n",
      "Epoch 5/10:  58%|██████▉     | 46/79 [08:35<06:17, 11.44s/it, train_loss=0.1811]\u001b[A\n",
      "Epoch 5/10:  58%|██████▉     | 46/79 [08:46<06:17, 11.44s/it, train_loss=0.1797]\u001b[A\n",
      "Epoch 5/10:  59%|███████▏    | 47/79 [08:47<06:10, 11.59s/it, train_loss=0.1797]\u001b[A\n",
      "Epoch 5/10:  59%|███████▏    | 47/79 [08:58<06:10, 11.59s/it, train_loss=0.1810]\u001b[A\n",
      "Epoch 5/10:  61%|███████▎    | 48/79 [08:59<06:00, 11.64s/it, train_loss=0.1810]\u001b[A\n",
      "Epoch 5/10:  61%|███████▎    | 48/79 [09:10<06:00, 11.64s/it, train_loss=0.1796]\u001b[A\n",
      "Epoch 5/10:  62%|███████▍    | 49/79 [09:10<05:48, 11.63s/it, train_loss=0.1796]\u001b[A\n",
      "Epoch 5/10:  62%|███████▍    | 49/79 [09:22<05:48, 11.63s/it, train_loss=0.1790]\u001b[A\n",
      "Epoch 5/10:  63%|███████▌    | 50/79 [09:22<05:39, 11.70s/it, train_loss=0.1790]\u001b[A\n",
      "Epoch 5/10:  63%|███████▌    | 50/79 [09:33<05:39, 11.70s/it, train_loss=0.1784]\u001b[A\n",
      "Epoch 5/10:  65%|███████▋    | 51/79 [09:34<05:26, 11.67s/it, train_loss=0.1784]\u001b[A\n",
      "Epoch 5/10:  65%|███████▋    | 51/79 [09:45<05:26, 11.67s/it, train_loss=0.1767]\u001b[A\n",
      "Epoch 5/10:  66%|███████▉    | 52/79 [09:45<05:13, 11.60s/it, train_loss=0.1767]\u001b[A\n",
      "Epoch 5/10:  66%|███████▉    | 52/79 [09:56<05:13, 11.60s/it, train_loss=0.1793]\u001b[A\n",
      "Epoch 5/10:  67%|████████    | 53/79 [09:56<04:59, 11.50s/it, train_loss=0.1793]\u001b[A\n",
      "Epoch 5/10:  67%|████████    | 53/79 [10:07<04:59, 11.50s/it, train_loss=0.1779]\u001b[A\n",
      "Epoch 5/10:  68%|████████▏   | 54/79 [10:08<04:46, 11.46s/it, train_loss=0.1779]\u001b[A\n",
      "Epoch 5/10:  68%|████████▏   | 54/79 [10:19<04:46, 11.46s/it, train_loss=0.1779]\u001b[A\n",
      "Epoch 5/10:  70%|████████▎   | 55/79 [10:19<04:34, 11.43s/it, train_loss=0.1779]\u001b[A\n",
      "Epoch 5/10:  70%|████████▎   | 55/79 [10:31<04:34, 11.43s/it, train_loss=0.1781]\u001b[A\n",
      "Epoch 5/10:  71%|████████▌   | 56/79 [10:32<04:30, 11.78s/it, train_loss=0.1781]\u001b[A\n",
      "Epoch 5/10:  71%|████████▌   | 56/79 [10:43<04:30, 11.78s/it, train_loss=0.1778]\u001b[A\n",
      "Epoch 5/10:  72%|████████▋   | 57/79 [10:43<04:18, 11.76s/it, train_loss=0.1778]\u001b[A\n",
      "Epoch 5/10:  72%|████████▋   | 57/79 [10:54<04:18, 11.76s/it, train_loss=0.1770]\u001b[A\n",
      "Epoch 5/10:  73%|████████▊   | 58/79 [10:54<04:01, 11.50s/it, train_loss=0.1770]\u001b[A\n",
      "Epoch 5/10:  73%|████████▊   | 58/79 [11:05<04:01, 11.50s/it, train_loss=0.1784]\u001b[A\n",
      "Epoch 5/10:  75%|████████▉   | 59/79 [11:06<03:50, 11.51s/it, train_loss=0.1784]\u001b[A\n",
      "Epoch 5/10:  75%|████████▉   | 59/79 [11:17<03:50, 11.51s/it, train_loss=0.1782]\u001b[A\n",
      "Epoch 5/10:  76%|█████████   | 60/79 [11:17<03:39, 11.56s/it, train_loss=0.1782]\u001b[A\n",
      "Epoch 5/10:  76%|█████████   | 60/79 [11:29<03:39, 11.56s/it, train_loss=0.1774]\u001b[A\n",
      "Epoch 5/10:  77%|█████████▎  | 61/79 [11:29<03:28, 11.59s/it, train_loss=0.1774]\u001b[A\n",
      "Epoch 5/10:  77%|█████████▎  | 61/79 [11:40<03:28, 11.59s/it, train_loss=0.1771]\u001b[A\n",
      "Epoch 5/10:  78%|█████████▍  | 62/79 [11:40<03:15, 11.51s/it, train_loss=0.1771]\u001b[A\n",
      "Epoch 5/10:  78%|█████████▍  | 62/79 [11:51<03:15, 11.51s/it, train_loss=0.1798]\u001b[A\n",
      "Epoch 5/10:  80%|█████████▌  | 63/79 [11:51<03:02, 11.38s/it, train_loss=0.1798]\u001b[A\n",
      "Epoch 5/10:  80%|█████████▌  | 63/79 [12:02<03:02, 11.38s/it, train_loss=0.1798]\u001b[A\n",
      "Epoch 5/10:  81%|█████████▋  | 64/79 [12:03<02:49, 11.33s/it, train_loss=0.1798]\u001b[A\n",
      "Epoch 5/10:  81%|█████████▋  | 64/79 [12:14<02:49, 11.33s/it, train_loss=0.1823]\u001b[A\n",
      "Epoch 5/10:  82%|█████████▊  | 65/79 [12:14<02:38, 11.35s/it, train_loss=0.1823]\u001b[A\n",
      "Epoch 5/10:  82%|█████████▊  | 65/79 [12:25<02:38, 11.35s/it, train_loss=0.1817]\u001b[A\n",
      "Epoch 5/10:  84%|██████████  | 66/79 [12:25<02:27, 11.32s/it, train_loss=0.1817]\u001b[A\n",
      "Epoch 5/10:  84%|██████████  | 66/79 [12:37<02:27, 11.32s/it, train_loss=0.1814]\u001b[A\n",
      "Epoch 5/10:  85%|██████████▏ | 67/79 [12:37<02:16, 11.40s/it, train_loss=0.1814]\u001b[A\n",
      "Epoch 5/10:  85%|██████████▏ | 67/79 [12:48<02:16, 11.40s/it, train_loss=0.1814]\u001b[A\n",
      "Epoch 5/10:  86%|██████████▎ | 68/79 [12:48<02:05, 11.40s/it, train_loss=0.1814]\u001b[A\n",
      "Epoch 5/10:  86%|██████████▎ | 68/79 [12:59<02:05, 11.40s/it, train_loss=0.1814]\u001b[A\n",
      "Epoch 5/10:  87%|██████████▍ | 69/79 [13:00<01:53, 11.35s/it, train_loss=0.1814]\u001b[A\n",
      "Epoch 5/10:  87%|██████████▍ | 69/79 [13:11<01:53, 11.35s/it, train_loss=0.1823]\u001b[A\n",
      "Epoch 5/10:  89%|██████████▋ | 70/79 [13:11<01:42, 11.40s/it, train_loss=0.1823]\u001b[A\n",
      "Epoch 5/10:  89%|██████████▋ | 70/79 [13:22<01:42, 11.40s/it, train_loss=0.1827]\u001b[A\n",
      "Epoch 5/10:  90%|██████████▊ | 71/79 [13:23<01:31, 11.43s/it, train_loss=0.1827]\u001b[A\n",
      "Epoch 5/10:  90%|██████████▊ | 71/79 [13:34<01:31, 11.43s/it, train_loss=0.1817]\u001b[A\n",
      "Epoch 5/10:  91%|██████████▉ | 72/79 [13:34<01:19, 11.37s/it, train_loss=0.1817]\u001b[A\n",
      "Epoch 5/10:  91%|██████████▉ | 72/79 [13:45<01:19, 11.37s/it, train_loss=0.1817]\u001b[A\n",
      "Epoch 5/10:  92%|███████████ | 73/79 [13:45<01:08, 11.35s/it, train_loss=0.1817]\u001b[A\n",
      "Epoch 5/10:  92%|███████████ | 73/79 [13:57<01:08, 11.35s/it, train_loss=0.1824]\u001b[A\n",
      "Epoch 5/10:  94%|███████████▏| 74/79 [13:57<00:57, 11.48s/it, train_loss=0.1824]\u001b[A\n",
      "Epoch 5/10:  94%|███████████▏| 74/79 [14:08<00:57, 11.48s/it, train_loss=0.1827]\u001b[A\n",
      "Epoch 5/10:  95%|███████████▍| 75/79 [14:09<00:46, 11.60s/it, train_loss=0.1827]\u001b[A\n",
      "Epoch 5/10:  95%|███████████▍| 75/79 [14:20<00:46, 11.60s/it, train_loss=0.1829]\u001b[A\n",
      "Epoch 5/10:  96%|███████████▌| 76/79 [14:21<00:34, 11.65s/it, train_loss=0.1829]\u001b[A\n",
      "Epoch 5/10:  96%|███████████▌| 76/79 [14:34<00:34, 11.65s/it, train_loss=0.1828]\u001b[A\n",
      "Epoch 5/10:  97%|███████████▋| 77/79 [14:35<00:24, 12.42s/it, train_loss=0.1828]\u001b[A\n",
      "Epoch 5/10:  97%|███████████▋| 77/79 [14:48<00:24, 12.42s/it, train_loss=0.1820]\u001b[A\n",
      "Epoch 5/10:  99%|███████████▊| 78/79 [14:48<00:12, 12.74s/it, train_loss=0.1820]\u001b[A\n",
      "Epoch 5/10:  99%|███████████▊| 78/79 [14:50<00:12, 12.74s/it, train_loss=1.4384]\u001b[A\n",
      "Epoch 5/10: 100%|████████████| 79/79 [14:51<00:00,  9.59s/it, train_loss=1.4384]\u001b[A\n",
      "Overall:  50%|███████████████               | 5/10 [1:13:05<1:14:42, 896.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 • Train loss=0.1818 (891.0s) • Val Acc=0.9150 • Prec=0.9072 • Recall=0.9167 • F1=0.9119 • AUC=0.9757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10:   0%|                                        | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6/10:   0%|                     | 0/79 [00:11<?, ?it/s, train_loss=0.0995]\u001b[A\n",
      "Epoch 6/10:   1%|▏            | 1/79 [00:12<15:36, 12.01s/it, train_loss=0.0995]\u001b[A\n",
      "Epoch 6/10:   1%|▏            | 1/79 [00:22<15:36, 12.01s/it, train_loss=0.1392]\u001b[A\n",
      "Epoch 6/10:   3%|▎            | 2/79 [00:22<14:26, 11.25s/it, train_loss=0.1392]\u001b[A\n",
      "Epoch 6/10:   3%|▎            | 2/79 [00:33<14:26, 11.25s/it, train_loss=0.1122]\u001b[A\n",
      "Epoch 6/10:   4%|▍            | 3/79 [00:34<14:18, 11.29s/it, train_loss=0.1122]\u001b[A\n",
      "Epoch 6/10:   4%|▍            | 3/79 [00:44<14:18, 11.29s/it, train_loss=0.1519]\u001b[A\n",
      "Epoch 6/10:   5%|▋            | 4/79 [00:45<14:01, 11.22s/it, train_loss=0.1519]\u001b[A\n",
      "Epoch 6/10:   5%|▋            | 4/79 [00:56<14:01, 11.22s/it, train_loss=0.1526]\u001b[A\n",
      "Epoch 6/10:   6%|▊            | 5/79 [00:56<13:51, 11.24s/it, train_loss=0.1526]\u001b[A\n",
      "Epoch 6/10:   6%|▊            | 5/79 [01:07<13:51, 11.24s/it, train_loss=0.1469]\u001b[A\n",
      "Epoch 6/10:   8%|▉            | 6/79 [01:08<13:52, 11.40s/it, train_loss=0.1469]\u001b[A\n",
      "Epoch 6/10:   8%|▉            | 6/79 [01:19<13:52, 11.40s/it, train_loss=0.1405]\u001b[A\n",
      "Epoch 6/10:   9%|█▏           | 7/79 [01:19<13:41, 11.41s/it, train_loss=0.1405]\u001b[A\n",
      "Epoch 6/10:   9%|█▏           | 7/79 [01:31<13:41, 11.41s/it, train_loss=0.1414]\u001b[A\n",
      "Epoch 6/10:  10%|█▎           | 8/79 [01:31<13:44, 11.62s/it, train_loss=0.1414]\u001b[A\n",
      "Epoch 6/10:  10%|█▎           | 8/79 [01:42<13:44, 11.62s/it, train_loss=0.1418]\u001b[A\n",
      "Epoch 6/10:  11%|█▍           | 9/79 [01:43<13:28, 11.55s/it, train_loss=0.1418]\u001b[A\n",
      "Epoch 6/10:  11%|█▍           | 9/79 [01:54<13:28, 11.55s/it, train_loss=0.1427]\u001b[A\n",
      "Epoch 6/10:  13%|█▌          | 10/79 [01:54<13:11, 11.47s/it, train_loss=0.1427]\u001b[A\n",
      "Epoch 6/10:  13%|█▌          | 10/79 [02:05<13:11, 11.47s/it, train_loss=0.1526]\u001b[A\n",
      "Epoch 6/10:  14%|█▋          | 11/79 [02:05<12:59, 11.46s/it, train_loss=0.1526]\u001b[A\n",
      "Epoch 6/10:  14%|█▋          | 11/79 [02:16<12:59, 11.46s/it, train_loss=0.1565]\u001b[A\n",
      "Epoch 6/10:  15%|█▊          | 12/79 [02:17<12:46, 11.43s/it, train_loss=0.1565]\u001b[A\n",
      "Epoch 6/10:  15%|█▊          | 12/79 [02:28<12:46, 11.43s/it, train_loss=0.1613]\u001b[A\n",
      "Epoch 6/10:  16%|█▉          | 13/79 [02:28<12:42, 11.55s/it, train_loss=0.1613]\u001b[A\n",
      "Epoch 6/10:  16%|█▉          | 13/79 [02:42<12:42, 11.55s/it, train_loss=0.1599]\u001b[A\n",
      "Epoch 6/10:  18%|██▏         | 14/79 [02:42<13:07, 12.11s/it, train_loss=0.1599]\u001b[A\n",
      "Epoch 6/10:  18%|██▏         | 14/79 [02:55<13:07, 12.11s/it, train_loss=0.1672]\u001b[A\n",
      "Epoch 6/10:  19%|██▎         | 15/79 [02:55<13:18, 12.47s/it, train_loss=0.1672]\u001b[A\n",
      "Epoch 6/10:  19%|██▎         | 15/79 [03:07<13:18, 12.47s/it, train_loss=0.1667]\u001b[A\n",
      "Epoch 6/10:  20%|██▍         | 16/79 [03:07<12:49, 12.21s/it, train_loss=0.1667]\u001b[A\n",
      "Epoch 6/10:  20%|██▍         | 16/79 [03:18<12:49, 12.21s/it, train_loss=0.1627]\u001b[A\n",
      "Epoch 6/10:  22%|██▌         | 17/79 [03:19<12:28, 12.07s/it, train_loss=0.1627]\u001b[A\n",
      "Epoch 6/10:  22%|██▌         | 17/79 [03:30<12:28, 12.07s/it, train_loss=0.1672]\u001b[A\n",
      "Epoch 6/10:  23%|██▋         | 18/79 [03:30<12:06, 11.92s/it, train_loss=0.1672]\u001b[A\n",
      "Epoch 6/10:  23%|██▋         | 18/79 [03:41<12:06, 11.92s/it, train_loss=0.1650]\u001b[A\n",
      "Epoch 6/10:  24%|██▉         | 19/79 [03:42<11:45, 11.76s/it, train_loss=0.1650]\u001b[A\n",
      "Epoch 6/10:  24%|██▉         | 19/79 [03:53<11:45, 11.76s/it, train_loss=0.1634]\u001b[A\n",
      "Epoch 6/10:  25%|███         | 20/79 [03:53<11:33, 11.75s/it, train_loss=0.1634]\u001b[A\n",
      "Epoch 6/10:  25%|███         | 20/79 [04:04<11:33, 11.75s/it, train_loss=0.1667]\u001b[A\n",
      "Epoch 6/10:  27%|███▏        | 21/79 [04:04<11:12, 11.59s/it, train_loss=0.1667]\u001b[A\n",
      "Epoch 6/10:  27%|███▏        | 21/79 [04:15<11:12, 11.59s/it, train_loss=0.1686]\u001b[A\n",
      "Epoch 6/10:  28%|███▎        | 22/79 [04:16<10:55, 11.50s/it, train_loss=0.1686]\u001b[A\n",
      "Epoch 6/10:  28%|███▎        | 22/79 [04:27<10:55, 11.50s/it, train_loss=0.1674]\u001b[A\n",
      "Epoch 6/10:  29%|███▍        | 23/79 [04:27<10:41, 11.46s/it, train_loss=0.1674]\u001b[A\n",
      "Epoch 6/10:  29%|███▍        | 23/79 [04:38<10:41, 11.46s/it, train_loss=0.1659]\u001b[A\n",
      "Epoch 6/10:  30%|███▋        | 24/79 [04:39<10:33, 11.52s/it, train_loss=0.1659]\u001b[A\n",
      "Epoch 6/10:  30%|███▋        | 24/79 [04:50<10:33, 11.52s/it, train_loss=0.1685]\u001b[A\n",
      "Epoch 6/10:  32%|███▊        | 25/79 [04:50<10:19, 11.47s/it, train_loss=0.1685]\u001b[A\n",
      "Epoch 6/10:  32%|███▊        | 25/79 [05:01<10:19, 11.47s/it, train_loss=0.1679]\u001b[A\n",
      "Epoch 6/10:  33%|███▉        | 26/79 [05:02<10:09, 11.51s/it, train_loss=0.1679]\u001b[A\n",
      "Epoch 6/10:  33%|███▉        | 26/79 [05:13<10:09, 11.51s/it, train_loss=0.1676]\u001b[A\n",
      "Epoch 6/10:  34%|████        | 27/79 [05:13<09:59, 11.52s/it, train_loss=0.1676]\u001b[A\n",
      "Epoch 6/10:  34%|████        | 27/79 [05:25<09:59, 11.52s/it, train_loss=0.1652]\u001b[A\n",
      "Epoch 6/10:  35%|████▎       | 28/79 [05:25<09:54, 11.65s/it, train_loss=0.1652]\u001b[A\n",
      "Epoch 6/10:  35%|████▎       | 28/79 [05:37<09:54, 11.65s/it, train_loss=0.1643]\u001b[A\n",
      "Epoch 6/10:  37%|████▍       | 29/79 [05:37<09:47, 11.75s/it, train_loss=0.1643]\u001b[A\n",
      "Epoch 6/10:  37%|████▍       | 29/79 [05:49<09:47, 11.75s/it, train_loss=0.1633]\u001b[A\n",
      "Epoch 6/10:  38%|████▌       | 30/79 [05:49<09:36, 11.77s/it, train_loss=0.1633]\u001b[A\n",
      "Epoch 6/10:  38%|████▌       | 30/79 [06:00<09:36, 11.77s/it, train_loss=0.1634]\u001b[A\n",
      "Epoch 6/10:  39%|████▋       | 31/79 [06:00<09:19, 11.67s/it, train_loss=0.1634]\u001b[A\n",
      "Epoch 6/10:  39%|████▋       | 31/79 [06:12<09:19, 11.67s/it, train_loss=0.1655]\u001b[A\n",
      "Epoch 6/10:  41%|████▊       | 32/79 [06:12<09:10, 11.71s/it, train_loss=0.1655]\u001b[A\n",
      "Epoch 6/10:  41%|████▊       | 32/79 [06:24<09:10, 11.71s/it, train_loss=0.1669]\u001b[A\n",
      "Epoch 6/10:  42%|█████       | 33/79 [06:24<09:02, 11.80s/it, train_loss=0.1669]\u001b[A\n",
      "Epoch 6/10:  42%|█████       | 33/79 [06:36<09:02, 11.80s/it, train_loss=0.1670]\u001b[A\n",
      "Epoch 6/10:  43%|█████▏      | 34/79 [06:36<08:51, 11.81s/it, train_loss=0.1670]\u001b[A\n",
      "Epoch 6/10:  43%|█████▏      | 34/79 [06:48<08:51, 11.81s/it, train_loss=0.1643]\u001b[A\n",
      "Epoch 6/10:  44%|█████▎      | 35/79 [06:48<08:40, 11.82s/it, train_loss=0.1643]\u001b[A\n",
      "Epoch 6/10:  44%|█████▎      | 35/79 [06:59<08:40, 11.82s/it, train_loss=0.1647]\u001b[A\n",
      "Epoch 6/10:  46%|█████▍      | 36/79 [07:00<08:25, 11.75s/it, train_loss=0.1647]\u001b[A\n",
      "Epoch 6/10:  46%|█████▍      | 36/79 [07:11<08:25, 11.75s/it, train_loss=0.1659]\u001b[A\n",
      "Epoch 6/10:  47%|█████▌      | 37/79 [07:11<08:09, 11.66s/it, train_loss=0.1659]\u001b[A\n",
      "Epoch 6/10:  47%|█████▌      | 37/79 [07:23<08:09, 11.66s/it, train_loss=0.1644]\u001b[A\n",
      "Epoch 6/10:  48%|█████▊      | 38/79 [07:23<08:03, 11.80s/it, train_loss=0.1644]\u001b[A\n",
      "Epoch 6/10:  48%|█████▊      | 38/79 [07:35<08:03, 11.80s/it, train_loss=0.1635]\u001b[A\n",
      "Epoch 6/10:  49%|█████▉      | 39/79 [07:35<07:53, 11.84s/it, train_loss=0.1635]\u001b[A\n",
      "Epoch 6/10:  49%|█████▉      | 39/79 [07:46<07:53, 11.84s/it, train_loss=0.1639]\u001b[A\n",
      "Epoch 6/10:  51%|██████      | 40/79 [07:47<07:38, 11.76s/it, train_loss=0.1639]\u001b[A\n",
      "Epoch 6/10:  51%|██████      | 40/79 [07:58<07:38, 11.76s/it, train_loss=0.1660]\u001b[A\n",
      "Epoch 6/10:  52%|██████▏     | 41/79 [07:59<07:30, 11.86s/it, train_loss=0.1660]\u001b[A\n",
      "Epoch 6/10:  52%|██████▏     | 41/79 [08:11<07:30, 11.86s/it, train_loss=0.1672]\u001b[A\n",
      "Epoch 6/10:  53%|██████▍     | 42/79 [08:11<07:23, 12.00s/it, train_loss=0.1672]\u001b[A\n",
      "Epoch 6/10:  53%|██████▍     | 42/79 [08:23<07:23, 12.00s/it, train_loss=0.1671]\u001b[A\n",
      "Epoch 6/10:  54%|██████▌     | 43/79 [08:24<07:19, 12.21s/it, train_loss=0.1671]\u001b[A\n",
      "Epoch 6/10:  54%|██████▌     | 43/79 [08:36<07:19, 12.21s/it, train_loss=0.1669]\u001b[A\n",
      "Epoch 6/10:  56%|██████▋     | 44/79 [08:37<07:15, 12.43s/it, train_loss=0.1669]\u001b[A\n",
      "Epoch 6/10:  56%|██████▋     | 44/79 [08:49<07:15, 12.43s/it, train_loss=0.1657]\u001b[A\n",
      "Epoch 6/10:  57%|██████▊     | 45/79 [08:49<07:01, 12.40s/it, train_loss=0.1657]\u001b[A\n",
      "Epoch 6/10:  57%|██████▊     | 45/79 [09:00<07:01, 12.40s/it, train_loss=0.1656]\u001b[A\n",
      "Epoch 6/10:  58%|██████▉     | 46/79 [09:00<06:39, 12.10s/it, train_loss=0.1656]\u001b[A\n",
      "Epoch 6/10:  58%|██████▉     | 46/79 [09:12<06:39, 12.10s/it, train_loss=0.1642]\u001b[A\n",
      "Epoch 6/10:  59%|███████▏    | 47/79 [09:12<06:25, 12.04s/it, train_loss=0.1642]\u001b[A\n",
      "Epoch 6/10:  59%|███████▏    | 47/79 [09:23<06:25, 12.04s/it, train_loss=0.1645]\u001b[A\n",
      "Epoch 6/10:  61%|███████▎    | 48/79 [09:24<06:07, 11.84s/it, train_loss=0.1645]\u001b[A\n",
      "Epoch 6/10:  61%|███████▎    | 48/79 [09:35<06:07, 11.84s/it, train_loss=0.1652]\u001b[A\n",
      "Epoch 6/10:  62%|███████▍    | 49/79 [09:35<05:49, 11.64s/it, train_loss=0.1652]\u001b[A\n",
      "Epoch 6/10:  62%|███████▍    | 49/79 [09:47<05:49, 11.64s/it, train_loss=0.1659]\u001b[A\n",
      "Epoch 6/10:  63%|███████▌    | 50/79 [09:47<05:40, 11.76s/it, train_loss=0.1659]\u001b[A\n",
      "Epoch 6/10:  63%|███████▌    | 50/79 [09:59<05:40, 11.76s/it, train_loss=0.1655]\u001b[A\n",
      "Epoch 6/10:  65%|███████▋    | 51/79 [09:59<05:30, 11.81s/it, train_loss=0.1655]\u001b[A\n",
      "Epoch 6/10:  65%|███████▋    | 51/79 [10:11<05:30, 11.81s/it, train_loss=0.1644]\u001b[A\n",
      "Epoch 6/10:  66%|███████▉    | 52/79 [10:11<05:22, 11.93s/it, train_loss=0.1644]\u001b[A\n",
      "Epoch 6/10:  66%|███████▉    | 52/79 [10:23<05:22, 11.93s/it, train_loss=0.1648]\u001b[A\n",
      "Epoch 6/10:  67%|████████    | 53/79 [10:23<05:09, 11.92s/it, train_loss=0.1648]\u001b[A\n",
      "Epoch 6/10:  67%|████████    | 53/79 [10:35<05:09, 11.92s/it, train_loss=0.1640]\u001b[A\n",
      "Epoch 6/10:  68%|████████▏   | 54/79 [10:35<05:00, 12.01s/it, train_loss=0.1640]\u001b[A\n",
      "Epoch 6/10:  68%|████████▏   | 54/79 [10:47<05:00, 12.01s/it, train_loss=0.1649]\u001b[A\n",
      "Epoch 6/10:  70%|████████▎   | 55/79 [10:48<04:51, 12.15s/it, train_loss=0.1649]\u001b[A\n",
      "Epoch 6/10:  70%|████████▎   | 55/79 [11:00<04:51, 12.15s/it, train_loss=0.1660]\u001b[A\n",
      "Epoch 6/10:  71%|████████▌   | 56/79 [11:00<04:42, 12.28s/it, train_loss=0.1660]\u001b[A\n",
      "Epoch 6/10:  71%|████████▌   | 56/79 [11:12<04:42, 12.28s/it, train_loss=0.1668]\u001b[A\n",
      "Epoch 6/10:  72%|████████▋   | 57/79 [11:12<04:28, 12.22s/it, train_loss=0.1668]\u001b[A\n",
      "Epoch 6/10:  72%|████████▋   | 57/79 [11:25<04:28, 12.22s/it, train_loss=0.1673]\u001b[A\n",
      "Epoch 6/10:  73%|████████▊   | 58/79 [11:25<04:18, 12.33s/it, train_loss=0.1673]\u001b[A\n",
      "Epoch 6/10:  73%|████████▊   | 58/79 [11:37<04:18, 12.33s/it, train_loss=0.1696]\u001b[A\n",
      "Epoch 6/10:  75%|████████▉   | 59/79 [11:37<04:05, 12.28s/it, train_loss=0.1696]\u001b[A\n",
      "Epoch 6/10:  75%|████████▉   | 59/79 [11:49<04:05, 12.28s/it, train_loss=0.1690]\u001b[A\n",
      "Epoch 6/10:  76%|█████████   | 60/79 [11:49<03:51, 12.17s/it, train_loss=0.1690]\u001b[A\n",
      "Epoch 6/10:  76%|█████████   | 60/79 [12:00<03:51, 12.17s/it, train_loss=0.1690]\u001b[A\n",
      "Epoch 6/10:  77%|█████████▎  | 61/79 [12:01<03:36, 12.04s/it, train_loss=0.1690]\u001b[A\n",
      "Epoch 6/10:  77%|█████████▎  | 61/79 [12:12<03:36, 12.04s/it, train_loss=0.1696]\u001b[A\n",
      "Epoch 6/10:  78%|█████████▍  | 62/79 [12:13<03:24, 12.04s/it, train_loss=0.1696]\u001b[A\n",
      "Epoch 6/10:  78%|█████████▍  | 62/79 [12:24<03:24, 12.04s/it, train_loss=0.1701]\u001b[A\n",
      "Epoch 6/10:  80%|█████████▌  | 63/79 [12:24<03:09, 11.87s/it, train_loss=0.1701]\u001b[A\n",
      "Epoch 6/10:  80%|█████████▌  | 63/79 [12:35<03:09, 11.87s/it, train_loss=0.1701]\u001b[A\n",
      "Epoch 6/10:  81%|█████████▋  | 64/79 [12:36<02:56, 11.76s/it, train_loss=0.1701]\u001b[A\n",
      "Epoch 6/10:  81%|█████████▋  | 64/79 [12:47<02:56, 11.76s/it, train_loss=0.1713]\u001b[A\n",
      "Epoch 6/10:  82%|█████████▊  | 65/79 [12:47<02:44, 11.74s/it, train_loss=0.1713]\u001b[A\n",
      "Epoch 6/10:  82%|█████████▊  | 65/79 [12:59<02:44, 11.74s/it, train_loss=0.1708]\u001b[A\n",
      "Epoch 6/10:  84%|██████████  | 66/79 [13:00<02:34, 11.92s/it, train_loss=0.1708]\u001b[A\n",
      "Epoch 6/10:  84%|██████████  | 66/79 [13:12<02:34, 11.92s/it, train_loss=0.1708]\u001b[A\n",
      "Epoch 6/10:  85%|██████████▏ | 67/79 [13:12<02:24, 12.00s/it, train_loss=0.1708]\u001b[A\n",
      "Epoch 6/10:  85%|██████████▏ | 67/79 [13:24<02:24, 12.00s/it, train_loss=0.1714]\u001b[A\n",
      "Epoch 6/10:  86%|██████████▎ | 68/79 [13:24<02:12, 12.08s/it, train_loss=0.1714]\u001b[A\n",
      "Epoch 6/10:  86%|██████████▎ | 68/79 [13:36<02:12, 12.08s/it, train_loss=0.1709]\u001b[A\n",
      "Epoch 6/10:  87%|██████████▍ | 69/79 [13:36<02:00, 12.05s/it, train_loss=0.1709]\u001b[A\n",
      "Epoch 6/10:  87%|██████████▍ | 69/79 [13:49<02:00, 12.05s/it, train_loss=0.1715]\u001b[A\n",
      "Epoch 6/10:  89%|██████████▋ | 70/79 [13:49<01:50, 12.31s/it, train_loss=0.1715]\u001b[A\n",
      "Epoch 6/10:  89%|██████████▋ | 70/79 [14:02<01:50, 12.31s/it, train_loss=0.1725]\u001b[A\n",
      "Epoch 6/10:  90%|██████████▊ | 71/79 [14:02<01:40, 12.58s/it, train_loss=0.1725]\u001b[A\n",
      "Epoch 6/10:  90%|██████████▊ | 71/79 [14:16<01:40, 12.58s/it, train_loss=0.1736]\u001b[A\n",
      "Epoch 6/10:  91%|██████████▉ | 72/79 [14:16<01:30, 13.00s/it, train_loss=0.1736]\u001b[A\n",
      "Epoch 6/10:  91%|██████████▉ | 72/79 [14:28<01:30, 13.00s/it, train_loss=0.1738]\u001b[A\n",
      "Epoch 6/10:  92%|███████████ | 73/79 [14:29<01:16, 12.77s/it, train_loss=0.1738]\u001b[A\n",
      "Epoch 6/10:  92%|███████████ | 73/79 [14:40<01:16, 12.77s/it, train_loss=0.1738]\u001b[A\n",
      "Epoch 6/10:  94%|███████████▏| 74/79 [14:40<01:02, 12.42s/it, train_loss=0.1738]\u001b[A\n",
      "Epoch 6/10:  94%|███████████▏| 74/79 [14:51<01:02, 12.42s/it, train_loss=0.1739]\u001b[A\n",
      "Epoch 6/10:  95%|███████████▍| 75/79 [14:52<00:48, 12.16s/it, train_loss=0.1739]\u001b[A\n",
      "Epoch 6/10:  95%|███████████▍| 75/79 [15:04<00:48, 12.16s/it, train_loss=0.1751]\u001b[A\n",
      "Epoch 6/10:  96%|███████████▌| 76/79 [15:04<00:36, 12.15s/it, train_loss=0.1751]\u001b[A\n",
      "Epoch 6/10:  96%|███████████▌| 76/79 [15:15<00:36, 12.15s/it, train_loss=0.1743]\u001b[A\n",
      "Epoch 6/10:  97%|███████████▋| 77/79 [15:16<00:24, 12.04s/it, train_loss=0.1743]\u001b[A\n",
      "Epoch 6/10:  97%|███████████▋| 77/79 [15:27<00:24, 12.04s/it, train_loss=0.1745]\u001b[A\n",
      "Epoch 6/10:  99%|███████████▊| 78/79 [15:27<00:11, 11.92s/it, train_loss=0.1745]\u001b[A\n",
      "Epoch 6/10:  99%|███████████▊| 78/79 [15:29<00:11, 11.92s/it, train_loss=1.3794]\u001b[A\n",
      "Epoch 6/10: 100%|████████████| 79/79 [15:29<00:00,  8.92s/it, train_loss=1.3794]\u001b[A\n",
      "Overall:  60%|██████████████████            | 6/10 [1:29:42<1:02:02, 930.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 • Train loss=0.1744 (929.7s) • Val Acc=0.9200 • Prec=0.9082 • Recall=0.9271 • F1=0.9175 • AUC=0.9765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10:   0%|                                        | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7/10:   0%|                     | 0/79 [00:11<?, ?it/s, train_loss=0.1545]\u001b[A\n",
      "Epoch 7/10:   1%|▏            | 1/79 [00:12<15:40, 12.05s/it, train_loss=0.1545]\u001b[A\n",
      "Epoch 7/10:   1%|▏            | 1/79 [00:23<15:40, 12.05s/it, train_loss=0.1467]\u001b[A\n",
      "Epoch 7/10:   3%|▎            | 2/79 [00:23<15:11, 11.84s/it, train_loss=0.1467]\u001b[A\n",
      "Epoch 7/10:   3%|▎            | 2/79 [00:35<15:11, 11.84s/it, train_loss=0.1377]\u001b[A\n",
      "Epoch 7/10:   4%|▍            | 3/79 [00:35<14:54, 11.76s/it, train_loss=0.1377]\u001b[A\n",
      "Epoch 7/10:   4%|▍            | 3/79 [00:47<14:54, 11.76s/it, train_loss=0.1224]\u001b[A\n",
      "Epoch 7/10:   5%|▋            | 4/79 [00:47<14:47, 11.84s/it, train_loss=0.1224]\u001b[A\n",
      "Epoch 7/10:   5%|▋            | 4/79 [00:58<14:47, 11.84s/it, train_loss=0.1345]\u001b[A\n",
      "Epoch 7/10:   6%|▊            | 5/79 [00:59<14:33, 11.80s/it, train_loss=0.1345]\u001b[A\n",
      "Epoch 7/10:   6%|▊            | 5/79 [01:10<14:33, 11.80s/it, train_loss=0.1325]\u001b[A\n",
      "Epoch 7/10:   8%|▉            | 6/79 [01:10<14:17, 11.74s/it, train_loss=0.1325]\u001b[A\n",
      "Epoch 7/10:   8%|▉            | 6/79 [01:22<14:17, 11.74s/it, train_loss=0.1384]\u001b[A\n",
      "Epoch 7/10:   9%|█▏           | 7/79 [01:22<14:13, 11.86s/it, train_loss=0.1384]\u001b[A\n",
      "Epoch 7/10:   9%|█▏           | 7/79 [01:34<14:13, 11.86s/it, train_loss=0.1406]\u001b[A\n",
      "Epoch 7/10:  10%|█▎           | 8/79 [01:34<14:04, 11.89s/it, train_loss=0.1406]\u001b[A\n",
      "Epoch 7/10:  10%|█▎           | 8/79 [01:46<14:04, 11.89s/it, train_loss=0.1388]\u001b[A\n",
      "Epoch 7/10:  11%|█▍           | 9/79 [01:46<13:54, 11.92s/it, train_loss=0.1388]\u001b[A\n",
      "Epoch 7/10:  11%|█▍           | 9/79 [01:58<13:54, 11.92s/it, train_loss=0.1483]\u001b[A\n",
      "Epoch 7/10:  13%|█▌          | 10/79 [01:58<13:46, 11.98s/it, train_loss=0.1483]\u001b[A\n",
      "Epoch 7/10:  13%|█▌          | 10/79 [02:09<13:46, 11.98s/it, train_loss=0.1499]\u001b[A\n",
      "Epoch 7/10:  14%|█▋          | 11/79 [02:10<13:20, 11.77s/it, train_loss=0.1499]\u001b[A\n",
      "Epoch 7/10:  14%|█▋          | 11/79 [02:21<13:20, 11.77s/it, train_loss=0.1498]\u001b[A\n",
      "Epoch 7/10:  15%|█▊          | 12/79 [02:21<13:06, 11.74s/it, train_loss=0.1498]\u001b[A\n",
      "Epoch 7/10:  15%|█▊          | 12/79 [02:33<13:06, 11.74s/it, train_loss=0.1512]\u001b[A\n",
      "Epoch 7/10:  16%|█▉          | 13/79 [02:34<13:04, 11.88s/it, train_loss=0.1512]\u001b[A\n",
      "Epoch 7/10:  16%|█▉          | 13/79 [02:45<13:04, 11.88s/it, train_loss=0.1570]\u001b[A\n",
      "Epoch 7/10:  18%|██▏         | 14/79 [02:45<12:47, 11.81s/it, train_loss=0.1570]\u001b[A\n",
      "Epoch 7/10:  18%|██▏         | 14/79 [02:57<12:47, 11.81s/it, train_loss=0.1572]\u001b[A\n",
      "Epoch 7/10:  19%|██▎         | 15/79 [02:57<12:32, 11.75s/it, train_loss=0.1572]\u001b[A\n",
      "Epoch 7/10:  19%|██▎         | 15/79 [03:08<12:32, 11.75s/it, train_loss=0.1589]\u001b[A\n",
      "Epoch 7/10:  20%|██▍         | 16/79 [03:09<12:22, 11.79s/it, train_loss=0.1589]\u001b[A\n",
      "Epoch 7/10:  20%|██▍         | 16/79 [03:20<12:22, 11.79s/it, train_loss=0.1552]\u001b[A\n",
      "Epoch 7/10:  22%|██▌         | 17/79 [03:20<12:05, 11.71s/it, train_loss=0.1552]\u001b[A\n",
      "Epoch 7/10:  22%|██▌         | 17/79 [03:31<12:05, 11.71s/it, train_loss=0.1547]\u001b[A\n",
      "Epoch 7/10:  23%|██▋         | 18/79 [03:32<11:49, 11.64s/it, train_loss=0.1547]\u001b[A\n",
      "Epoch 7/10:  23%|██▋         | 18/79 [03:43<11:49, 11.64s/it, train_loss=0.1536]\u001b[A\n",
      "Epoch 7/10:  24%|██▉         | 19/79 [03:44<11:42, 11.70s/it, train_loss=0.1536]\u001b[A\n",
      "Epoch 7/10:  24%|██▉         | 19/79 [03:55<11:42, 11.70s/it, train_loss=0.1565]\u001b[A\n",
      "Epoch 7/10:  25%|███         | 20/79 [03:55<11:29, 11.69s/it, train_loss=0.1565]\u001b[A\n",
      "Epoch 7/10:  25%|███         | 20/79 [04:06<11:29, 11.69s/it, train_loss=0.1624]\u001b[A\n",
      "Epoch 7/10:  27%|███▏        | 21/79 [04:07<11:13, 11.62s/it, train_loss=0.1624]\u001b[A\n",
      "Epoch 7/10:  27%|███▏        | 21/79 [04:18<11:13, 11.62s/it, train_loss=0.1651]\u001b[A\n",
      "Epoch 7/10:  28%|███▎        | 22/79 [04:18<10:59, 11.58s/it, train_loss=0.1651]\u001b[A\n",
      "Epoch 7/10:  28%|███▎        | 22/79 [04:29<10:59, 11.58s/it, train_loss=0.1666]\u001b[A\n",
      "Epoch 7/10:  29%|███▍        | 23/79 [04:30<10:48, 11.59s/it, train_loss=0.1666]\u001b[A\n",
      "Epoch 7/10:  29%|███▍        | 23/79 [04:41<10:48, 11.59s/it, train_loss=0.1666]\u001b[A\n",
      "Epoch 7/10:  30%|███▋        | 24/79 [04:41<10:32, 11.50s/it, train_loss=0.1666]\u001b[A\n",
      "Epoch 7/10:  30%|███▋        | 24/79 [04:52<10:32, 11.50s/it, train_loss=0.1665]\u001b[A\n",
      "Epoch 7/10:  32%|███▊        | 25/79 [04:52<10:13, 11.36s/it, train_loss=0.1665]\u001b[A\n",
      "Epoch 7/10:  32%|███▊        | 25/79 [05:03<10:13, 11.36s/it, train_loss=0.1675]\u001b[A\n",
      "Epoch 7/10:  33%|███▉        | 26/79 [05:03<10:01, 11.34s/it, train_loss=0.1675]\u001b[A\n",
      "Epoch 7/10:  33%|███▉        | 26/79 [05:15<10:01, 11.34s/it, train_loss=0.1641]\u001b[A\n",
      "Epoch 7/10:  34%|████        | 27/79 [05:15<09:51, 11.38s/it, train_loss=0.1641]\u001b[A\n",
      "Epoch 7/10:  34%|████        | 27/79 [05:28<09:51, 11.38s/it, train_loss=0.1644]\u001b[A\n",
      "Epoch 7/10:  35%|████▎       | 28/79 [05:28<10:04, 11.86s/it, train_loss=0.1644]\u001b[A\n",
      "Epoch 7/10:  35%|████▎       | 28/79 [05:40<10:04, 11.86s/it, train_loss=0.1700]\u001b[A\n",
      "Epoch 7/10:  37%|████▍       | 29/79 [05:40<10:00, 12.02s/it, train_loss=0.1700]\u001b[A\n",
      "Epoch 7/10:  37%|████▍       | 29/79 [05:51<10:00, 12.02s/it, train_loss=0.1691]\u001b[A\n",
      "Epoch 7/10:  38%|████▌       | 30/79 [05:52<09:42, 11.88s/it, train_loss=0.1691]\u001b[A\n",
      "Epoch 7/10:  38%|████▌       | 30/79 [06:03<09:42, 11.88s/it, train_loss=0.1698]\u001b[A\n",
      "Epoch 7/10:  39%|████▋       | 31/79 [06:03<09:26, 11.80s/it, train_loss=0.1698]\u001b[A\n",
      "Epoch 7/10:  39%|████▋       | 31/79 [06:14<09:26, 11.80s/it, train_loss=0.1700]\u001b[A\n",
      "Epoch 7/10:  41%|████▊       | 32/79 [06:15<09:06, 11.64s/it, train_loss=0.1700]\u001b[A\n",
      "Epoch 7/10:  41%|████▊       | 32/79 [06:26<09:06, 11.64s/it, train_loss=0.1691]\u001b[A\n",
      "Epoch 7/10:  42%|█████       | 33/79 [06:26<08:57, 11.69s/it, train_loss=0.1691]\u001b[A\n",
      "Epoch 7/10:  42%|█████       | 33/79 [06:38<08:57, 11.69s/it, train_loss=0.1687]\u001b[A\n",
      "Epoch 7/10:  43%|█████▏      | 34/79 [06:39<08:54, 11.87s/it, train_loss=0.1687]\u001b[A\n",
      "Epoch 7/10:  43%|█████▏      | 34/79 [06:50<08:54, 11.87s/it, train_loss=0.1666]\u001b[A\n",
      "Epoch 7/10:  44%|█████▎      | 35/79 [06:50<08:40, 11.83s/it, train_loss=0.1666]\u001b[A\n",
      "Epoch 7/10:  44%|█████▎      | 35/79 [07:02<08:40, 11.83s/it, train_loss=0.1699]\u001b[A\n",
      "Epoch 7/10:  46%|█████▍      | 36/79 [07:02<08:27, 11.80s/it, train_loss=0.1699]\u001b[A\n",
      "Epoch 7/10:  46%|█████▍      | 36/79 [07:13<08:27, 11.80s/it, train_loss=0.1691]\u001b[A\n",
      "Epoch 7/10:  47%|█████▌      | 37/79 [07:14<08:11, 11.70s/it, train_loss=0.1691]\u001b[A\n",
      "Epoch 7/10:  47%|█████▌      | 37/79 [07:25<08:11, 11.70s/it, train_loss=0.1685]\u001b[A\n",
      "Epoch 7/10:  48%|█████▊      | 38/79 [07:25<07:54, 11.57s/it, train_loss=0.1685]\u001b[A\n",
      "Epoch 7/10:  48%|█████▊      | 38/79 [07:36<07:54, 11.57s/it, train_loss=0.1683]\u001b[A\n",
      "Epoch 7/10:  49%|█████▉      | 39/79 [07:36<07:42, 11.57s/it, train_loss=0.1683]\u001b[A\n",
      "Epoch 7/10:  49%|█████▉      | 39/79 [07:48<07:42, 11.57s/it, train_loss=0.1691]\u001b[A\n",
      "Epoch 7/10:  51%|██████      | 40/79 [07:48<07:34, 11.64s/it, train_loss=0.1691]\u001b[A\n",
      "Epoch 7/10:  51%|██████      | 40/79 [08:00<07:34, 11.64s/it, train_loss=0.1690]\u001b[A\n",
      "Epoch 7/10:  52%|██████▏     | 41/79 [08:00<07:21, 11.62s/it, train_loss=0.1690]\u001b[A\n",
      "Epoch 7/10:  52%|██████▏     | 41/79 [08:11<07:21, 11.62s/it, train_loss=0.1689]\u001b[A\n",
      "Epoch 7/10:  53%|██████▍     | 42/79 [08:12<07:12, 11.69s/it, train_loss=0.1689]\u001b[A\n",
      "Epoch 7/10:  53%|██████▍     | 42/79 [08:23<07:12, 11.69s/it, train_loss=0.1691]\u001b[A\n",
      "Epoch 7/10:  54%|██████▌     | 43/79 [08:24<07:03, 11.75s/it, train_loss=0.1691]\u001b[A\n",
      "Epoch 7/10:  54%|██████▌     | 43/79 [08:35<07:03, 11.75s/it, train_loss=0.1697]\u001b[A\n",
      "Epoch 7/10:  56%|██████▋     | 44/79 [08:35<06:52, 11.78s/it, train_loss=0.1697]\u001b[A\n",
      "Epoch 7/10:  56%|██████▋     | 44/79 [08:47<06:52, 11.78s/it, train_loss=0.1693]\u001b[A\n",
      "Epoch 7/10:  57%|██████▊     | 45/79 [08:47<06:39, 11.74s/it, train_loss=0.1693]\u001b[A\n",
      "Epoch 7/10:  57%|██████▊     | 45/79 [08:59<06:39, 11.74s/it, train_loss=0.1714]\u001b[A\n",
      "Epoch 7/10:  58%|██████▉     | 46/79 [08:59<06:28, 11.78s/it, train_loss=0.1714]\u001b[A\n",
      "Epoch 7/10:  58%|██████▉     | 46/79 [09:11<06:28, 11.78s/it, train_loss=0.1714]\u001b[A\n",
      "Epoch 7/10:  59%|███████▏    | 47/79 [09:11<06:17, 11.79s/it, train_loss=0.1714]\u001b[A\n",
      "Epoch 7/10:  59%|███████▏    | 47/79 [09:22<06:17, 11.79s/it, train_loss=0.1700]\u001b[A\n",
      "Epoch 7/10:  61%|███████▎    | 48/79 [09:23<06:05, 11.80s/it, train_loss=0.1700]\u001b[A\n",
      "Epoch 7/10:  61%|███████▎    | 48/79 [09:34<06:05, 11.80s/it, train_loss=0.1696]\u001b[A\n",
      "Epoch 7/10:  62%|███████▍    | 49/79 [09:34<05:51, 11.73s/it, train_loss=0.1696]\u001b[A\n",
      "Epoch 7/10:  62%|███████▍    | 49/79 [09:47<05:51, 11.73s/it, train_loss=0.1685]\u001b[A\n",
      "Epoch 7/10:  63%|███████▌    | 50/79 [09:47<05:48, 12.01s/it, train_loss=0.1685]\u001b[A\n",
      "Epoch 7/10:  63%|███████▌    | 50/79 [09:58<05:48, 12.01s/it, train_loss=0.1698]\u001b[A\n",
      "Epoch 7/10:  65%|███████▋    | 51/79 [09:58<05:32, 11.86s/it, train_loss=0.1698]\u001b[A\n",
      "Epoch 7/10:  65%|███████▋    | 51/79 [10:10<05:32, 11.86s/it, train_loss=0.1704]\u001b[A\n",
      "Epoch 7/10:  66%|███████▉    | 52/79 [10:10<05:17, 11.74s/it, train_loss=0.1704]\u001b[A\n",
      "Epoch 7/10:  66%|███████▉    | 52/79 [10:21<05:17, 11.74s/it, train_loss=0.1705]\u001b[A\n",
      "Epoch 7/10:  67%|████████    | 53/79 [10:21<05:04, 11.70s/it, train_loss=0.1705]\u001b[A\n",
      "Epoch 7/10:  67%|████████    | 53/79 [10:33<05:04, 11.70s/it, train_loss=0.1693]\u001b[A\n",
      "Epoch 7/10:  68%|████████▏   | 54/79 [10:34<04:56, 11.86s/it, train_loss=0.1693]\u001b[A\n",
      "Epoch 7/10:  68%|████████▏   | 54/79 [10:46<04:56, 11.86s/it, train_loss=0.1695]\u001b[A\n",
      "Epoch 7/10:  70%|████████▎   | 55/79 [10:46<04:47, 12.00s/it, train_loss=0.1695]\u001b[A\n",
      "Epoch 7/10:  70%|████████▎   | 55/79 [10:57<04:47, 12.00s/it, train_loss=0.1689]\u001b[A\n",
      "Epoch 7/10:  71%|████████▌   | 56/79 [10:57<04:31, 11.79s/it, train_loss=0.1689]\u001b[A\n",
      "Epoch 7/10:  71%|████████▌   | 56/79 [11:08<04:31, 11.79s/it, train_loss=0.1684]\u001b[A\n",
      "Epoch 7/10:  72%|████████▋   | 57/79 [11:09<04:16, 11.65s/it, train_loss=0.1684]\u001b[A\n",
      "Epoch 7/10:  72%|████████▋   | 57/79 [11:20<04:16, 11.65s/it, train_loss=0.1675]\u001b[A\n",
      "Epoch 7/10:  73%|████████▊   | 58/79 [11:20<04:03, 11.59s/it, train_loss=0.1675]\u001b[A\n",
      "Epoch 7/10:  73%|████████▊   | 58/79 [11:32<04:03, 11.59s/it, train_loss=0.1673]\u001b[A\n",
      "Epoch 7/10:  75%|████████▉   | 59/79 [11:32<03:56, 11.84s/it, train_loss=0.1673]\u001b[A\n",
      "Epoch 7/10:  75%|████████▉   | 59/79 [11:44<03:56, 11.84s/it, train_loss=0.1665]\u001b[A\n",
      "Epoch 7/10:  76%|█████████   | 60/79 [11:44<03:45, 11.88s/it, train_loss=0.1665]\u001b[A\n",
      "Epoch 7/10:  76%|█████████   | 60/79 [11:55<03:45, 11.88s/it, train_loss=0.1662]\u001b[A\n",
      "Epoch 7/10:  77%|█████████▎  | 61/79 [11:56<03:30, 11.70s/it, train_loss=0.1662]\u001b[A\n",
      "Epoch 7/10:  77%|█████████▎  | 61/79 [12:07<03:30, 11.70s/it, train_loss=0.1661]\u001b[A\n",
      "Epoch 7/10:  78%|█████████▍  | 62/79 [12:07<03:17, 11.64s/it, train_loss=0.1661]\u001b[A\n",
      "Epoch 7/10:  78%|█████████▍  | 62/79 [12:21<03:17, 11.64s/it, train_loss=0.1652]\u001b[A\n",
      "Epoch 7/10:  80%|█████████▌  | 63/79 [12:21<03:16, 12.31s/it, train_loss=0.1652]\u001b[A\n",
      "Epoch 7/10:  80%|█████████▌  | 63/79 [12:33<03:16, 12.31s/it, train_loss=0.1652]\u001b[A\n",
      "Epoch 7/10:  81%|█████████▋  | 64/79 [12:33<03:04, 12.32s/it, train_loss=0.1652]\u001b[A\n",
      "Epoch 7/10:  81%|█████████▋  | 64/79 [12:45<03:04, 12.32s/it, train_loss=0.1639]\u001b[A\n",
      "Epoch 7/10:  82%|█████████▊  | 65/79 [12:45<02:50, 12.16s/it, train_loss=0.1639]\u001b[A\n",
      "Epoch 7/10:  82%|█████████▊  | 65/79 [12:56<02:50, 12.16s/it, train_loss=0.1634]\u001b[A\n",
      "Epoch 7/10:  84%|██████████  | 66/79 [12:57<02:34, 11.91s/it, train_loss=0.1634]\u001b[A\n",
      "Epoch 7/10:  84%|██████████  | 66/79 [13:07<02:34, 11.91s/it, train_loss=0.1626]\u001b[A\n",
      "Epoch 7/10:  85%|██████████▏ | 67/79 [13:08<02:20, 11.69s/it, train_loss=0.1626]\u001b[A\n",
      "Epoch 7/10:  85%|██████████▏ | 67/79 [13:19<02:20, 11.69s/it, train_loss=0.1617]\u001b[A\n",
      "Epoch 7/10:  86%|██████████▎ | 68/79 [13:19<02:08, 11.68s/it, train_loss=0.1617]\u001b[A\n",
      "Epoch 7/10:  86%|██████████▎ | 68/79 [13:31<02:08, 11.68s/it, train_loss=0.1632]\u001b[A\n",
      "Epoch 7/10:  87%|██████████▍ | 69/79 [13:31<01:57, 11.79s/it, train_loss=0.1632]\u001b[A\n",
      "Epoch 7/10:  87%|██████████▍ | 69/79 [13:43<01:57, 11.79s/it, train_loss=0.1629]\u001b[A\n",
      "Epoch 7/10:  89%|██████████▋ | 70/79 [13:43<01:46, 11.78s/it, train_loss=0.1629]\u001b[A\n",
      "Epoch 7/10:  89%|██████████▋ | 70/79 [13:55<01:46, 11.78s/it, train_loss=0.1623]\u001b[A\n",
      "Epoch 7/10:  90%|██████████▊ | 71/79 [13:55<01:34, 11.83s/it, train_loss=0.1623]\u001b[A\n",
      "Epoch 7/10:  90%|██████████▊ | 71/79 [14:07<01:34, 11.83s/it, train_loss=0.1619]\u001b[A\n",
      "Epoch 7/10:  91%|██████████▉ | 72/79 [14:07<01:22, 11.82s/it, train_loss=0.1619]\u001b[A\n",
      "Epoch 7/10:  91%|██████████▉ | 72/79 [14:18<01:22, 11.82s/it, train_loss=0.1613]\u001b[A\n",
      "Epoch 7/10:  92%|███████████ | 73/79 [14:19<01:10, 11.79s/it, train_loss=0.1613]\u001b[A\n",
      "Epoch 7/10:  92%|███████████ | 73/79 [14:30<01:10, 11.79s/it, train_loss=0.1608]\u001b[A\n",
      "Epoch 7/10:  94%|███████████▏| 74/79 [14:30<00:58, 11.62s/it, train_loss=0.1608]\u001b[A\n",
      "Epoch 7/10:  94%|███████████▏| 74/79 [14:42<00:58, 11.62s/it, train_loss=0.1612]\u001b[A\n",
      "Epoch 7/10:  95%|███████████▍| 75/79 [14:42<00:46, 11.73s/it, train_loss=0.1612]\u001b[A\n",
      "Epoch 7/10:  95%|███████████▍| 75/79 [14:53<00:46, 11.73s/it, train_loss=0.1605]\u001b[A\n",
      "Epoch 7/10:  96%|███████████▌| 76/79 [14:53<00:35, 11.69s/it, train_loss=0.1605]\u001b[A\n",
      "Epoch 7/10:  96%|███████████▌| 76/79 [15:05<00:35, 11.69s/it, train_loss=0.1614]\u001b[A\n",
      "Epoch 7/10:  97%|███████████▋| 77/79 [15:06<00:23, 11.84s/it, train_loss=0.1614]\u001b[A\n",
      "Epoch 7/10:  97%|███████████▋| 77/79 [15:17<00:23, 11.84s/it, train_loss=0.1622]\u001b[A\n",
      "Epoch 7/10:  99%|███████████▊| 78/79 [15:18<00:11, 11.93s/it, train_loss=0.1622]\u001b[A\n",
      "Epoch 7/10:  99%|███████████▊| 78/79 [15:19<00:11, 11.93s/it, train_loss=1.2873]\u001b[A\n",
      "Epoch 7/10: 100%|████████████| 79/79 [15:20<00:00,  8.91s/it, train_loss=1.2873]\u001b[A\n",
      "Overall:  70%|██████████████████████▍         | 7/10 [1:46:12<47:30, 950.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 • Train loss=0.1627 (920.1s) • Val Acc=0.9150 • Prec=0.9089 • Recall=0.9146 • F1=0.9117 • AUC=0.9756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10:   0%|                                        | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8/10:   0%|                     | 0/79 [00:11<?, ?it/s, train_loss=0.2009]\u001b[A\n",
      "Epoch 8/10:   1%|▏            | 1/79 [00:12<15:37, 12.02s/it, train_loss=0.2009]\u001b[A\n",
      "Epoch 8/10:   1%|▏            | 1/79 [00:23<15:37, 12.02s/it, train_loss=0.2169]\u001b[A\n",
      "Epoch 8/10:   3%|▎            | 2/79 [00:23<14:53, 11.61s/it, train_loss=0.2169]\u001b[A\n",
      "Epoch 8/10:   3%|▎            | 2/79 [00:35<14:53, 11.61s/it, train_loss=0.1992]\u001b[A\n",
      "Epoch 8/10:   4%|▍            | 3/79 [00:35<14:58, 11.83s/it, train_loss=0.1992]\u001b[A\n",
      "Epoch 8/10:   4%|▍            | 3/79 [00:46<14:58, 11.83s/it, train_loss=0.1679]\u001b[A\n",
      "Epoch 8/10:   5%|▋            | 4/79 [00:47<14:41, 11.75s/it, train_loss=0.1679]\u001b[A\n",
      "Epoch 8/10:   5%|▋            | 4/79 [00:58<14:41, 11.75s/it, train_loss=0.1671]\u001b[A\n",
      "Epoch 8/10:   6%|▊            | 5/79 [00:58<14:27, 11.73s/it, train_loss=0.1671]\u001b[A\n",
      "Epoch 8/10:   6%|▊            | 5/79 [01:10<14:27, 11.73s/it, train_loss=0.1797]\u001b[A\n",
      "Epoch 8/10:   8%|▉            | 6/79 [01:10<14:19, 11.77s/it, train_loss=0.1797]\u001b[A\n",
      "Epoch 8/10:   8%|▉            | 6/79 [01:22<14:19, 11.77s/it, train_loss=0.1726]\u001b[A\n",
      "Epoch 8/10:   9%|█▏           | 7/79 [01:23<14:23, 11.99s/it, train_loss=0.1726]\u001b[A\n",
      "Epoch 8/10:   9%|█▏           | 7/79 [01:34<14:23, 11.99s/it, train_loss=0.1711]\u001b[A\n",
      "Epoch 8/10:  10%|█▎           | 8/79 [01:35<14:14, 12.03s/it, train_loss=0.1711]\u001b[A\n",
      "Epoch 8/10:  10%|█▎           | 8/79 [01:46<14:14, 12.03s/it, train_loss=0.1819]\u001b[A\n",
      "Epoch 8/10:  11%|█▍           | 9/79 [01:47<14:01, 12.02s/it, train_loss=0.1819]\u001b[A\n",
      "Epoch 8/10:  11%|█▍           | 9/79 [01:59<14:01, 12.02s/it, train_loss=0.1789]\u001b[A\n",
      "Epoch 8/10:  13%|█▌          | 10/79 [01:59<13:59, 12.17s/it, train_loss=0.1789]\u001b[A\n",
      "Epoch 8/10:  13%|█▌          | 10/79 [02:11<13:59, 12.17s/it, train_loss=0.1746]\u001b[A\n",
      "Epoch 8/10:  14%|█▋          | 11/79 [02:11<13:49, 12.19s/it, train_loss=0.1746]\u001b[A\n",
      "Epoch 8/10:  14%|█▋          | 11/79 [02:23<13:49, 12.19s/it, train_loss=0.1743]\u001b[A\n",
      "Epoch 8/10:  15%|█▊          | 12/79 [02:23<13:27, 12.05s/it, train_loss=0.1743]\u001b[A\n",
      "Epoch 8/10:  15%|█▊          | 12/79 [02:34<13:27, 12.05s/it, train_loss=0.1717]\u001b[A\n",
      "Epoch 8/10:  16%|█▉          | 13/79 [02:34<12:57, 11.78s/it, train_loss=0.1717]\u001b[A\n",
      "Epoch 8/10:  16%|█▉          | 13/79 [02:45<12:57, 11.78s/it, train_loss=0.1683]\u001b[A\n",
      "Epoch 8/10:  18%|██▏         | 14/79 [02:46<12:36, 11.64s/it, train_loss=0.1683]\u001b[A\n",
      "Epoch 8/10:  18%|██▏         | 14/79 [02:57<12:36, 11.64s/it, train_loss=0.1688]\u001b[A\n",
      "Epoch 8/10:  19%|██▎         | 15/79 [02:57<12:24, 11.63s/it, train_loss=0.1688]\u001b[A\n",
      "Epoch 8/10:  19%|██▎         | 15/79 [03:09<12:24, 11.63s/it, train_loss=0.1670]\u001b[A\n",
      "Epoch 8/10:  20%|██▍         | 16/79 [03:09<12:19, 11.74s/it, train_loss=0.1670]\u001b[A\n",
      "Epoch 8/10:  20%|██▍         | 16/79 [03:21<12:19, 11.74s/it, train_loss=0.1653]\u001b[A\n",
      "Epoch 8/10:  22%|██▌         | 17/79 [03:21<12:05, 11.70s/it, train_loss=0.1653]\u001b[A\n",
      "Epoch 8/10:  22%|██▌         | 17/79 [03:32<12:05, 11.70s/it, train_loss=0.1643]\u001b[A\n",
      "Epoch 8/10:  23%|██▋         | 18/79 [03:32<11:48, 11.61s/it, train_loss=0.1643]\u001b[A\n",
      "Epoch 8/10:  23%|██▋         | 18/79 [03:43<11:48, 11.61s/it, train_loss=0.1619]\u001b[A\n",
      "Epoch 8/10:  24%|██▉         | 19/79 [03:43<11:29, 11.50s/it, train_loss=0.1619]\u001b[A\n",
      "Epoch 8/10:  24%|██▉         | 19/79 [03:55<11:29, 11.50s/it, train_loss=0.1579]\u001b[A\n",
      "Epoch 8/10:  25%|███         | 20/79 [03:55<11:18, 11.51s/it, train_loss=0.1579]\u001b[A\n",
      "Epoch 8/10:  25%|███         | 20/79 [04:06<11:18, 11.51s/it, train_loss=0.1573]\u001b[A\n",
      "Epoch 8/10:  27%|███▏        | 21/79 [04:07<11:09, 11.54s/it, train_loss=0.1573]\u001b[A\n",
      "Epoch 8/10:  27%|███▏        | 21/79 [04:18<11:09, 11.54s/it, train_loss=0.1621]\u001b[A\n",
      "Epoch 8/10:  28%|███▎        | 22/79 [04:18<10:54, 11.48s/it, train_loss=0.1621]\u001b[A\n",
      "Epoch 8/10:  28%|███▎        | 22/79 [04:29<10:54, 11.48s/it, train_loss=0.1653]\u001b[A\n",
      "Epoch 8/10:  29%|███▍        | 23/79 [04:29<10:43, 11.50s/it, train_loss=0.1653]\u001b[A\n",
      "Epoch 8/10:  29%|███▍        | 23/79 [04:41<10:43, 11.50s/it, train_loss=0.1654]\u001b[A\n",
      "Epoch 8/10:  30%|███▋        | 24/79 [04:41<10:34, 11.53s/it, train_loss=0.1654]\u001b[A\n",
      "Epoch 8/10:  30%|███▋        | 24/79 [04:52<10:34, 11.53s/it, train_loss=0.1672]\u001b[A\n",
      "Epoch 8/10:  32%|███▊        | 25/79 [04:52<10:18, 11.45s/it, train_loss=0.1672]\u001b[A\n",
      "Epoch 8/10:  32%|███▊        | 25/79 [05:03<10:18, 11.45s/it, train_loss=0.1662]\u001b[A\n",
      "Epoch 8/10:  33%|███▉        | 26/79 [05:04<10:03, 11.38s/it, train_loss=0.1662]\u001b[A\n",
      "Epoch 8/10:  33%|███▉        | 26/79 [05:15<10:03, 11.38s/it, train_loss=0.1631]\u001b[A\n",
      "Epoch 8/10:  34%|████        | 27/79 [05:15<09:50, 11.36s/it, train_loss=0.1631]\u001b[A\n",
      "Epoch 8/10:  34%|████        | 27/79 [05:26<09:50, 11.36s/it, train_loss=0.1619]\u001b[A\n",
      "Epoch 8/10:  35%|████▎       | 28/79 [05:26<09:39, 11.37s/it, train_loss=0.1619]\u001b[A\n",
      "Epoch 8/10:  35%|████▎       | 28/79 [05:37<09:39, 11.37s/it, train_loss=0.1634]\u001b[A\n",
      "Epoch 8/10:  37%|████▍       | 29/79 [05:38<09:27, 11.36s/it, train_loss=0.1634]\u001b[A\n",
      "Epoch 8/10:  37%|████▍       | 29/79 [05:48<09:27, 11.36s/it, train_loss=0.1660]\u001b[A\n",
      "Epoch 8/10:  38%|████▌       | 30/79 [05:49<09:13, 11.30s/it, train_loss=0.1660]\u001b[A\n",
      "Epoch 8/10:  38%|████▌       | 30/79 [06:00<09:13, 11.30s/it, train_loss=0.1690]\u001b[A\n",
      "Epoch 8/10:  39%|████▋       | 31/79 [06:00<08:59, 11.25s/it, train_loss=0.1690]\u001b[A\n",
      "Epoch 8/10:  39%|████▋       | 31/79 [06:11<08:59, 11.25s/it, train_loss=0.1699]\u001b[A\n",
      "Epoch 8/10:  41%|████▊       | 32/79 [06:11<08:50, 11.29s/it, train_loss=0.1699]\u001b[A\n",
      "Epoch 8/10:  41%|████▊       | 32/79 [06:22<08:50, 11.29s/it, train_loss=0.1667]\u001b[A\n",
      "Epoch 8/10:  42%|█████       | 33/79 [06:22<08:37, 11.24s/it, train_loss=0.1667]\u001b[A\n",
      "Epoch 8/10:  42%|█████       | 33/79 [06:34<08:37, 11.24s/it, train_loss=0.1705]\u001b[A\n",
      "Epoch 8/10:  43%|█████▏      | 34/79 [06:34<08:27, 11.29s/it, train_loss=0.1705]\u001b[A\n",
      "Epoch 8/10:  43%|█████▏      | 34/79 [06:45<08:27, 11.29s/it, train_loss=0.1677]\u001b[A\n",
      "Epoch 8/10:  44%|█████▎      | 35/79 [06:45<08:15, 11.25s/it, train_loss=0.1677]\u001b[A\n",
      "Epoch 8/10:  44%|█████▎      | 35/79 [06:56<08:15, 11.25s/it, train_loss=0.1659]\u001b[A\n",
      "Epoch 8/10:  46%|█████▍      | 36/79 [06:56<08:03, 11.25s/it, train_loss=0.1659]\u001b[A\n",
      "Epoch 8/10:  46%|█████▍      | 36/79 [07:07<08:03, 11.25s/it, train_loss=0.1641]\u001b[A\n",
      "Epoch 8/10:  47%|█████▌      | 37/79 [07:08<07:54, 11.31s/it, train_loss=0.1641]\u001b[A\n",
      "Epoch 8/10:  47%|█████▌      | 37/79 [07:19<07:54, 11.31s/it, train_loss=0.1626]\u001b[A\n",
      "Epoch 8/10:  48%|█████▊      | 38/79 [07:19<07:44, 11.33s/it, train_loss=0.1626]\u001b[A\n",
      "Epoch 8/10:  48%|█████▊      | 38/79 [07:30<07:44, 11.33s/it, train_loss=0.1629]\u001b[A\n",
      "Epoch 8/10:  49%|█████▉      | 39/79 [07:30<07:31, 11.28s/it, train_loss=0.1629]\u001b[A\n",
      "Epoch 8/10:  49%|█████▉      | 39/79 [07:41<07:31, 11.28s/it, train_loss=0.1617]\u001b[A\n",
      "Epoch 8/10:  51%|██████      | 40/79 [07:41<07:18, 11.23s/it, train_loss=0.1617]\u001b[A\n",
      "Epoch 8/10:  51%|██████      | 40/79 [07:52<07:18, 11.23s/it, train_loss=0.1623]\u001b[A\n",
      "Epoch 8/10:  52%|██████▏     | 41/79 [07:52<07:06, 11.21s/it, train_loss=0.1623]\u001b[A\n",
      "Epoch 8/10:  52%|██████▏     | 41/79 [08:04<07:06, 11.21s/it, train_loss=0.1627]\u001b[A\n",
      "Epoch 8/10:  53%|██████▍     | 42/79 [08:04<06:59, 11.33s/it, train_loss=0.1627]\u001b[A\n",
      "Epoch 8/10:  53%|██████▍     | 42/79 [08:15<06:59, 11.33s/it, train_loss=0.1623]\u001b[A\n",
      "Epoch 8/10:  54%|██████▌     | 43/79 [08:16<06:50, 11.40s/it, train_loss=0.1623]\u001b[A\n",
      "Epoch 8/10:  54%|██████▌     | 43/79 [08:27<06:50, 11.40s/it, train_loss=0.1614]\u001b[A\n",
      "Epoch 8/10:  56%|██████▋     | 44/79 [08:27<06:36, 11.33s/it, train_loss=0.1614]\u001b[A\n",
      "Epoch 8/10:  56%|██████▋     | 44/79 [08:38<06:36, 11.33s/it, train_loss=0.1615]\u001b[A\n",
      "Epoch 8/10:  57%|██████▊     | 45/79 [08:38<06:25, 11.33s/it, train_loss=0.1615]\u001b[A\n",
      "Epoch 8/10:  57%|██████▊     | 45/79 [08:49<06:25, 11.33s/it, train_loss=0.1596]\u001b[A\n",
      "Epoch 8/10:  58%|██████▉     | 46/79 [08:49<06:12, 11.28s/it, train_loss=0.1596]\u001b[A\n",
      "Epoch 8/10:  58%|██████▉     | 46/79 [09:00<06:12, 11.28s/it, train_loss=0.1591]\u001b[A\n",
      "Epoch 8/10:  59%|███████▏    | 47/79 [09:01<06:02, 11.32s/it, train_loss=0.1591]\u001b[A\n",
      "Epoch 8/10:  59%|███████▏    | 47/79 [09:12<06:02, 11.32s/it, train_loss=0.1573]\u001b[A\n",
      "Epoch 8/10:  61%|███████▎    | 48/79 [09:12<05:49, 11.27s/it, train_loss=0.1573]\u001b[A\n",
      "Epoch 8/10:  61%|███████▎    | 48/79 [09:23<05:49, 11.27s/it, train_loss=0.1569]\u001b[A\n",
      "Epoch 8/10:  62%|███████▍    | 49/79 [09:24<05:42, 11.41s/it, train_loss=0.1569]\u001b[A\n",
      "Epoch 8/10:  62%|███████▍    | 49/79 [09:35<05:42, 11.41s/it, train_loss=0.1561]\u001b[A\n",
      "Epoch 8/10:  63%|███████▌    | 50/79 [09:36<05:36, 11.62s/it, train_loss=0.1561]\u001b[A\n",
      "Epoch 8/10:  63%|███████▌    | 50/79 [09:46<05:36, 11.62s/it, train_loss=0.1582]\u001b[A\n",
      "Epoch 8/10:  65%|███████▋    | 51/79 [09:47<05:19, 11.43s/it, train_loss=0.1582]\u001b[A\n",
      "Epoch 8/10:  65%|███████▋    | 51/79 [09:58<05:19, 11.43s/it, train_loss=0.1586]\u001b[A\n",
      "Epoch 8/10:  66%|███████▉    | 52/79 [09:58<05:08, 11.43s/it, train_loss=0.1586]\u001b[A\n",
      "Epoch 8/10:  66%|███████▉    | 52/79 [10:09<05:08, 11.43s/it, train_loss=0.1582]\u001b[A\n",
      "Epoch 8/10:  67%|████████    | 53/79 [10:10<04:56, 11.42s/it, train_loss=0.1582]\u001b[A\n",
      "Epoch 8/10:  67%|████████    | 53/79 [10:21<04:56, 11.42s/it, train_loss=0.1585]\u001b[A\n",
      "Epoch 8/10:  68%|████████▏   | 54/79 [10:21<04:45, 11.40s/it, train_loss=0.1585]\u001b[A\n",
      "Epoch 8/10:  68%|████████▏   | 54/79 [10:32<04:45, 11.40s/it, train_loss=0.1575]\u001b[A\n",
      "Epoch 8/10:  70%|████████▎   | 55/79 [10:33<04:36, 11.50s/it, train_loss=0.1575]\u001b[A\n",
      "Epoch 8/10:  70%|████████▎   | 55/79 [10:44<04:36, 11.50s/it, train_loss=0.1578]\u001b[A\n",
      "Epoch 8/10:  71%|████████▌   | 56/79 [10:44<04:25, 11.55s/it, train_loss=0.1578]\u001b[A\n",
      "Epoch 8/10:  71%|████████▌   | 56/79 [10:56<04:25, 11.55s/it, train_loss=0.1576]\u001b[A\n",
      "Epoch 8/10:  72%|████████▋   | 57/79 [10:56<04:16, 11.64s/it, train_loss=0.1576]\u001b[A\n",
      "Epoch 8/10:  72%|████████▋   | 57/79 [11:08<04:16, 11.64s/it, train_loss=0.1585]\u001b[A\n",
      "Epoch 8/10:  73%|████████▊   | 58/79 [11:08<04:05, 11.67s/it, train_loss=0.1585]\u001b[A\n",
      "Epoch 8/10:  73%|████████▊   | 58/79 [11:19<04:05, 11.67s/it, train_loss=0.1578]\u001b[A\n",
      "Epoch 8/10:  75%|████████▉   | 59/79 [11:19<03:51, 11.57s/it, train_loss=0.1578]\u001b[A\n",
      "Epoch 8/10:  75%|████████▉   | 59/79 [11:30<03:51, 11.57s/it, train_loss=0.1566]\u001b[A\n",
      "Epoch 8/10:  76%|█████████   | 60/79 [11:31<03:39, 11.54s/it, train_loss=0.1566]\u001b[A\n",
      "Epoch 8/10:  76%|█████████   | 60/79 [11:42<03:39, 11.54s/it, train_loss=0.1550]\u001b[A\n",
      "Epoch 8/10:  77%|█████████▎  | 61/79 [11:42<03:25, 11.42s/it, train_loss=0.1550]\u001b[A\n",
      "Epoch 8/10:  77%|█████████▎  | 61/79 [11:53<03:25, 11.42s/it, train_loss=0.1573]\u001b[A\n",
      "Epoch 8/10:  78%|█████████▍  | 62/79 [11:53<03:13, 11.38s/it, train_loss=0.1573]\u001b[A\n",
      "Epoch 8/10:  78%|█████████▍  | 62/79 [12:04<03:13, 11.38s/it, train_loss=0.1582]\u001b[A\n",
      "Epoch 8/10:  80%|█████████▌  | 63/79 [12:04<03:01, 11.37s/it, train_loss=0.1582]\u001b[A\n",
      "Epoch 8/10:  80%|█████████▌  | 63/79 [12:16<03:01, 11.37s/it, train_loss=0.1588]\u001b[A\n",
      "Epoch 8/10:  81%|█████████▋  | 64/79 [12:17<02:54, 11.64s/it, train_loss=0.1588]\u001b[A\n",
      "Epoch 8/10:  81%|█████████▋  | 64/79 [12:28<02:54, 11.64s/it, train_loss=0.1575]\u001b[A\n",
      "Epoch 8/10:  82%|█████████▊  | 65/79 [12:29<02:44, 11.72s/it, train_loss=0.1575]\u001b[A\n",
      "Epoch 8/10:  82%|█████████▊  | 65/79 [12:40<02:44, 11.72s/it, train_loss=0.1575]\u001b[A\n",
      "Epoch 8/10:  84%|██████████  | 66/79 [12:41<02:33, 11.84s/it, train_loss=0.1575]\u001b[A\n",
      "Epoch 8/10:  84%|██████████  | 66/79 [12:53<02:33, 11.84s/it, train_loss=0.1583]\u001b[A\n",
      "Epoch 8/10:  85%|██████████▏ | 67/79 [12:53<02:22, 11.91s/it, train_loss=0.1583]\u001b[A\n",
      "Epoch 8/10:  85%|██████████▏ | 67/79 [13:04<02:22, 11.91s/it, train_loss=0.1585]\u001b[A\n",
      "Epoch 8/10:  86%|██████████▎ | 68/79 [13:05<02:11, 11.92s/it, train_loss=0.1585]\u001b[A\n",
      "Epoch 8/10:  86%|██████████▎ | 68/79 [13:17<02:11, 11.92s/it, train_loss=0.1587]\u001b[A\n",
      "Epoch 8/10:  87%|██████████▍ | 69/79 [13:17<02:01, 12.11s/it, train_loss=0.1587]\u001b[A\n",
      "Epoch 8/10:  87%|██████████▍ | 69/79 [13:29<02:01, 12.11s/it, train_loss=0.1578]\u001b[A\n",
      "Epoch 8/10:  89%|██████████▋ | 70/79 [13:29<01:48, 12.09s/it, train_loss=0.1578]\u001b[A\n",
      "Epoch 8/10:  89%|██████████▋ | 70/79 [13:41<01:48, 12.09s/it, train_loss=0.1574]\u001b[A\n",
      "Epoch 8/10:  90%|██████████▊ | 71/79 [13:41<01:36, 12.10s/it, train_loss=0.1574]\u001b[A\n",
      "Epoch 8/10:  90%|██████████▊ | 71/79 [13:54<01:36, 12.10s/it, train_loss=0.1573]\u001b[A\n",
      "Epoch 8/10:  91%|██████████▉ | 72/79 [13:55<01:26, 12.39s/it, train_loss=0.1573]\u001b[A\n",
      "Epoch 8/10:  91%|██████████▉ | 72/79 [14:07<01:26, 12.39s/it, train_loss=0.1574]\u001b[A\n",
      "Epoch 8/10:  92%|███████████ | 73/79 [14:08<01:15, 12.55s/it, train_loss=0.1574]\u001b[A\n",
      "Epoch 8/10:  92%|███████████ | 73/79 [14:19<01:15, 12.55s/it, train_loss=0.1578]\u001b[A\n",
      "Epoch 8/10:  94%|███████████▏| 74/79 [14:20<01:02, 12.45s/it, train_loss=0.1578]\u001b[A\n",
      "Epoch 8/10:  94%|███████████▏| 74/79 [14:32<01:02, 12.45s/it, train_loss=0.1572]\u001b[A\n",
      "Epoch 8/10:  95%|███████████▍| 75/79 [14:32<00:49, 12.49s/it, train_loss=0.1572]\u001b[A\n",
      "Epoch 8/10:  95%|███████████▍| 75/79 [14:45<00:49, 12.49s/it, train_loss=0.1579]\u001b[A\n",
      "Epoch 8/10:  96%|███████████▌| 76/79 [14:45<00:38, 12.68s/it, train_loss=0.1579]\u001b[A\n",
      "Epoch 8/10:  96%|███████████▌| 76/79 [14:58<00:38, 12.68s/it, train_loss=0.1583]\u001b[A\n",
      "Epoch 8/10:  97%|███████████▋| 77/79 [14:59<00:25, 12.82s/it, train_loss=0.1583]\u001b[A\n",
      "Epoch 8/10:  97%|███████████▋| 77/79 [15:10<00:25, 12.82s/it, train_loss=0.1573]\u001b[A\n",
      "Epoch 8/10:  99%|███████████▊| 78/79 [15:11<00:12, 12.61s/it, train_loss=0.1573]\u001b[A\n",
      "Epoch 8/10:  99%|███████████▊| 78/79 [15:12<00:12, 12.61s/it, train_loss=1.2445]\u001b[A\n",
      "Epoch 8/10: 100%|████████████| 79/79 [15:13<00:00,  9.39s/it, train_loss=1.2445]\u001b[A\n",
      "Overall:  80%|█████████████████████████▌      | 8/10 [2:02:35<32:00, 960.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 • Train loss=0.1573 (913.1s) • Val Acc=0.9180 • Prec=0.9198 • Recall=0.9083 • F1=0.9140 • AUC=0.9758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10:   0%|                                        | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9/10:   0%|                     | 0/79 [00:11<?, ?it/s, train_loss=0.0997]\u001b[A\n",
      "Epoch 9/10:   1%|▏            | 1/79 [00:11<15:00, 11.55s/it, train_loss=0.0997]\u001b[A\n",
      "Epoch 9/10:   1%|▏            | 1/79 [00:23<15:00, 11.55s/it, train_loss=0.1220]\u001b[A\n",
      "Epoch 9/10:   3%|▎            | 2/79 [00:23<15:00, 11.69s/it, train_loss=0.1220]\u001b[A\n",
      "Epoch 9/10:   3%|▎            | 2/79 [00:34<15:00, 11.69s/it, train_loss=0.1223]\u001b[A\n",
      "Epoch 9/10:   4%|▍            | 3/79 [00:35<14:50, 11.72s/it, train_loss=0.1223]\u001b[A\n",
      "Epoch 9/10:   4%|▍            | 3/79 [00:47<14:50, 11.72s/it, train_loss=0.1177]\u001b[A\n",
      "Epoch 9/10:   5%|▋            | 4/79 [00:47<14:54, 11.93s/it, train_loss=0.1177]\u001b[A\n",
      "Epoch 9/10:   5%|▋            | 4/79 [00:58<14:54, 11.93s/it, train_loss=0.1422]\u001b[A\n",
      "Epoch 9/10:   6%|▊            | 5/79 [00:59<14:35, 11.84s/it, train_loss=0.1422]\u001b[A\n",
      "Epoch 9/10:   6%|▊            | 5/79 [01:10<14:35, 11.84s/it, train_loss=0.1634]\u001b[A\n",
      "Epoch 9/10:   8%|▉            | 6/79 [01:11<14:33, 11.97s/it, train_loss=0.1634]\u001b[A\n",
      "Epoch 9/10:   8%|▉            | 6/79 [01:22<14:33, 11.97s/it, train_loss=0.1734]\u001b[A\n",
      "Epoch 9/10:   9%|█▏           | 7/79 [01:22<14:15, 11.88s/it, train_loss=0.1734]\u001b[A\n",
      "Epoch 9/10:   9%|█▏           | 7/79 [01:34<14:15, 11.88s/it, train_loss=0.1647]\u001b[A\n",
      "Epoch 9/10:  10%|█▎           | 8/79 [01:34<13:53, 11.73s/it, train_loss=0.1647]\u001b[A\n",
      "Epoch 9/10:  10%|█▎           | 8/79 [01:45<13:53, 11.73s/it, train_loss=0.1747]\u001b[A\n",
      "Epoch 9/10:  11%|█▍           | 9/79 [01:45<13:33, 11.63s/it, train_loss=0.1747]\u001b[A\n",
      "Epoch 9/10:  11%|█▍           | 9/79 [01:56<13:33, 11.63s/it, train_loss=0.1711]\u001b[A\n",
      "Epoch 9/10:  13%|█▌          | 10/79 [01:56<13:10, 11.46s/it, train_loss=0.1711]\u001b[A\n",
      "Epoch 9/10:  13%|█▌          | 10/79 [02:07<13:10, 11.46s/it, train_loss=0.1644]\u001b[A\n",
      "Epoch 9/10:  14%|█▋          | 11/79 [02:07<12:49, 11.32s/it, train_loss=0.1644]\u001b[A\n",
      "Epoch 9/10:  14%|█▋          | 11/79 [02:19<12:49, 11.32s/it, train_loss=0.1624]\u001b[A\n",
      "Epoch 9/10:  15%|█▊          | 12/79 [02:19<12:51, 11.51s/it, train_loss=0.1624]\u001b[A\n",
      "Epoch 9/10:  15%|█▊          | 12/79 [02:30<12:51, 11.51s/it, train_loss=0.1660]\u001b[A\n",
      "Epoch 9/10:  16%|█▉          | 13/79 [02:30<12:32, 11.40s/it, train_loss=0.1660]\u001b[A\n",
      "Epoch 9/10:  16%|█▉          | 13/79 [02:41<12:32, 11.40s/it, train_loss=0.1677]\u001b[A\n",
      "Epoch 9/10:  18%|██▏         | 14/79 [02:42<12:17, 11.35s/it, train_loss=0.1677]\u001b[A\n",
      "Epoch 9/10:  18%|██▏         | 14/79 [02:53<12:17, 11.35s/it, train_loss=0.1666]\u001b[A\n",
      "Epoch 9/10:  19%|██▎         | 15/79 [02:53<12:14, 11.48s/it, train_loss=0.1666]\u001b[A\n",
      "Epoch 9/10:  19%|██▎         | 15/79 [03:04<12:14, 11.48s/it, train_loss=0.1648]\u001b[A\n",
      "Epoch 9/10:  20%|██▍         | 16/79 [03:05<11:57, 11.39s/it, train_loss=0.1648]\u001b[A\n",
      "Epoch 9/10:  20%|██▍         | 16/79 [03:16<11:57, 11.39s/it, train_loss=0.1625]\u001b[A\n",
      "Epoch 9/10:  22%|██▌         | 17/79 [03:16<11:44, 11.36s/it, train_loss=0.1625]\u001b[A\n",
      "Epoch 9/10:  22%|██▌         | 17/79 [03:27<11:44, 11.36s/it, train_loss=0.1582]\u001b[A\n",
      "Epoch 9/10:  23%|██▋         | 18/79 [03:27<11:33, 11.37s/it, train_loss=0.1582]\u001b[A\n",
      "Epoch 9/10:  23%|██▋         | 18/79 [03:39<11:33, 11.37s/it, train_loss=0.1595]\u001b[A\n",
      "Epoch 9/10:  24%|██▉         | 19/79 [03:39<11:26, 11.45s/it, train_loss=0.1595]\u001b[A\n",
      "Epoch 9/10:  24%|██▉         | 19/79 [03:50<11:26, 11.45s/it, train_loss=0.1582]\u001b[A\n",
      "Epoch 9/10:  25%|███         | 20/79 [03:51<11:19, 11.52s/it, train_loss=0.1582]\u001b[A\n",
      "Epoch 9/10:  25%|███         | 20/79 [04:03<11:19, 11.52s/it, train_loss=0.1572]\u001b[A\n",
      "Epoch 9/10:  27%|███▏        | 21/79 [04:03<11:19, 11.72s/it, train_loss=0.1572]\u001b[A\n",
      "Epoch 9/10:  27%|███▏        | 21/79 [04:14<11:19, 11.72s/it, train_loss=0.1575]\u001b[A\n",
      "Epoch 9/10:  28%|███▎        | 22/79 [04:14<11:05, 11.68s/it, train_loss=0.1575]\u001b[A\n",
      "Epoch 9/10:  28%|███▎        | 22/79 [04:25<11:05, 11.68s/it, train_loss=0.1611]\u001b[A\n",
      "Epoch 9/10:  29%|███▍        | 23/79 [04:26<10:48, 11.59s/it, train_loss=0.1611]\u001b[A\n",
      "Epoch 9/10:  29%|███▍        | 23/79 [04:37<10:48, 11.59s/it, train_loss=0.1655]\u001b[A\n",
      "Epoch 9/10:  30%|███▋        | 24/79 [04:37<10:34, 11.54s/it, train_loss=0.1655]\u001b[A\n",
      "Epoch 9/10:  30%|███▋        | 24/79 [04:48<10:34, 11.54s/it, train_loss=0.1627]\u001b[A\n",
      "Epoch 9/10:  32%|███▊        | 25/79 [04:48<10:16, 11.41s/it, train_loss=0.1627]\u001b[A\n",
      "Epoch 9/10:  32%|███▊        | 25/79 [05:00<10:16, 11.41s/it, train_loss=0.1593]\u001b[A\n",
      "Epoch 9/10:  33%|███▉        | 26/79 [05:00<10:16, 11.63s/it, train_loss=0.1593]\u001b[A\n",
      "Epoch 9/10:  33%|███▉        | 26/79 [05:12<10:16, 11.63s/it, train_loss=0.1593]\u001b[A\n",
      "Epoch 9/10:  34%|████        | 27/79 [05:12<10:03, 11.61s/it, train_loss=0.1593]\u001b[A\n",
      "Epoch 9/10:  34%|████        | 27/79 [05:24<10:03, 11.61s/it, train_loss=0.1588]\u001b[A\n",
      "Epoch 9/10:  35%|████▎       | 28/79 [05:24<09:56, 11.70s/it, train_loss=0.1588]\u001b[A\n",
      "Epoch 9/10:  35%|████▎       | 28/79 [05:35<09:56, 11.70s/it, train_loss=0.1612]\u001b[A\n",
      "Epoch 9/10:  37%|████▍       | 29/79 [05:35<09:42, 11.65s/it, train_loss=0.1612]\u001b[A\n",
      "Epoch 9/10:  37%|████▍       | 29/79 [05:47<09:42, 11.65s/it, train_loss=0.1609]\u001b[A\n",
      "Epoch 9/10:  38%|████▌       | 30/79 [05:47<09:30, 11.64s/it, train_loss=0.1609]\u001b[A\n",
      "Epoch 9/10:  38%|████▌       | 30/79 [05:58<09:30, 11.64s/it, train_loss=0.1595]\u001b[A\n",
      "Epoch 9/10:  39%|████▋       | 31/79 [05:59<09:18, 11.63s/it, train_loss=0.1595]\u001b[A\n",
      "Epoch 9/10:  39%|████▋       | 31/79 [06:10<09:18, 11.63s/it, train_loss=0.1578]\u001b[A\n",
      "Epoch 9/10:  41%|████▊       | 32/79 [06:11<09:10, 11.71s/it, train_loss=0.1578]\u001b[A\n",
      "Epoch 9/10:  41%|████▊       | 32/79 [06:22<09:10, 11.71s/it, train_loss=0.1568]\u001b[A\n",
      "Epoch 9/10:  42%|█████       | 33/79 [06:22<08:58, 11.71s/it, train_loss=0.1568]\u001b[A\n",
      "Epoch 9/10:  42%|█████       | 33/79 [06:34<08:58, 11.71s/it, train_loss=0.1562]\u001b[A\n",
      "Epoch 9/10:  43%|█████▏      | 34/79 [06:34<08:53, 11.86s/it, train_loss=0.1562]\u001b[A\n",
      "Epoch 9/10:  43%|█████▏      | 34/79 [06:46<08:53, 11.86s/it, train_loss=0.1565]\u001b[A\n",
      "Epoch 9/10:  44%|█████▎      | 35/79 [06:47<08:45, 11.95s/it, train_loss=0.1565]\u001b[A\n",
      "Epoch 9/10:  44%|█████▎      | 35/79 [06:59<08:45, 11.95s/it, train_loss=0.1576]\u001b[A\n",
      "Epoch 9/10:  46%|█████▍      | 36/79 [06:59<08:39, 12.08s/it, train_loss=0.1576]\u001b[A\n",
      "Epoch 9/10:  46%|█████▍      | 36/79 [07:11<08:39, 12.08s/it, train_loss=0.1562]\u001b[A\n",
      "Epoch 9/10:  47%|█████▌      | 37/79 [07:11<08:25, 12.04s/it, train_loss=0.1562]\u001b[A\n",
      "Epoch 9/10:  47%|█████▌      | 37/79 [07:22<08:25, 12.04s/it, train_loss=0.1540]\u001b[A\n",
      "Epoch 9/10:  48%|█████▊      | 38/79 [07:23<08:09, 11.94s/it, train_loss=0.1540]\u001b[A\n",
      "Epoch 9/10:  48%|█████▊      | 38/79 [07:34<08:09, 11.94s/it, train_loss=0.1526]\u001b[A\n",
      "Epoch 9/10:  49%|█████▉      | 39/79 [07:34<07:52, 11.80s/it, train_loss=0.1526]\u001b[A\n",
      "Epoch 9/10:  49%|█████▉      | 39/79 [07:45<07:52, 11.80s/it, train_loss=0.1513]\u001b[A\n",
      "Epoch 9/10:  51%|██████      | 40/79 [07:45<07:33, 11.64s/it, train_loss=0.1513]\u001b[A\n",
      "Epoch 9/10:  51%|██████      | 40/79 [07:56<07:33, 11.64s/it, train_loss=0.1529]\u001b[A\n",
      "Epoch 9/10:  52%|██████▏     | 41/79 [07:57<07:16, 11.48s/it, train_loss=0.1529]\u001b[A\n",
      "Epoch 9/10:  52%|██████▏     | 41/79 [08:08<07:16, 11.48s/it, train_loss=0.1514]\u001b[A\n",
      "Epoch 9/10:  53%|██████▍     | 42/79 [08:08<07:04, 11.48s/it, train_loss=0.1514]\u001b[A\n",
      "Epoch 9/10:  53%|██████▍     | 42/79 [08:19<07:04, 11.48s/it, train_loss=0.1502]\u001b[A\n",
      "Epoch 9/10:  54%|██████▌     | 43/79 [08:19<06:52, 11.47s/it, train_loss=0.1502]\u001b[A\n",
      "Epoch 9/10:  54%|██████▌     | 43/79 [08:30<06:52, 11.47s/it, train_loss=0.1507]\u001b[A\n",
      "Epoch 9/10:  56%|██████▋     | 44/79 [08:31<06:37, 11.36s/it, train_loss=0.1507]\u001b[A\n",
      "Epoch 9/10:  56%|██████▋     | 44/79 [08:41<06:37, 11.36s/it, train_loss=0.1499]\u001b[A\n",
      "Epoch 9/10:  57%|██████▊     | 45/79 [08:42<06:24, 11.32s/it, train_loss=0.1499]\u001b[A\n",
      "Epoch 9/10:  57%|██████▊     | 45/79 [08:53<06:24, 11.32s/it, train_loss=0.1482]\u001b[A\n",
      "Epoch 9/10:  58%|██████▉     | 46/79 [08:54<06:18, 11.46s/it, train_loss=0.1482]\u001b[A\n",
      "Epoch 9/10:  58%|██████▉     | 46/79 [09:05<06:18, 11.46s/it, train_loss=0.1490]\u001b[A\n",
      "Epoch 9/10:  59%|███████▏    | 47/79 [09:05<06:06, 11.47s/it, train_loss=0.1490]\u001b[A\n",
      "Epoch 9/10:  59%|███████▏    | 47/79 [09:16<06:06, 11.47s/it, train_loss=0.1479]\u001b[A\n",
      "Epoch 9/10:  61%|███████▎    | 48/79 [09:16<05:54, 11.44s/it, train_loss=0.1479]\u001b[A\n",
      "Epoch 9/10:  61%|███████▎    | 48/79 [09:28<05:54, 11.44s/it, train_loss=0.1483]\u001b[A\n",
      "Epoch 9/10:  62%|███████▍    | 49/79 [09:28<05:43, 11.46s/it, train_loss=0.1483]\u001b[A\n",
      "Epoch 9/10:  62%|███████▍    | 49/79 [09:39<05:43, 11.46s/it, train_loss=0.1480]\u001b[A\n",
      "Epoch 9/10:  63%|███████▌    | 50/79 [09:40<05:34, 11.55s/it, train_loss=0.1480]\u001b[A\n",
      "Epoch 9/10:  63%|███████▌    | 50/79 [09:51<05:34, 11.55s/it, train_loss=0.1464]\u001b[A\n",
      "Epoch 9/10:  65%|███████▋    | 51/79 [09:52<05:25, 11.63s/it, train_loss=0.1464]\u001b[A\n",
      "Epoch 9/10:  65%|███████▋    | 51/79 [10:03<05:25, 11.63s/it, train_loss=0.1470]\u001b[A\n",
      "Epoch 9/10:  66%|███████▉    | 52/79 [10:03<05:12, 11.59s/it, train_loss=0.1470]\u001b[A\n",
      "Epoch 9/10:  66%|███████▉    | 52/79 [10:14<05:12, 11.59s/it, train_loss=0.1483]\u001b[A\n",
      "Epoch 9/10:  67%|████████    | 53/79 [10:14<04:59, 11.52s/it, train_loss=0.1483]\u001b[A\n",
      "Epoch 9/10:  67%|████████    | 53/79 [10:25<04:59, 11.52s/it, train_loss=0.1490]\u001b[A\n",
      "Epoch 9/10:  68%|████████▏   | 54/79 [10:26<04:45, 11.44s/it, train_loss=0.1490]\u001b[A\n",
      "Epoch 9/10:  68%|████████▏   | 54/79 [10:36<04:45, 11.44s/it, train_loss=0.1492]\u001b[A\n",
      "Epoch 9/10:  70%|████████▎   | 55/79 [10:37<04:31, 11.32s/it, train_loss=0.1492]\u001b[A\n",
      "Epoch 9/10:  70%|████████▎   | 55/79 [10:48<04:31, 11.32s/it, train_loss=0.1505]\u001b[A\n",
      "Epoch 9/10:  71%|████████▌   | 56/79 [10:48<04:20, 11.31s/it, train_loss=0.1505]\u001b[A\n",
      "Epoch 9/10:  71%|████████▌   | 56/79 [10:59<04:20, 11.31s/it, train_loss=0.1496]\u001b[A\n",
      "Epoch 9/10:  72%|████████▋   | 57/79 [10:59<04:08, 11.29s/it, train_loss=0.1496]\u001b[A\n",
      "Epoch 9/10:  72%|████████▋   | 57/79 [11:10<04:08, 11.29s/it, train_loss=0.1491]\u001b[A\n",
      "Epoch 9/10:  73%|████████▊   | 58/79 [11:10<03:56, 11.26s/it, train_loss=0.1491]\u001b[A\n",
      "Epoch 9/10:  73%|████████▊   | 58/79 [11:21<03:56, 11.26s/it, train_loss=0.1499]\u001b[A\n",
      "Epoch 9/10:  75%|████████▉   | 59/79 [11:22<03:45, 11.26s/it, train_loss=0.1499]\u001b[A\n",
      "Epoch 9/10:  75%|████████▉   | 59/79 [11:33<03:45, 11.26s/it, train_loss=0.1500]\u001b[A\n",
      "Epoch 9/10:  76%|█████████   | 60/79 [11:33<03:33, 11.26s/it, train_loss=0.1500]\u001b[A\n",
      "Epoch 9/10:  76%|█████████   | 60/79 [11:44<03:33, 11.26s/it, train_loss=0.1501]\u001b[A\n",
      "Epoch 9/10:  77%|█████████▎  | 61/79 [11:44<03:24, 11.35s/it, train_loss=0.1501]\u001b[A\n",
      "Epoch 9/10:  77%|█████████▎  | 61/79 [11:56<03:24, 11.35s/it, train_loss=0.1505]\u001b[A\n",
      "Epoch 9/10:  78%|█████████▍  | 62/79 [11:56<03:13, 11.35s/it, train_loss=0.1505]\u001b[A\n",
      "Epoch 9/10:  78%|█████████▍  | 62/79 [12:07<03:13, 11.35s/it, train_loss=0.1499]\u001b[A\n",
      "Epoch 9/10:  80%|█████████▌  | 63/79 [12:07<03:01, 11.36s/it, train_loss=0.1499]\u001b[A\n",
      "Epoch 9/10:  80%|█████████▌  | 63/79 [12:19<03:01, 11.36s/it, train_loss=0.1510]\u001b[A\n",
      "Epoch 9/10:  81%|█████████▋  | 64/79 [12:20<02:56, 11.75s/it, train_loss=0.1510]\u001b[A\n",
      "Epoch 9/10:  81%|█████████▋  | 64/79 [12:32<02:56, 11.75s/it, train_loss=0.1514]\u001b[A\n",
      "Epoch 9/10:  82%|█████████▊  | 65/79 [12:33<02:49, 12.07s/it, train_loss=0.1514]\u001b[A\n",
      "Epoch 9/10:  82%|█████████▊  | 65/79 [12:44<02:49, 12.07s/it, train_loss=0.1530]\u001b[A\n",
      "Epoch 9/10:  84%|██████████  | 66/79 [12:44<02:34, 11.91s/it, train_loss=0.1530]\u001b[A\n",
      "Epoch 9/10:  84%|██████████  | 66/79 [12:55<02:34, 11.91s/it, train_loss=0.1534]\u001b[A\n",
      "Epoch 9/10:  85%|██████████▏ | 67/79 [12:55<02:20, 11.69s/it, train_loss=0.1534]\u001b[A\n",
      "Epoch 9/10:  85%|██████████▏ | 67/79 [13:06<02:20, 11.69s/it, train_loss=0.1545]\u001b[A\n",
      "Epoch 9/10:  86%|██████████▎ | 68/79 [13:07<02:06, 11.54s/it, train_loss=0.1545]\u001b[A\n",
      "Epoch 9/10:  86%|██████████▎ | 68/79 [13:17<02:06, 11.54s/it, train_loss=0.1539]\u001b[A\n",
      "Epoch 9/10:  87%|██████████▍ | 69/79 [13:18<01:54, 11.44s/it, train_loss=0.1539]\u001b[A\n",
      "Epoch 9/10:  87%|██████████▍ | 69/79 [13:29<01:54, 11.44s/it, train_loss=0.1529]\u001b[A\n",
      "Epoch 9/10:  89%|██████████▋ | 70/79 [13:29<01:42, 11.35s/it, train_loss=0.1529]\u001b[A\n",
      "Epoch 9/10:  89%|██████████▋ | 70/79 [13:40<01:42, 11.35s/it, train_loss=0.1532]\u001b[A\n",
      "Epoch 9/10:  90%|██████████▊ | 71/79 [13:40<01:30, 11.32s/it, train_loss=0.1532]\u001b[A\n",
      "Epoch 9/10:  90%|██████████▊ | 71/79 [13:51<01:30, 11.32s/it, train_loss=0.1533]\u001b[A\n",
      "Epoch 9/10:  91%|██████████▉ | 72/79 [13:51<01:19, 11.29s/it, train_loss=0.1533]\u001b[A\n",
      "Epoch 9/10:  91%|██████████▉ | 72/79 [14:03<01:19, 11.29s/it, train_loss=0.1529]\u001b[A\n",
      "Epoch 9/10:  92%|███████████ | 73/79 [14:03<01:08, 11.45s/it, train_loss=0.1529]\u001b[A\n",
      "Epoch 9/10:  92%|███████████ | 73/79 [14:14<01:08, 11.45s/it, train_loss=0.1534]\u001b[A\n",
      "Epoch 9/10:  94%|███████████▏| 74/79 [14:15<00:57, 11.44s/it, train_loss=0.1534]\u001b[A\n",
      "Epoch 9/10:  94%|███████████▏| 74/79 [14:26<00:57, 11.44s/it, train_loss=0.1535]\u001b[A\n",
      "Epoch 9/10:  95%|███████████▍| 75/79 [14:26<00:45, 11.41s/it, train_loss=0.1535]\u001b[A\n",
      "Epoch 9/10:  95%|███████████▍| 75/79 [14:37<00:45, 11.41s/it, train_loss=0.1539]\u001b[A\n",
      "Epoch 9/10:  96%|███████████▌| 76/79 [14:37<00:34, 11.42s/it, train_loss=0.1539]\u001b[A\n",
      "Epoch 9/10:  96%|███████████▌| 76/79 [14:48<00:34, 11.42s/it, train_loss=0.1531]\u001b[A\n",
      "Epoch 9/10:  97%|███████████▋| 77/79 [14:49<00:22, 11.37s/it, train_loss=0.1531]\u001b[A\n",
      "Epoch 9/10:  97%|███████████▋| 77/79 [14:59<00:22, 11.37s/it, train_loss=0.1540]\u001b[A\n",
      "Epoch 9/10:  99%|███████████▊| 78/79 [15:00<00:11, 11.25s/it, train_loss=0.1540]\u001b[A\n",
      "Epoch 9/10:  99%|███████████▊| 78/79 [15:01<00:11, 11.25s/it, train_loss=1.2164]\u001b[A\n",
      "Epoch 9/10: 100%|████████████| 79/79 [15:02<00:00,  8.44s/it, train_loss=1.2164]\u001b[A\n",
      "Overall:  90%|████████████████████████████▊   | 9/10 [2:18:45<16:03, 963.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 • Train loss=0.1537 (902.0s) • Val Acc=0.9200 • Prec=0.8922 • Recall=0.9479 • F1=0.9192 • AUC=0.9761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10:   0%|                                       | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10/10:   0%|                    | 0/79 [00:10<?, ?it/s, train_loss=0.0624]\u001b[A\n",
      "Epoch 10/10:   1%|▏           | 1/79 [00:11<14:29, 11.15s/it, train_loss=0.0624]\u001b[A\n",
      "Epoch 10/10:   1%|▏           | 1/79 [00:21<14:29, 11.15s/it, train_loss=0.1249]\u001b[A\n",
      "Epoch 10/10:   3%|▎           | 2/79 [00:22<14:17, 11.13s/it, train_loss=0.1249]\u001b[A\n",
      "Epoch 10/10:   3%|▎           | 2/79 [00:33<14:17, 11.13s/it, train_loss=0.1347]\u001b[A\n",
      "Epoch 10/10:   4%|▍           | 3/79 [00:33<14:17, 11.29s/it, train_loss=0.1347]\u001b[A\n",
      "Epoch 10/10:   4%|▍           | 3/79 [00:44<14:17, 11.29s/it, train_loss=0.1185]\u001b[A\n",
      "Epoch 10/10:   5%|▌           | 4/79 [00:45<14:06, 11.29s/it, train_loss=0.1185]\u001b[A\n",
      "Epoch 10/10:   5%|▌           | 4/79 [00:56<14:06, 11.29s/it, train_loss=0.1067]\u001b[A\n",
      "Epoch 10/10:   6%|▊           | 5/79 [00:56<13:59, 11.34s/it, train_loss=0.1067]\u001b[A\n",
      "Epoch 10/10:   6%|▊           | 5/79 [01:07<13:59, 11.34s/it, train_loss=0.1096]\u001b[A\n",
      "Epoch 10/10:   8%|▉           | 6/79 [01:07<13:40, 11.24s/it, train_loss=0.1096]\u001b[A\n",
      "Epoch 10/10:   8%|▉           | 6/79 [01:18<13:40, 11.24s/it, train_loss=0.1345]\u001b[A\n",
      "Epoch 10/10:   9%|█           | 7/79 [01:18<13:27, 11.22s/it, train_loss=0.1345]\u001b[A\n",
      "Epoch 10/10:   9%|█           | 7/79 [01:30<13:27, 11.22s/it, train_loss=0.1266]\u001b[A\n",
      "Epoch 10/10:  10%|█▏          | 8/79 [01:30<13:28, 11.39s/it, train_loss=0.1266]\u001b[A\n",
      "Epoch 10/10:  10%|█▏          | 8/79 [01:41<13:28, 11.39s/it, train_loss=0.1334]\u001b[A\n",
      "Epoch 10/10:  11%|█▎          | 9/79 [01:41<13:17, 11.39s/it, train_loss=0.1334]\u001b[A\n",
      "Epoch 10/10:  11%|█▎          | 9/79 [01:52<13:17, 11.39s/it, train_loss=0.1415]\u001b[A\n",
      "Epoch 10/10:  13%|█▍         | 10/79 [01:53<13:05, 11.38s/it, train_loss=0.1415]\u001b[A\n",
      "Epoch 10/10:  13%|█▍         | 10/79 [02:04<13:05, 11.38s/it, train_loss=0.1457]\u001b[A\n",
      "Epoch 10/10:  14%|█▌         | 11/79 [02:04<12:55, 11.40s/it, train_loss=0.1457]\u001b[A\n",
      "Epoch 10/10:  14%|█▌         | 11/79 [02:15<12:55, 11.40s/it, train_loss=0.1443]\u001b[A\n",
      "Epoch 10/10:  15%|█▋         | 12/79 [02:15<12:40, 11.35s/it, train_loss=0.1443]\u001b[A\n",
      "Epoch 10/10:  15%|█▋         | 12/79 [02:27<12:40, 11.35s/it, train_loss=0.1394]\u001b[A\n",
      "Epoch 10/10:  16%|█▊         | 13/79 [02:27<12:37, 11.47s/it, train_loss=0.1394]\u001b[A\n",
      "Epoch 10/10:  16%|█▊         | 13/79 [02:39<12:37, 11.47s/it, train_loss=0.1455]\u001b[A\n",
      "Epoch 10/10:  18%|█▉         | 14/79 [02:39<12:34, 11.61s/it, train_loss=0.1455]\u001b[A\n",
      "Epoch 10/10:  18%|█▉         | 14/79 [02:50<12:34, 11.61s/it, train_loss=0.1453]\u001b[A\n",
      "Epoch 10/10:  19%|██         | 15/79 [02:51<12:22, 11.60s/it, train_loss=0.1453]\u001b[A\n",
      "Epoch 10/10:  19%|██         | 15/79 [03:02<12:22, 11.60s/it, train_loss=0.1472]\u001b[A\n",
      "Epoch 10/10:  20%|██▏        | 16/79 [03:02<12:13, 11.65s/it, train_loss=0.1472]\u001b[A\n",
      "Epoch 10/10:  20%|██▏        | 16/79 [03:13<12:13, 11.65s/it, train_loss=0.1541]\u001b[A\n",
      "Epoch 10/10:  22%|██▎        | 17/79 [03:14<11:55, 11.54s/it, train_loss=0.1541]\u001b[A\n",
      "Epoch 10/10:  22%|██▎        | 17/79 [03:25<11:55, 11.54s/it, train_loss=0.1581]\u001b[A\n",
      "Epoch 10/10:  23%|██▌        | 18/79 [03:25<11:44, 11.54s/it, train_loss=0.1581]\u001b[A\n",
      "Epoch 10/10:  23%|██▌        | 18/79 [03:36<11:44, 11.54s/it, train_loss=0.1543]\u001b[A\n",
      "Epoch 10/10:  24%|██▋        | 19/79 [03:36<11:25, 11.43s/it, train_loss=0.1543]\u001b[A\n",
      "Epoch 10/10:  24%|██▋        | 19/79 [03:47<11:25, 11.43s/it, train_loss=0.1556]\u001b[A\n",
      "Epoch 10/10:  25%|██▊        | 20/79 [03:48<11:10, 11.37s/it, train_loss=0.1556]\u001b[A\n",
      "Epoch 10/10:  25%|██▊        | 20/79 [03:58<11:10, 11.37s/it, train_loss=0.1529]\u001b[A\n",
      "Epoch 10/10:  27%|██▉        | 21/79 [03:59<10:54, 11.28s/it, train_loss=0.1529]\u001b[A\n",
      "Epoch 10/10:  27%|██▉        | 21/79 [04:10<10:54, 11.28s/it, train_loss=0.1544]\u001b[A\n",
      "Epoch 10/10:  28%|███        | 22/79 [04:10<10:39, 11.22s/it, train_loss=0.1544]\u001b[A\n",
      "Epoch 10/10:  28%|███        | 22/79 [04:22<10:39, 11.22s/it, train_loss=0.1546]\u001b[A\n",
      "Epoch 10/10:  29%|███▏       | 23/79 [04:22<10:46, 11.54s/it, train_loss=0.1546]\u001b[A\n",
      "Epoch 10/10:  29%|███▏       | 23/79 [04:33<10:46, 11.54s/it, train_loss=0.1534]\u001b[A\n",
      "Epoch 10/10:  30%|███▎       | 24/79 [04:33<10:31, 11.48s/it, train_loss=0.1534]\u001b[A\n",
      "Epoch 10/10:  30%|███▎       | 24/79 [04:44<10:31, 11.48s/it, train_loss=0.1587]\u001b[A\n",
      "Epoch 10/10:  32%|███▍       | 25/79 [04:45<10:16, 11.41s/it, train_loss=0.1587]\u001b[A\n",
      "Epoch 10/10:  32%|███▍       | 25/79 [04:56<10:16, 11.41s/it, train_loss=0.1565]\u001b[A\n",
      "Epoch 10/10:  33%|███▌       | 26/79 [04:56<10:11, 11.53s/it, train_loss=0.1565]\u001b[A\n",
      "Epoch 10/10:  33%|███▌       | 26/79 [05:07<10:11, 11.53s/it, train_loss=0.1597]\u001b[A\n",
      "Epoch 10/10:  34%|███▊       | 27/79 [05:07<09:51, 11.37s/it, train_loss=0.1597]\u001b[A\n",
      "Epoch 10/10:  34%|███▊       | 27/79 [05:18<09:51, 11.37s/it, train_loss=0.1584]\u001b[A\n",
      "Epoch 10/10:  35%|███▉       | 28/79 [05:18<09:33, 11.24s/it, train_loss=0.1584]\u001b[A\n",
      "Epoch 10/10:  35%|███▉       | 28/79 [05:30<09:33, 11.24s/it, train_loss=0.1570]\u001b[A\n",
      "Epoch 10/10:  37%|████       | 29/79 [05:30<09:28, 11.37s/it, train_loss=0.1570]\u001b[A\n",
      "Epoch 10/10:  37%|████       | 29/79 [05:41<09:28, 11.37s/it, train_loss=0.1550]\u001b[A\n",
      "Epoch 10/10:  38%|████▏      | 30/79 [05:42<09:19, 11.41s/it, train_loss=0.1550]\u001b[A\n",
      "Epoch 10/10:  38%|████▏      | 30/79 [05:52<09:19, 11.41s/it, train_loss=0.1563]\u001b[A\n",
      "Epoch 10/10:  39%|████▎      | 31/79 [05:53<09:04, 11.34s/it, train_loss=0.1563]\u001b[A\n",
      "Epoch 10/10:  39%|████▎      | 31/79 [06:04<09:04, 11.34s/it, train_loss=0.1547]\u001b[A\n",
      "Epoch 10/10:  41%|████▍      | 32/79 [06:04<08:52, 11.33s/it, train_loss=0.1547]\u001b[A\n",
      "Epoch 10/10:  41%|████▍      | 32/79 [06:15<08:52, 11.33s/it, train_loss=0.1555]\u001b[A\n",
      "Epoch 10/10:  42%|████▌      | 33/79 [06:15<08:38, 11.26s/it, train_loss=0.1555]\u001b[A\n",
      "Epoch 10/10:  42%|████▌      | 33/79 [06:26<08:38, 11.26s/it, train_loss=0.1549]\u001b[A\n",
      "Epoch 10/10:  43%|████▋      | 34/79 [06:26<08:25, 11.24s/it, train_loss=0.1549]\u001b[A\n",
      "Epoch 10/10:  43%|████▋      | 34/79 [06:37<08:25, 11.24s/it, train_loss=0.1548]\u001b[A\n",
      "Epoch 10/10:  44%|████▊      | 35/79 [06:37<08:13, 11.21s/it, train_loss=0.1548]\u001b[A\n",
      "Epoch 10/10:  44%|████▊      | 35/79 [06:48<08:13, 11.21s/it, train_loss=0.1539]\u001b[A\n",
      "Epoch 10/10:  46%|█████      | 36/79 [06:49<08:01, 11.19s/it, train_loss=0.1539]\u001b[A\n",
      "Epoch 10/10:  46%|█████      | 36/79 [06:59<08:01, 11.19s/it, train_loss=0.1524]\u001b[A\n",
      "Epoch 10/10:  47%|█████▏     | 37/79 [06:59<07:45, 11.09s/it, train_loss=0.1524]\u001b[A\n",
      "Epoch 10/10:  47%|█████▏     | 37/79 [07:10<07:45, 11.09s/it, train_loss=0.1506]\u001b[A\n",
      "Epoch 10/10:  48%|█████▎     | 38/79 [07:11<07:35, 11.10s/it, train_loss=0.1506]\u001b[A\n",
      "Epoch 10/10:  48%|█████▎     | 38/79 [07:21<07:35, 11.10s/it, train_loss=0.1496]\u001b[A\n",
      "Epoch 10/10:  49%|█████▍     | 39/79 [07:21<07:20, 11.02s/it, train_loss=0.1496]\u001b[A\n",
      "Epoch 10/10:  49%|█████▍     | 39/79 [07:32<07:20, 11.02s/it, train_loss=0.1500]\u001b[A\n",
      "Epoch 10/10:  51%|█████▌     | 40/79 [07:33<07:11, 11.08s/it, train_loss=0.1500]\u001b[A\n",
      "Epoch 10/10:  51%|█████▌     | 40/79 [07:44<07:11, 11.08s/it, train_loss=0.1500]\u001b[A\n",
      "Epoch 10/10:  52%|█████▋     | 41/79 [07:44<07:02, 11.12s/it, train_loss=0.1500]\u001b[A\n",
      "Epoch 10/10:  52%|█████▋     | 41/79 [07:55<07:02, 11.12s/it, train_loss=0.1506]\u001b[A\n",
      "Epoch 10/10:  53%|█████▊     | 42/79 [07:55<06:51, 11.13s/it, train_loss=0.1506]\u001b[A\n",
      "Epoch 10/10:  53%|█████▊     | 42/79 [08:06<06:51, 11.13s/it, train_loss=0.1490]\u001b[A\n",
      "Epoch 10/10:  54%|█████▉     | 43/79 [08:06<06:42, 11.18s/it, train_loss=0.1490]\u001b[A\n",
      "Epoch 10/10:  54%|█████▉     | 43/79 [08:17<06:42, 11.18s/it, train_loss=0.1476]\u001b[A\n",
      "Epoch 10/10:  56%|██████▏    | 44/79 [08:17<06:29, 11.13s/it, train_loss=0.1476]\u001b[A\n",
      "Epoch 10/10:  56%|██████▏    | 44/79 [08:29<06:29, 11.13s/it, train_loss=0.1470]\u001b[A\n",
      "Epoch 10/10:  57%|██████▎    | 45/79 [08:29<06:23, 11.27s/it, train_loss=0.1470]\u001b[A\n",
      "Epoch 10/10:  57%|██████▎    | 45/79 [08:40<06:23, 11.27s/it, train_loss=0.1476]\u001b[A\n",
      "Epoch 10/10:  58%|██████▍    | 46/79 [08:40<06:13, 11.32s/it, train_loss=0.1476]\u001b[A\n",
      "Epoch 10/10:  58%|██████▍    | 46/79 [08:52<06:13, 11.32s/it, train_loss=0.1500]\u001b[A\n",
      "Epoch 10/10:  59%|██████▌    | 47/79 [08:52<06:09, 11.55s/it, train_loss=0.1500]\u001b[A\n",
      "Epoch 10/10:  59%|██████▌    | 47/79 [09:04<06:09, 11.55s/it, train_loss=0.1501]\u001b[A\n",
      "Epoch 10/10:  61%|██████▋    | 48/79 [09:04<06:00, 11.63s/it, train_loss=0.1501]\u001b[A\n",
      "Epoch 10/10:  61%|██████▋    | 48/79 [09:16<06:00, 11.63s/it, train_loss=0.1499]\u001b[A\n",
      "Epoch 10/10:  62%|██████▊    | 49/79 [09:16<05:49, 11.63s/it, train_loss=0.1499]\u001b[A\n",
      "Epoch 10/10:  62%|██████▊    | 49/79 [09:27<05:49, 11.63s/it, train_loss=0.1495]\u001b[A\n",
      "Epoch 10/10:  63%|██████▉    | 50/79 [09:27<05:35, 11.56s/it, train_loss=0.1495]\u001b[A\n",
      "Epoch 10/10:  63%|██████▉    | 50/79 [09:39<05:35, 11.56s/it, train_loss=0.1507]\u001b[A\n",
      "Epoch 10/10:  65%|███████    | 51/79 [09:39<05:22, 11.53s/it, train_loss=0.1507]\u001b[A\n",
      "Epoch 10/10:  65%|███████    | 51/79 [09:50<05:22, 11.53s/it, train_loss=0.1511]\u001b[A\n",
      "Epoch 10/10:  66%|███████▏   | 52/79 [09:50<05:07, 11.38s/it, train_loss=0.1511]\u001b[A\n",
      "Epoch 10/10:  66%|███████▏   | 52/79 [10:00<05:07, 11.38s/it, train_loss=0.1506]\u001b[A\n",
      "Epoch 10/10:  67%|███████▍   | 53/79 [10:01<04:52, 11.26s/it, train_loss=0.1506]\u001b[A\n",
      "Epoch 10/10:  67%|███████▍   | 53/79 [10:11<04:52, 11.26s/it, train_loss=0.1518]\u001b[A\n",
      "Epoch 10/10:  68%|███████▌   | 54/79 [10:12<04:38, 11.16s/it, train_loss=0.1518]\u001b[A\n",
      "Epoch 10/10:  68%|███████▌   | 54/79 [10:23<04:38, 11.16s/it, train_loss=0.1512]\u001b[A\n",
      "Epoch 10/10:  70%|███████▋   | 55/79 [10:23<04:27, 11.16s/it, train_loss=0.1512]\u001b[A\n",
      "Epoch 10/10:  70%|███████▋   | 55/79 [10:34<04:27, 11.16s/it, train_loss=0.1523]\u001b[A\n",
      "Epoch 10/10:  71%|███████▊   | 56/79 [10:34<04:17, 11.20s/it, train_loss=0.1523]\u001b[A\n",
      "Epoch 10/10:  71%|███████▊   | 56/79 [10:46<04:17, 11.20s/it, train_loss=0.1510]\u001b[A\n",
      "Epoch 10/10:  72%|███████▉   | 57/79 [10:46<04:10, 11.40s/it, train_loss=0.1510]\u001b[A\n",
      "Epoch 10/10:  72%|███████▉   | 57/79 [10:57<04:10, 11.40s/it, train_loss=0.1496]\u001b[A\n",
      "Epoch 10/10:  73%|████████   | 58/79 [10:58<04:00, 11.48s/it, train_loss=0.1496]\u001b[A\n",
      "Epoch 10/10:  73%|████████   | 58/79 [11:09<04:00, 11.48s/it, train_loss=0.1498]\u001b[A\n",
      "Epoch 10/10:  75%|████████▏  | 59/79 [11:09<03:49, 11.46s/it, train_loss=0.1498]\u001b[A\n",
      "Epoch 10/10:  75%|████████▏  | 59/79 [11:20<03:49, 11.46s/it, train_loss=0.1499]\u001b[A\n",
      "Epoch 10/10:  76%|████████▎  | 60/79 [11:20<03:36, 11.37s/it, train_loss=0.1499]\u001b[A\n",
      "Epoch 10/10:  76%|████████▎  | 60/79 [11:31<03:36, 11.37s/it, train_loss=0.1486]\u001b[A\n",
      "Epoch 10/10:  77%|████████▍  | 61/79 [11:31<03:23, 11.32s/it, train_loss=0.1486]\u001b[A\n",
      "Epoch 10/10:  77%|████████▍  | 61/79 [11:42<03:23, 11.32s/it, train_loss=0.1491]\u001b[A\n",
      "Epoch 10/10:  78%|████████▋  | 62/79 [11:43<03:11, 11.27s/it, train_loss=0.1491]\u001b[A\n",
      "Epoch 10/10:  78%|████████▋  | 62/79 [11:54<03:11, 11.27s/it, train_loss=0.1492]\u001b[A\n",
      "Epoch 10/10:  80%|████████▊  | 63/79 [11:54<03:01, 11.33s/it, train_loss=0.1492]\u001b[A\n",
      "Epoch 10/10:  80%|████████▊  | 63/79 [12:05<03:01, 11.33s/it, train_loss=0.1484]\u001b[A\n",
      "Epoch 10/10:  81%|████████▉  | 64/79 [12:05<02:49, 11.32s/it, train_loss=0.1484]\u001b[A\n",
      "Epoch 10/10:  81%|████████▉  | 64/79 [12:16<02:49, 11.32s/it, train_loss=0.1474]\u001b[A\n",
      "Epoch 10/10:  82%|█████████  | 65/79 [12:16<02:37, 11.23s/it, train_loss=0.1474]\u001b[A\n",
      "Epoch 10/10:  82%|█████████  | 65/79 [12:27<02:37, 11.23s/it, train_loss=0.1476]\u001b[A\n",
      "Epoch 10/10:  84%|█████████▏ | 66/79 [12:27<02:25, 11.19s/it, train_loss=0.1476]\u001b[A\n",
      "Epoch 10/10:  84%|█████████▏ | 66/79 [12:38<02:25, 11.19s/it, train_loss=0.1490]\u001b[A\n",
      "Epoch 10/10:  85%|█████████▎ | 67/79 [12:39<02:14, 11.22s/it, train_loss=0.1490]\u001b[A\n",
      "Epoch 10/10:  85%|█████████▎ | 67/79 [12:50<02:14, 11.22s/it, train_loss=0.1488]\u001b[A\n",
      "Epoch 10/10:  86%|█████████▍ | 68/79 [12:50<02:04, 11.35s/it, train_loss=0.1488]\u001b[A\n",
      "Epoch 10/10:  86%|█████████▍ | 68/79 [13:02<02:04, 11.35s/it, train_loss=0.1475]\u001b[A\n",
      "Epoch 10/10:  87%|█████████▌ | 69/79 [13:02<01:54, 11.42s/it, train_loss=0.1475]\u001b[A\n",
      "Epoch 10/10:  87%|█████████▌ | 69/79 [13:13<01:54, 11.42s/it, train_loss=0.1474]\u001b[A\n",
      "Epoch 10/10:  89%|█████████▋ | 70/79 [13:14<01:43, 11.47s/it, train_loss=0.1474]\u001b[A\n",
      "Overall:  90%|███████████████████████████▉   | 9/10 [2:32:11<16:54, 1014.60s/it]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trange, tqdm\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m trange(start_epoch, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     train_loss, train_time \u001b[38;5;241m=\u001b[39m train_one_epoch(epoch, start_batch)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# after first epoch, always start batch at 0\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     start_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[24], line 28\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, resume_batch)\u001b[0m\n\u001b[1;32m     25\u001b[0m loss    \u001b[38;5;241m=\u001b[39m criterion(logits, labels)\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     30\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    650\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m _engine_run_backward(\n\u001b[1;32m    354\u001b[0m     tensors,\n\u001b[1;32m    355\u001b[0m     grad_tensors_,\n\u001b[1;32m    356\u001b[0m     retain_graph,\n\u001b[1;32m    357\u001b[0m     create_graph,\n\u001b[1;32m    358\u001b[0m     inputs,\n\u001b[1;32m    359\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    360\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    361\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "for epoch in trange(start_epoch, epochs + 1, desc=\"Overall\"):\n",
    "    train_loss, train_time = train_one_epoch(epoch, start_batch)\n",
    "    # after first epoch, always start batch at 0\n",
    "    start_batch = 0\n",
    "\n",
    "    metrics = evaluate_binary(val_loader)\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{epochs} • \"\n",
    "        f\"Train loss={train_loss:.4f} ({train_time:.1f}s) • \"\n",
    "        f\"Val Acc={metrics['acc']:.4f} • \"\n",
    "        f\"Prec={metrics['prec']:.4f} • \"\n",
    "        f\"Recall={metrics['rec']:.4f} • \"\n",
    "        f\"F1={metrics['f1']:.4f} • \"\n",
    "        f\"AUC={metrics['roc_auc']:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1d38c7f817c140719ca0344c67c447e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c60248dd79d04344b37e9eeeceb59831",
      "placeholder": "​",
      "style": "IPY_MODEL_7f491eb21bdf4ced8ae70fd622b972fd",
      "value": " 346M/346M [00:02&lt;00:00, 105MB/s]"
     }
    },
    "1f4919bde4e14e99a82aa78d6e4a63e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b0440a258acd469d8c5a8cd1f94bed7f",
       "IPY_MODEL_95ddb99c650645fcadf6c530f8d98a77",
       "IPY_MODEL_1d38c7f817c140719ca0344c67c447e4"
      ],
      "layout": "IPY_MODEL_8b5ebc0002d049a6ab90ae6cf8a85b0e"
     }
    },
    "4bd1451f5e6c48f1b0cd2eddf7ac450c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f491eb21bdf4ced8ae70fd622b972fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8423e26de1ca41ae9c36ecf535abab0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b5ebc0002d049a6ab90ae6cf8a85b0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8de7e2127b664cdd8fd86c950e9bb501": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95ddb99c650645fcadf6c530f8d98a77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8de7e2127b664cdd8fd86c950e9bb501",
      "max": 346293852,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d2b84222d8384ee1ae23c71e6c5bde2c",
      "value": 346293852
     }
    },
    "b0440a258acd469d8c5a8cd1f94bed7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4bd1451f5e6c48f1b0cd2eddf7ac450c",
      "placeholder": "​",
      "style": "IPY_MODEL_8423e26de1ca41ae9c36ecf535abab0f",
      "value": "model.safetensors: 100%"
     }
    },
    "c60248dd79d04344b37e9eeeceb59831": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2b84222d8384ee1ae23c71e6c5bde2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
